diff --git a/.gitignore b/.gitignore
index fdedd4a..0efd60f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1 +1,2 @@
 /build-nacl-*
+*.swp
diff --git a/ffmpeg.c b/ffmpeg.c
index 001e5c1..86b9af1 100644
--- a/ffmpeg.c
+++ b/ffmpeg.c
@@ -102,6 +102,8 @@
 
 #include "libavutil/avassert.h"
 
+#undef HAVE_GETRUSAGE
+
 const char program_name[] = "ffmpeg";
 const int program_birth_year = 2000;
 
diff --git a/libavcodec/x86/dsputil_mmx.c b/libavcodec/x86/dsputil_mmx.c
index 805bacd..92fff1d 100644
--- a/libavcodec/x86/dsputil_mmx.c
+++ b/libavcodec/x86/dsputil_mmx.c
@@ -44,22 +44,22 @@ void ff_put_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
     pix = pixels;
     /* unrolled loop */
     __asm__ volatile (
-        "movq      (%3), %%mm0          \n\t"
-        "movq     8(%3), %%mm1          \n\t"
-        "movq    16(%3), %%mm2          \n\t"
-        "movq    24(%3), %%mm3          \n\t"
-        "movq    32(%3), %%mm4          \n\t"
-        "movq    40(%3), %%mm5          \n\t"
-        "movq    48(%3), %%mm6          \n\t"
-        "movq    56(%3), %%mm7          \n\t"
+        "movq      (%q3), %%mm0          \n\t"
+        "movq     8(%q3), %%mm1          \n\t"
+        "movq    16(%q3), %%mm2          \n\t"
+        "movq    24(%q3), %%mm3          \n\t"
+        "movq    32(%q3), %%mm4          \n\t"
+        "movq    40(%q3), %%mm5          \n\t"
+        "movq    48(%q3), %%mm6          \n\t"
+        "movq    56(%q3), %%mm7          \n\t"
         "packuswb %%mm1, %%mm0          \n\t"
         "packuswb %%mm3, %%mm2          \n\t"
         "packuswb %%mm5, %%mm4          \n\t"
         "packuswb %%mm7, %%mm6          \n\t"
-        "movq     %%mm0, (%0)           \n\t"
-        "movq     %%mm2, (%0, %1)       \n\t"
-        "movq     %%mm4, (%0, %1, 2)    \n\t"
-        "movq     %%mm6, (%0, %2)       \n\t"
+        "movq     %%mm0, (%q0)           \n\t"
+        "movq     %%mm2, (%q0, %q1)       \n\t"
+        "movq     %%mm4, (%q0, %q1, 2)    \n\t"
+        "movq     %%mm6, (%q0, %q2)       \n\t"
         :: "r"(pix), "r"((x86_reg)line_size), "r"((x86_reg)line_size * 3),
            "r"(p)
         : "memory");
@@ -70,43 +70,43 @@ void ff_put_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
     // compiler would generate some very strange code
     // thus using "r"
     __asm__ volatile (
-        "movq       (%3), %%mm0         \n\t"
-        "movq      8(%3), %%mm1         \n\t"
-        "movq     16(%3), %%mm2         \n\t"
-        "movq     24(%3), %%mm3         \n\t"
-        "movq     32(%3), %%mm4         \n\t"
-        "movq     40(%3), %%mm5         \n\t"
-        "movq     48(%3), %%mm6         \n\t"
-        "movq     56(%3), %%mm7         \n\t"
+        "movq       (%q3), %%mm0         \n\t"
+        "movq      8(%q3), %%mm1         \n\t"
+        "movq     16(%q3), %%mm2         \n\t"
+        "movq     24(%q3), %%mm3         \n\t"
+        "movq     32(%q3), %%mm4         \n\t"
+        "movq     40(%q3), %%mm5         \n\t"
+        "movq     48(%q3), %%mm6         \n\t"
+        "movq     56(%q3), %%mm7         \n\t"
         "packuswb  %%mm1, %%mm0         \n\t"
         "packuswb  %%mm3, %%mm2         \n\t"
         "packuswb  %%mm5, %%mm4         \n\t"
         "packuswb  %%mm7, %%mm6         \n\t"
-        "movq      %%mm0, (%0)          \n\t"
-        "movq      %%mm2, (%0, %1)      \n\t"
-        "movq      %%mm4, (%0, %1, 2)   \n\t"
-        "movq      %%mm6, (%0, %2)      \n\t"
+        "movq      %%mm0, (%q0)          \n\t"
+        "movq      %%mm2, (%q0, %q1)      \n\t"
+        "movq      %%mm4, (%q0, %q1, 2)   \n\t"
+        "movq      %%mm6, (%q0, %q2)      \n\t"
         :: "r"(pix), "r"((x86_reg)line_size), "r"((x86_reg)line_size * 3), "r"(p)
         : "memory");
 }
 
 #define put_signed_pixels_clamped_mmx_half(off)             \
-    "movq          "#off"(%2), %%mm1        \n\t"           \
-    "movq     16 + "#off"(%2), %%mm2        \n\t"           \
-    "movq     32 + "#off"(%2), %%mm3        \n\t"           \
-    "movq     48 + "#off"(%2), %%mm4        \n\t"           \
-    "packsswb  8 + "#off"(%2), %%mm1        \n\t"           \
-    "packsswb 24 + "#off"(%2), %%mm2        \n\t"           \
-    "packsswb 40 + "#off"(%2), %%mm3        \n\t"           \
-    "packsswb 56 + "#off"(%2), %%mm4        \n\t"           \
+    "movq          "#off"(%q2), %%mm1        \n\t"           \
+    "movq     16 + "#off"(%q2), %%mm2        \n\t"           \
+    "movq     32 + "#off"(%q2), %%mm3        \n\t"           \
+    "movq     48 + "#off"(%q2), %%mm4        \n\t"           \
+    "packsswb  8 + "#off"(%q2), %%mm1        \n\t"           \
+    "packsswb 24 + "#off"(%q2), %%mm2        \n\t"           \
+    "packsswb 40 + "#off"(%q2), %%mm3        \n\t"           \
+    "packsswb 56 + "#off"(%q2), %%mm4        \n\t"           \
     "paddb              %%mm0, %%mm1        \n\t"           \
     "paddb              %%mm0, %%mm2        \n\t"           \
     "paddb              %%mm0, %%mm3        \n\t"           \
     "paddb              %%mm0, %%mm4        \n\t"           \
-    "movq               %%mm1, (%0)         \n\t"           \
-    "movq               %%mm2, (%0, %3)     \n\t"           \
-    "movq               %%mm3, (%0, %3, 2)  \n\t"           \
-    "movq               %%mm4, (%0, %1)     \n\t"
+    "movq               %%mm1, (%q0)         \n\t"           \
+    "movq               %%mm2, (%q0, %q3)     \n\t"           \
+    "movq               %%mm3, (%q0, %q3, 2)  \n\t"           \
+    "movq               %%mm4, (%q0, %q1)     \n\t"
 
 void ff_put_signed_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
                                       int line_size)
@@ -116,9 +116,9 @@ void ff_put_signed_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
 
     __asm__ volatile (
         "movq "MANGLE(ff_pb_80)", %%mm0     \n\t"
-        "lea         (%3, %3, 2), %1        \n\t"
+        "lea         (%q3, %q3, 2), %q1        \n\t"
         put_signed_pixels_clamped_mmx_half(0)
-        "lea         (%0, %3, 4), %0        \n\t"
+        "lea         (%q0, %q3, 4), %q0        \n\t"
         put_signed_pixels_clamped_mmx_half(64)
         : "+&r"(pixels), "=&r"(line_skip3)
         : "r"(block), "r"(line_skip)
@@ -139,12 +139,12 @@ void ff_add_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
     i = 4;
     do {
         __asm__ volatile (
-            "movq        (%2), %%mm0    \n\t"
-            "movq       8(%2), %%mm1    \n\t"
-            "movq      16(%2), %%mm2    \n\t"
-            "movq      24(%2), %%mm3    \n\t"
-            "movq          %0, %%mm4    \n\t"
-            "movq          %1, %%mm6    \n\t"
+            "movq        (%q2), %%mm0    \n\t"
+            "movq       8(%q2), %%mm1    \n\t"
+            "movq      16(%q2), %%mm2    \n\t"
+            "movq      24(%q2), %%mm3    \n\t"
+            "movq          %q0, %%mm4    \n\t"
+            "movq          %q1, %%mm6    \n\t"
             "movq       %%mm4, %%mm5    \n\t"
             "punpcklbw  %%mm7, %%mm4    \n\t"
             "punpckhbw  %%mm7, %%mm5    \n\t"
@@ -157,8 +157,8 @@ void ff_add_pixels_clamped_mmx(const int16_t *block, uint8_t *pixels,
             "paddsw     %%mm5, %%mm3    \n\t"
             "packuswb   %%mm1, %%mm0    \n\t"
             "packuswb   %%mm3, %%mm2    \n\t"
-            "movq       %%mm0, %0       \n\t"
-            "movq       %%mm2, %1       \n\t"
+            "movq       %%mm0, %q0       \n\t"
+            "movq       %%mm2, %q1       \n\t"
             : "+m"(*pix), "+m"(*(pix + line_size))
             : "r"(p)
             : "memory");
@@ -172,12 +172,12 @@ void name(int16_t *blocks)                              \
 {                                                       \
     __asm__ volatile (                                  \
         "pxor %%mm7, %%mm7              \n\t"           \
-        "mov     %1,        %%"REG_a"   \n\t"           \
+        "mov     %q1,        %%"REG_a"   \n\t"           \
         "1:                             \n\t"           \
-        "movq %%mm7,   (%0, %%"REG_a")  \n\t"           \
-        "movq %%mm7,  8(%0, %%"REG_a")  \n\t"           \
-        "movq %%mm7, 16(%0, %%"REG_a")  \n\t"           \
-        "movq %%mm7, 24(%0, %%"REG_a")  \n\t"           \
+        "movq %%mm7,   (%q0, %%"REG_a")  \n\t"           \
+        "movq %%mm7,  8(%q0, %%"REG_a")  \n\t"           \
+        "movq %%mm7, 16(%q0, %%"REG_a")  \n\t"           \
+        "movq %%mm7, 24(%q0, %%"REG_a")  \n\t"           \
         "add    $32, %%"REG_a"          \n\t"           \
         "js      1b                     \n\t"           \
         :: "r"(((uint8_t *)blocks) + 128 * n),          \
@@ -192,14 +192,14 @@ void ff_clear_block_sse(int16_t *block)
 {
     __asm__ volatile (
         "xorps  %%xmm0, %%xmm0          \n"
-        "movaps %%xmm0,    (%0)         \n"
-        "movaps %%xmm0,  16(%0)         \n"
-        "movaps %%xmm0,  32(%0)         \n"
-        "movaps %%xmm0,  48(%0)         \n"
-        "movaps %%xmm0,  64(%0)         \n"
-        "movaps %%xmm0,  80(%0)         \n"
-        "movaps %%xmm0,  96(%0)         \n"
-        "movaps %%xmm0, 112(%0)         \n"
+        "movaps %%xmm0,    (%q0)         \n"
+        "movaps %%xmm0,  16(%q0)         \n"
+        "movaps %%xmm0,  32(%q0)         \n"
+        "movaps %%xmm0,  48(%q0)         \n"
+        "movaps %%xmm0,  64(%q0)         \n"
+        "movaps %%xmm0,  80(%q0)         \n"
+        "movaps %%xmm0,  96(%q0)         \n"
+        "movaps %%xmm0, 112(%q0)         \n"
         :: "r"(block)
         : "memory"
     );
@@ -209,16 +209,16 @@ void ff_clear_blocks_sse(int16_t *blocks)
 {
     __asm__ volatile (
         "xorps  %%xmm0, %%xmm0              \n"
-        "mov        %1,         %%"REG_a"   \n"
+        "mov        %q1,         %%"REG_a"   \n"
         "1:                                 \n"
-        "movaps %%xmm0,    (%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  16(%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  32(%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  48(%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  64(%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  80(%0, %%"REG_a")  \n"
-        "movaps %%xmm0,  96(%0, %%"REG_a")  \n"
-        "movaps %%xmm0, 112(%0, %%"REG_a")  \n"
+        "movaps %%xmm0,    (%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  16(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  32(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  48(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  64(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  80(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0,  96(%q0, %%"REG_a")  \n"
+        "movaps %%xmm0, 112(%q0, %%"REG_a")  \n"
         "add      $128,         %%"REG_a"   \n"
         "js         1b                      \n"
         :: "r"(((uint8_t *)blocks) + 128 * 6),
@@ -233,17 +233,17 @@ void ff_add_bytes_mmx(uint8_t *dst, uint8_t *src, int w)
     __asm__ volatile (
         "jmp          2f                \n\t"
         "1:                             \n\t"
-        "movq   (%1, %0), %%mm0         \n\t"
-        "movq   (%2, %0), %%mm1         \n\t"
+        "movq   (%q1, %q0), %%mm0         \n\t"
+        "movq   (%q2, %q0), %%mm1         \n\t"
         "paddb     %%mm0, %%mm1         \n\t"
-        "movq      %%mm1, (%2, %0)      \n\t"
-        "movq  8(%1, %0), %%mm0         \n\t"
-        "movq  8(%2, %0), %%mm1         \n\t"
+        "movq      %%mm1, (%q2, %q0)      \n\t"
+        "movq  8(%q1, %q0), %%mm0         \n\t"
+        "movq  8(%q2, %q0), %%mm1         \n\t"
         "paddb     %%mm0, %%mm1         \n\t"
-        "movq      %%mm1, 8(%2, %0)     \n\t"
-        "add         $16, %0            \n\t"
+        "movq      %%mm1, 8(%q2, %q0)     \n\t"
+        "add         $16, %q0            \n\t"
         "2:                             \n\t"
-        "cmp          %3, %0            \n\t"
+        "cmp          %q3, %q0            \n\t"
         "js           1b                \n\t"
         : "+r"(i)
         : "r"(src), "r"(dst), "r"((x86_reg)w - 15)
@@ -266,18 +266,18 @@ void ff_draw_edges_mmx(uint8_t *buf, int wrap, int width, int height,
     if (w == 8) {
         __asm__ volatile (
             "1:                             \n\t"
-            "movd            (%0), %%mm0    \n\t"
+            "movd            (%q0), %%mm0    \n\t"
             "punpcklbw      %%mm0, %%mm0    \n\t"
             "punpcklwd      %%mm0, %%mm0    \n\t"
             "punpckldq      %%mm0, %%mm0    \n\t"
-            "movq           %%mm0, -8(%0)   \n\t"
-            "movq      -8(%0, %2), %%mm1    \n\t"
+            "movq           %%mm0, -8(%q0)   \n\t"
+            "movq      -8(%q0, %q2), %%mm1    \n\t"
             "punpckhbw      %%mm1, %%mm1    \n\t"
             "punpckhwd      %%mm1, %%mm1    \n\t"
             "punpckhdq      %%mm1, %%mm1    \n\t"
-            "movq           %%mm1, (%0, %2) \n\t"
-            "add               %1, %0       \n\t"
-            "cmp               %3, %0       \n\t"
+            "movq           %%mm1, (%q0, %q2) \n\t"
+            "add               %q1, %q0       \n\t"
+            "cmp               %q3, %q0       \n\t"
             "jb                1b           \n\t"
             : "+r"(ptr)
             : "r"((x86_reg)wrap), "r"((x86_reg)width), "r"(ptr + wrap * height)
@@ -285,20 +285,20 @@ void ff_draw_edges_mmx(uint8_t *buf, int wrap, int width, int height,
     } else if(w==16){
         __asm__ volatile (
             "1:                                 \n\t"
-            "movd            (%0), %%mm0        \n\t"
+            "movd            (%q0), %%mm0        \n\t"
             "punpcklbw      %%mm0, %%mm0        \n\t"
             "punpcklwd      %%mm0, %%mm0        \n\t"
             "punpckldq      %%mm0, %%mm0        \n\t"
-            "movq           %%mm0, -8(%0)       \n\t"
-            "movq           %%mm0, -16(%0)      \n\t"
-            "movq      -8(%0, %2), %%mm1        \n\t"
+            "movq           %%mm0, -8(%q0)       \n\t"
+            "movq           %%mm0, -16(%q0)      \n\t"
+            "movq      -8(%q0, %q2), %%mm1        \n\t"
             "punpckhbw      %%mm1, %%mm1        \n\t"
             "punpckhwd      %%mm1, %%mm1        \n\t"
             "punpckhdq      %%mm1, %%mm1        \n\t"
-            "movq           %%mm1,  (%0, %2)    \n\t"
-            "movq           %%mm1, 8(%0, %2)    \n\t"
-            "add               %1, %0           \n\t"
-            "cmp               %3, %0           \n\t"
+            "movq           %%mm1,  (%q0, %q2)    \n\t"
+            "movq           %%mm1, 8(%q0, %q2)    \n\t"
+            "add               %q1, %q0           \n\t"
+            "cmp               %q3, %q0           \n\t"
             "jb                1b               \n\t"
             : "+r"(ptr)
             : "r"((x86_reg)wrap), "r"((x86_reg)width), "r"(ptr + wrap * height)
@@ -307,17 +307,17 @@ void ff_draw_edges_mmx(uint8_t *buf, int wrap, int width, int height,
         av_assert1(w == 4);
         __asm__ volatile (
             "1:                             \n\t"
-            "movd            (%0), %%mm0    \n\t"
+            "movd            (%q0), %%mm0    \n\t"
             "punpcklbw      %%mm0, %%mm0    \n\t"
             "punpcklwd      %%mm0, %%mm0    \n\t"
-            "movd           %%mm0, -4(%0)   \n\t"
-            "movd      -4(%0, %2), %%mm1    \n\t"
+            "movd           %%mm0, -4(%q0)   \n\t"
+            "movd      -4(%q0, %q2), %%mm1    \n\t"
             "punpcklbw      %%mm1, %%mm1    \n\t"
             "punpckhwd      %%mm1, %%mm1    \n\t"
             "punpckhdq      %%mm1, %%mm1    \n\t"
-            "movd           %%mm1, (%0, %2) \n\t"
-            "add               %1, %0       \n\t"
-            "cmp               %3, %0       \n\t"
+            "movd           %%mm1, (%q0, %q2) \n\t"
+            "add               %q1, %q0       \n\t"
+            "cmp               %q3, %q0       \n\t"
             "jb                1b           \n\t"
             : "+r"(ptr)
             : "r"((x86_reg)wrap), "r"((x86_reg)width), "r"(ptr + wrap * height)
@@ -330,13 +330,13 @@ void ff_draw_edges_mmx(uint8_t *buf, int wrap, int width, int height,
             ptr = buf - (i + 1) * wrap - w;
             __asm__ volatile (
                 "1:                             \n\t"
-                "movq (%1, %0), %%mm0           \n\t"
-                "movq    %%mm0, (%0)            \n\t"
-                "movq    %%mm0, (%0, %2)        \n\t"
-                "movq    %%mm0, (%0, %2, 2)     \n\t"
-                "movq    %%mm0, (%0, %3)        \n\t"
-                "add        $8, %0              \n\t"
-                "cmp        %4, %0              \n\t"
+                "movq (%q1, %q0), %%mm0           \n\t"
+                "movq    %%mm0, (%q0)            \n\t"
+                "movq    %%mm0, (%q0, %q2)        \n\t"
+                "movq    %%mm0, (%q0, %q2, 2)     \n\t"
+                "movq    %%mm0, (%q0, %q3)        \n\t"
+                "add        $8, %q0              \n\t"
+                "cmp        %q4, %q0              \n\t"
                 "jb         1b                  \n\t"
                 : "+r"(ptr)
                 : "r"((x86_reg)buf - (x86_reg)ptr - w), "r"((x86_reg) -wrap),
@@ -350,13 +350,13 @@ void ff_draw_edges_mmx(uint8_t *buf, int wrap, int width, int height,
             ptr = last_line + (i + 1) * wrap - w;
             __asm__ volatile (
                 "1:                             \n\t"
-                "movq (%1, %0), %%mm0           \n\t"
-                "movq    %%mm0, (%0)            \n\t"
-                "movq    %%mm0, (%0, %2)        \n\t"
-                "movq    %%mm0, (%0, %2, 2)     \n\t"
-                "movq    %%mm0, (%0, %3)        \n\t"
-                "add        $8, %0              \n\t"
-                "cmp        %4, %0              \n\t"
+                "movq (%q1, %q0), %%mm0           \n\t"
+                "movq    %%mm0, (%q0)            \n\t"
+                "movq    %%mm0, (%q0, %q2)        \n\t"
+                "movq    %%mm0, (%q0, %q2, 2)     \n\t"
+                "movq    %%mm0, (%q0, %q3)        \n\t"
+                "add        $8, %q0              \n\t"
+                "cmp        %q4, %q0              \n\t"
                 "jb         1b                  \n\t"
                 : "+r"(ptr)
                 : "r"((x86_reg)last_line - (x86_reg)ptr - w),
@@ -422,7 +422,7 @@ static av_always_inline void gmc(uint8_t *dst, uint8_t *src,
     }
 
     __asm__ volatile (
-        "movd         %0, %%mm6         \n\t"
+        "movd         %q0, %%mm6         \n\t"
         "pxor      %%mm7, %%mm7         \n\t"
         "punpcklwd %%mm6, %%mm6         \n\t"
         "punpcklwd %%mm6, %%mm6         \n\t"
@@ -441,12 +441,12 @@ static av_always_inline void gmc(uint8_t *dst, uint8_t *src,
 
         for (y = 0; y < h; y++) {
             __asm__ volatile (
-                "movq      %0, %%mm4    \n\t"
-                "movq      %1, %%mm5    \n\t"
-                "paddw     %2, %%mm4    \n\t"
-                "paddw     %3, %%mm5    \n\t"
-                "movq   %%mm4, %0       \n\t"
-                "movq   %%mm5, %1       \n\t"
+                "movq      %q0, %%mm4    \n\t"
+                "movq      %q1, %%mm5    \n\t"
+                "paddw     %q2, %%mm4    \n\t"
+                "paddw     %q3, %%mm5    \n\t"
+                "movq   %%mm4, %q0       \n\t"
+                "movq   %%mm5, %q1       \n\t"
                 "psrlw    $12, %%mm4    \n\t"
                 "psrlw    $12, %%mm5    \n\t"
                 : "+m"(*dx4), "+m"(*dy4)
@@ -465,27 +465,27 @@ static av_always_inline void gmc(uint8_t *dst, uint8_t *src,
                 "pmullw    %%mm5, %%mm2 \n\t" // (s - dx) * dy
                 "pmullw    %%mm4, %%mm1 \n\t" // dx * (s - dy)
 
-                "movd         %4, %%mm5 \n\t"
-                "movd         %3, %%mm4 \n\t"
+                "movd         %q4, %%mm5 \n\t"
+                "movd         %q3, %%mm4 \n\t"
                 "punpcklbw %%mm7, %%mm5 \n\t"
                 "punpcklbw %%mm7, %%mm4 \n\t"
                 "pmullw    %%mm5, %%mm3 \n\t" // src[1, 1] * dx * dy
                 "pmullw    %%mm4, %%mm2 \n\t" // src[0, 1] * (s - dx) * dy
 
-                "movd         %2, %%mm5 \n\t"
-                "movd         %1, %%mm4 \n\t"
+                "movd         %q2, %%mm5 \n\t"
+                "movd         %q1, %%mm4 \n\t"
                 "punpcklbw %%mm7, %%mm5 \n\t"
                 "punpcklbw %%mm7, %%mm4 \n\t"
                 "pmullw    %%mm5, %%mm1 \n\t" // src[1, 0] * dx * (s - dy)
                 "pmullw    %%mm4, %%mm0 \n\t" // src[0, 0] * (s - dx) * (s - dy)
-                "paddw        %5, %%mm1 \n\t"
+                "paddw        %q5, %%mm1 \n\t"
                 "paddw     %%mm3, %%mm2 \n\t"
                 "paddw     %%mm1, %%mm0 \n\t"
                 "paddw     %%mm2, %%mm0 \n\t"
 
-                "psrlw        %6, %%mm0 \n\t"
+                "psrlw        %q6, %%mm0 \n\t"
                 "packuswb  %%mm0, %%mm0 \n\t"
-                "movd      %%mm0, %0    \n\t"
+                "movd      %%mm0, %q0    \n\t"
 
                 : "=m"(dst[x + y * stride])
                 : "m"(src[0]), "m"(src[1]),
@@ -605,15 +605,15 @@ void ff_vector_clipf_sse(float *dst, const float *src,
 {
     x86_reg i = (len - 16) * 4;
     __asm__ volatile (
-        "movss          %3, %%xmm4      \n\t"
-        "movss          %4, %%xmm5      \n\t"
+        "movss          %q3, %%xmm4      \n\t"
+        "movss          %q4, %%xmm5      \n\t"
         "shufps $0, %%xmm4, %%xmm4      \n\t"
         "shufps $0, %%xmm5, %%xmm5      \n\t"
         "1:                             \n\t"
-        "movaps   (%2, %0), %%xmm0      \n\t" // 3/1 on intel
-        "movaps 16(%2, %0), %%xmm1      \n\t"
-        "movaps 32(%2, %0), %%xmm2      \n\t"
-        "movaps 48(%2, %0), %%xmm3      \n\t"
+        "movaps   (%q2, %q0), %%xmm0      \n\t" // 3/1 on intel
+        "movaps 16(%q2, %q0), %%xmm1      \n\t"
+        "movaps 32(%q2, %q0), %%xmm2      \n\t"
+        "movaps 48(%q2, %q0), %%xmm3      \n\t"
         "maxps      %%xmm4, %%xmm0      \n\t"
         "maxps      %%xmm4, %%xmm1      \n\t"
         "maxps      %%xmm4, %%xmm2      \n\t"
@@ -622,11 +622,11 @@ void ff_vector_clipf_sse(float *dst, const float *src,
         "minps      %%xmm5, %%xmm1      \n\t"
         "minps      %%xmm5, %%xmm2      \n\t"
         "minps      %%xmm5, %%xmm3      \n\t"
-        "movaps     %%xmm0,   (%1, %0)  \n\t"
-        "movaps     %%xmm1, 16(%1, %0)  \n\t"
-        "movaps     %%xmm2, 32(%1, %0)  \n\t"
-        "movaps     %%xmm3, 48(%1, %0)  \n\t"
-        "sub           $64, %0          \n\t"
+        "movaps     %%xmm0,   (%q1, %q0)  \n\t"
+        "movaps     %%xmm1, 16(%q1, %q0)  \n\t"
+        "movaps     %%xmm2, 32(%q1, %q0)  \n\t"
+        "movaps     %%xmm3, 48(%q1, %q0)  \n\t"
+        "sub           $64, %q0          \n\t"
         "jge            1b              \n\t"
         : "+&r"(i)
         : "r"(dst), "r"(src), "m"(min), "m"(max)
diff --git a/libavcodec/x86/dsputil_qns_template.c b/libavcodec/x86/dsputil_qns_template.c
index bde6b0a..12c897c 100644
--- a/libavcodec/x86/dsputil_qns_template.c
+++ b/libavcodec/x86/dsputil_qns_template.c
@@ -1,4 +1,5 @@
 /*
+ * m
  * DSP utils : QNS functions are compiled 3 times for mmx/3dnow/ssse3
  * Copyright (c) 2004 Michael Niedermayer
  *
@@ -34,34 +35,35 @@ static int DEF(try_8x8basis)(int16_t rem[64], int16_t weight[64], int16_t basis[
     SET_RND(mm6);
     __asm__ volatile(
         "pxor %%mm7, %%mm7              \n\t"
-        "movd  %4, %%mm5                \n\t"
+        "movd  %q4, %%mm5                \n\t"
         "punpcklwd %%mm5, %%mm5         \n\t"
         "punpcklwd %%mm5, %%mm5         \n\t"
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq  (%1, %0), %%mm0          \n\t"
-        "movq  8(%1, %0), %%mm1         \n\t"
+        "naclmovq1  \"(%q1, %q0)\", %%mm0          \n\t"
+        "naclmovq1  \"8(%q1, %q0)\", %%mm1         \n\t"
         PMULHRW(%%mm0, %%mm1, %%mm5, %%mm6)
-        "paddw (%2, %0), %%mm0          \n\t"
-        "paddw 8(%2, %0), %%mm1         \n\t"
+        "paddw (%q2, %q0), %%mm0          \n\t"
+        "paddw 8(%q2, %q0), %%mm1         \n\t"
         "psraw $6, %%mm0                \n\t"
         "psraw $6, %%mm1                \n\t"
-        "pmullw (%3, %0), %%mm0         \n\t"
-        "pmullw 8(%3, %0), %%mm1        \n\t"
+        "pmullw (%q3, %q0), %%mm0         \n\t"
+        "pmullw 8(%q3, %q0), %%mm1        \n\t"
         "pmaddwd %%mm0, %%mm0           \n\t"
         "pmaddwd %%mm1, %%mm1           \n\t"
         "paddd %%mm1, %%mm0             \n\t"
         "psrld $4, %%mm0                \n\t"
         "paddd %%mm0, %%mm7             \n\t"
-        "add $16, %0                    \n\t"
-        "cmp $128, %0                   \n\t" //FIXME optimize & bench
+        "add $16, %q0                    \n\t"
+        "cmp $128, %q0                   \n\t" //FIXME optimize & bench
         " jb 1b                         \n\t"
         PHADDD(%%mm7, %%mm6)
         "psrld $2, %%mm7                \n\t"
-        "movd %%mm7, %0                 \n\t"
+        "movd %%mm7, %q0                 \n\t"
 
         : "+r" (i)
         : "r"(basis), "r"(rem), "r"(weight), "g"(scale)
+            : "%r14"
     );
     return i;
 }
@@ -74,24 +76,25 @@ static void DEF(add_8x8basis)(int16_t rem[64], int16_t basis[64], int scale)
         scale<<= 16 + SCALE_OFFSET - BASIS_SHIFT + RECON_SHIFT;
         SET_RND(mm6);
         __asm__ volatile(
-                "movd  %3, %%mm5        \n\t"
+                "movd  %q3, %%mm5        \n\t"
                 "punpcklwd %%mm5, %%mm5 \n\t"
                 "punpcklwd %%mm5, %%mm5 \n\t"
                 ".p2align 4             \n\t"
                 "1:                     \n\t"
-                "movq  (%1, %0), %%mm0  \n\t"
-                "movq  8(%1, %0), %%mm1 \n\t"
+                "naclmovq1  \"(%q1, %q0)\", %%mm0  \n\t"
+                "naclmovq1  \"8(%q1, %q0)\", %%mm1 \n\t"
                 PMULHRW(%%mm0, %%mm1, %%mm5, %%mm6)
-                "paddw (%2, %0), %%mm0  \n\t"
-                "paddw 8(%2, %0), %%mm1 \n\t"
-                "movq %%mm0, (%2, %0)   \n\t"
-                "movq %%mm1, 8(%2, %0)  \n\t"
-                "add $16, %0            \n\t"
-                "cmp $128, %0           \n\t" // FIXME optimize & bench
+                "paddw (%q2, %q0), %%mm0  \n\t"
+                "paddw 8(%q2, %q0), %%mm1 \n\t"
+                "naclmovq2 %%mm0, \"(%q2, %q0)\"   \n\t"
+                "naclmovq2 %%mm1, \"8(%q2, %q0)\"  \n\t"
+                "add $16, %q0            \n\t"
+                "cmp $128, %q0           \n\t" // FIXME optimize & bench
                 " jb 1b                 \n\t"
 
                 : "+r" (i)
                 : "r"(basis), "r"(rem), "g"(scale)
+                : "%r14"
         );
     }else{
         for(i=0; i<8*8; i++){
diff --git a/libavcodec/x86/dsputilenc_mmx.c b/libavcodec/x86/dsputilenc_mmx.c
index 6205577..ddc2f86 100644
--- a/libavcodec/x86/dsputilenc_mmx.c
+++ b/libavcodec/x86/dsputilenc_mmx.c
@@ -48,10 +48,10 @@ static int sse8_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "pxor %%mm0,%%mm0\n"      /* mm0 = 0 */
       "pxor %%mm7,%%mm7\n"      /* mm7 holds the sum */
       "1:\n"
-      "movq (%0),%%mm1\n"       /* mm1 = pix1[0][0-7] */
-      "movq (%1),%%mm2\n"       /* mm2 = pix2[0][0-7] */
-      "movq (%0,%3),%%mm3\n"    /* mm3 = pix1[1][0-7] */
-      "movq (%1,%3),%%mm4\n"    /* mm4 = pix2[1][0-7] */
+      "movq (%q0),%%mm1\n"       /* mm1 = pix1[0][0-7] */
+      "movq (%q1),%%mm2\n"       /* mm2 = pix2[0][0-7] */
+      "movq (%q0,%q3),%%mm3\n"    /* mm3 = pix1[1][0-7] */
+      "movq (%q1,%q3),%%mm4\n"    /* mm4 = pix2[1][0-7] */
 
       /* todo: mm1-mm2, mm3-mm4 */
       /* algo: subtract mm1 from mm2 with saturation and vice versa */
@@ -80,8 +80,8 @@ static int sse8_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "pmaddwd %%mm1,%%mm1\n"
       "pmaddwd %%mm3,%%mm3\n"
 
-      "lea (%0,%3,2), %0\n"     /* pix1 += 2*line_size */
-      "lea (%1,%3,2), %1\n"     /* pix2 += 2*line_size */
+      "lea (%q0,%q3,2), %q0\n"     /* pix1 += 2*line_size */
+      "lea (%q1,%q3,2), %q1\n"     /* pix2 += 2*line_size */
 
       "paddd %%mm2,%%mm1\n"
       "paddd %%mm4,%%mm3\n"
@@ -94,7 +94,7 @@ static int sse8_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "movq %%mm7,%%mm1\n"
       "psrlq $32, %%mm7\n"      /* shift hi dword to lo */
       "paddd %%mm7,%%mm1\n"
-      "movd %%mm1,%2\n"
+      "movd %%mm1,%q2\n"
       : "+r" (pix1), "+r" (pix2), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -108,10 +108,10 @@ static int sse16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "pxor %%mm0,%%mm0\n"      /* mm0 = 0 */
       "pxor %%mm7,%%mm7\n"      /* mm7 holds the sum */
       "1:\n"
-      "movq (%0),%%mm1\n"       /* mm1 = pix1[0-7] */
-      "movq (%1),%%mm2\n"       /* mm2 = pix2[0-7] */
-      "movq 8(%0),%%mm3\n"      /* mm3 = pix1[8-15] */
-      "movq 8(%1),%%mm4\n"      /* mm4 = pix2[8-15] */
+      "movq (%q0),%%mm1\n"       /* mm1 = pix1[0-7] */
+      "movq (%q1),%%mm2\n"       /* mm2 = pix2[0-7] */
+      "movq 8(%q0),%%mm3\n"      /* mm3 = pix1[8-15] */
+      "movq 8(%q1),%%mm4\n"      /* mm4 = pix2[8-15] */
 
       /* todo: mm1-mm2, mm3-mm4 */
       /* algo: subtract mm1 from mm2 with saturation and vice versa */
@@ -140,8 +140,8 @@ static int sse16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "pmaddwd %%mm1,%%mm1\n"
       "pmaddwd %%mm3,%%mm3\n"
 
-      "add %3,%0\n"
-      "add %3,%1\n"
+      "add %q3,%q0\n"
+      "add %q3,%q1\n"
 
       "paddd %%mm2,%%mm1\n"
       "paddd %%mm4,%%mm3\n"
@@ -154,7 +154,7 @@ static int sse16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, int
       "movq %%mm7,%%mm1\n"
       "psrlq $32, %%mm7\n"      /* shift hi dword to lo */
       "paddd %%mm7,%%mm1\n"
-      "movd %%mm1,%2\n"
+      "movd %%mm1,%q2\n"
       : "+r" (pix1), "+r" (pix2), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -168,7 +168,7 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "pxor %%mm7,%%mm7\n"
       "pxor %%mm6,%%mm6\n"
 
-      "movq (%0),%%mm0\n"
+      "movq (%q0),%%mm0\n"
       "movq %%mm0, %%mm1\n"
       "psllq $8, %%mm0\n"
       "psrlq $8, %%mm1\n"
@@ -182,9 +182,9 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "psubw %%mm1, %%mm0\n"
       "psubw %%mm3, %%mm2\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
 
-      "movq (%0),%%mm4\n"
+      "movq (%q0),%%mm4\n"
       "movq %%mm4, %%mm1\n"
       "psllq $8, %%mm4\n"
       "psrlq $8, %%mm1\n"
@@ -210,10 +210,10 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm0, %%mm2\n"
       "paddw %%mm2, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
       "1:\n"
 
-      "movq (%0),%%mm0\n"
+      "movq (%q0),%%mm0\n"
       "movq %%mm0, %%mm1\n"
       "psllq $8, %%mm0\n"
       "psrlq $8, %%mm1\n"
@@ -239,9 +239,9 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm4, %%mm5\n"
       "paddw %%mm5, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
 
-      "movq (%0),%%mm4\n"
+      "movq (%q0),%%mm4\n"
       "movq %%mm4, %%mm1\n"
       "psllq $8, %%mm4\n"
       "psrlq $8, %%mm1\n"
@@ -267,7 +267,7 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm0, %%mm2\n"
       "paddw %%mm2, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
       "subl $2, %%ecx\n"
       " jnz 1b\n"
 
@@ -279,7 +279,7 @@ static int hf_noise8_mmx(uint8_t * pix1, int line_size, int h) {
       "movq %%mm6,%%mm0\n"
       "psrlq $32, %%mm6\n"
       "paddd %%mm6,%%mm0\n"
-      "movd %%mm0,%1\n"
+      "movd %%mm0,%q1\n"
       : "+r" (pix1), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "g" (h-2)
       : "%ecx");
@@ -294,8 +294,8 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "pxor %%mm7,%%mm7\n"
       "pxor %%mm6,%%mm6\n"
 
-      "movq (%0),%%mm0\n"
-      "movq 1(%0),%%mm1\n"
+      "movq (%q0),%%mm0\n"
+      "movq 1(%q0),%%mm1\n"
       "movq %%mm0, %%mm2\n"
       "movq %%mm1, %%mm3\n"
       "punpcklbw %%mm7,%%mm0\n"
@@ -305,10 +305,10 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "psubw %%mm1, %%mm0\n"
       "psubw %%mm3, %%mm2\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
 
-      "movq (%0),%%mm4\n"
-      "movq 1(%0),%%mm1\n"
+      "movq (%q0),%%mm4\n"
+      "movq 1(%q0),%%mm1\n"
       "movq %%mm4, %%mm5\n"
       "movq %%mm1, %%mm3\n"
       "punpcklbw %%mm7,%%mm4\n"
@@ -330,11 +330,11 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm0, %%mm2\n"
       "paddw %%mm2, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
       "1:\n"
 
-      "movq (%0),%%mm0\n"
-      "movq 1(%0),%%mm1\n"
+      "movq (%q0),%%mm0\n"
+      "movq 1(%q0),%%mm1\n"
       "movq %%mm0, %%mm2\n"
       "movq %%mm1, %%mm3\n"
       "punpcklbw %%mm7,%%mm0\n"
@@ -356,10 +356,10 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm4, %%mm5\n"
       "paddw %%mm5, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
 
-      "movq (%0),%%mm4\n"
-      "movq 1(%0),%%mm1\n"
+      "movq (%q0),%%mm4\n"
+      "movq 1(%q0),%%mm1\n"
       "movq %%mm4, %%mm5\n"
       "movq %%mm1, %%mm3\n"
       "punpcklbw %%mm7,%%mm4\n"
@@ -381,7 +381,7 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "paddw %%mm0, %%mm2\n"
       "paddw %%mm2, %%mm6\n"
 
-      "add %2,%0\n"
+      "add %q2,%q0\n"
       "subl $2, %%ecx\n"
       " jnz 1b\n"
 
@@ -393,7 +393,7 @@ static int hf_noise16_mmx(uint8_t * pix1, int line_size, int h) {
       "movq %%mm6,%%mm0\n"
       "psrlq $32, %%mm6\n"
       "paddd %%mm6,%%mm0\n"
-      "movd %%mm0,%1\n"
+      "movd %%mm0,%q1\n"
       : "+r" (pix1), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "g" (h-2)
       : "%ecx");
@@ -428,9 +428,9 @@ static int vsad_intra16_mmx(void *v, uint8_t * pix, uint8_t * dummy, int line_si
     av_assert2((line_size &7) ==0);
 
 #define SUM(in0, in1, out0, out1) \
-      "movq (%0), %%mm2\n"\
-      "movq 8(%0), %%mm3\n"\
-      "add %2,%0\n"\
+      "movq (%q0), %%mm2\n"\
+      "movq 8(%q0), %%mm3\n"\
+      "add %q2,%q0\n"\
       "movq %%mm2, " #out0 "\n"\
       "movq %%mm3, " #out1 "\n"\
       "psubusb " #in0 ", %%mm2\n"\
@@ -455,9 +455,9 @@ static int vsad_intra16_mmx(void *v, uint8_t * pix, uint8_t * dummy, int line_si
       "movl %3,%%ecx\n"
       "pxor %%mm6,%%mm6\n"
       "pxor %%mm7,%%mm7\n"
-      "movq (%0),%%mm0\n"
-      "movq 8(%0),%%mm1\n"
-      "add %2,%0\n"
+      "movq (%q0),%%mm0\n"
+      "movq 8(%q0),%%mm1\n"
+      "add %q2,%q0\n"
       "jmp 2f\n"
       "1:\n"
 
@@ -474,7 +474,7 @@ static int vsad_intra16_mmx(void *v, uint8_t * pix, uint8_t * dummy, int line_si
       "movq %%mm0,%%mm6\n"
       "psrlq $16, %%mm0\n"
       "paddw %%mm6,%%mm0\n"
-      "movd %%mm0,%1\n"
+      "movd %%mm0,%q1\n"
       : "+r" (pix), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -491,9 +491,9 @@ static int vsad_intra16_mmxext(void *v, uint8_t *pix, uint8_t *dummy,
     av_assert2((line_size &7) ==0);
 
 #define SUM(in0, in1, out0, out1) \
-      "movq (%0), " #out0 "\n"\
-      "movq 8(%0), " #out1 "\n"\
-      "add %2,%0\n"\
+      "movq (%q0), " #out0 "\n"\
+      "movq 8(%q0), " #out1 "\n"\
+      "add %q2,%q0\n"\
       "psadbw " #out0 ", " #in0 "\n"\
       "psadbw " #out1 ", " #in1 "\n"\
       "paddw " #in1 ", " #in0 "\n"\
@@ -503,9 +503,9 @@ static int vsad_intra16_mmxext(void *v, uint8_t *pix, uint8_t *dummy,
       "movl %3,%%ecx\n"
       "pxor %%mm6,%%mm6\n"
       "pxor %%mm7,%%mm7\n"
-      "movq (%0),%%mm0\n"
-      "movq 8(%0),%%mm1\n"
-      "add %2,%0\n"
+      "movq (%q0),%%mm0\n"
+      "movq 8(%q0),%%mm1\n"
+      "add %q2,%q0\n"
       "jmp 2f\n"
       "1:\n"
 
@@ -516,7 +516,7 @@ static int vsad_intra16_mmxext(void *v, uint8_t *pix, uint8_t *dummy,
       "subl $2, %%ecx\n"
       "jnz 1b\n"
 
-      "movd %%mm6,%1\n"
+      "movd %%mm6,%q1\n"
       : "+r" (pix), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -532,12 +532,12 @@ static int vsad16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, in
     av_assert2((line_size &7) ==0);
 
 #define SUM(in0, in1, out0, out1) \
-      "movq (%0),%%mm2\n"\
-      "movq (%1)," #out0 "\n"\
-      "movq 8(%0),%%mm3\n"\
-      "movq 8(%1)," #out1 "\n"\
-      "add %3,%0\n"\
-      "add %3,%1\n"\
+      "movq (%q0),%%mm2\n"\
+      "movq (%q1)," #out0 "\n"\
+      "movq 8(%q0),%%mm3\n"\
+      "movq 8(%q1)," #out1 "\n"\
+      "add %q3,%q0\n"\
+      "add %q3,%q1\n"\
       "psubb " #out0 ", %%mm2\n"\
       "psubb " #out1 ", %%mm3\n"\
       "pxor %%mm7, %%mm2\n"\
@@ -568,12 +568,12 @@ static int vsad16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, in
       "pcmpeqw %%mm7,%%mm7\n"
       "psllw $15, %%mm7\n"
       "packsswb %%mm7, %%mm7\n"
-      "movq (%0),%%mm0\n"
-      "movq (%1),%%mm2\n"
-      "movq 8(%0),%%mm1\n"
-      "movq 8(%1),%%mm3\n"
-      "add %3,%0\n"
-      "add %3,%1\n"
+      "movq (%q0),%%mm0\n"
+      "movq (%q1),%%mm2\n"
+      "movq 8(%q0),%%mm1\n"
+      "movq 8(%q1),%%mm3\n"
+      "add %q3,%q0\n"
+      "add %q3,%q1\n"
       "psubb %%mm2, %%mm0\n"
       "psubb %%mm3, %%mm1\n"
       "pxor %%mm7, %%mm0\n"
@@ -594,7 +594,7 @@ static int vsad16_mmx(void *v, uint8_t * pix1, uint8_t * pix2, int line_size, in
       "movq %%mm0,%%mm6\n"
       "psrlq $16, %%mm0\n"
       "paddw %%mm6,%%mm0\n"
-      "movd %%mm0,%2\n"
+      "movd %%mm0,%q2\n"
       : "+r" (pix1), "+r" (pix2), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -612,12 +612,12 @@ static int vsad16_mmxext(void *v, uint8_t *pix1, uint8_t *pix2,
     av_assert2((line_size &7) ==0);
 
 #define SUM(in0, in1, out0, out1) \
-      "movq (%0)," #out0 "\n"\
-      "movq (%1),%%mm2\n"\
-      "movq 8(%0)," #out1 "\n"\
-      "movq 8(%1),%%mm3\n"\
-      "add %3,%0\n"\
-      "add %3,%1\n"\
+      "movq (%q0)," #out0 "\n"\
+      "movq (%q1),%%mm2\n"\
+      "movq 8(%q0)," #out1 "\n"\
+      "movq 8(%q1),%%mm3\n"\
+      "add %q3,%q0\n"\
+      "add %q3,%q1\n"\
       "psubb %%mm2, " #out0 "\n"\
       "psubb %%mm3, " #out1 "\n"\
       "pxor %%mm7, " #out0 "\n"\
@@ -633,12 +633,12 @@ static int vsad16_mmxext(void *v, uint8_t *pix1, uint8_t *pix2,
       "pcmpeqw %%mm7,%%mm7\n"
       "psllw $15, %%mm7\n"
       "packsswb %%mm7, %%mm7\n"
-      "movq (%0),%%mm0\n"
-      "movq (%1),%%mm2\n"
-      "movq 8(%0),%%mm1\n"
-      "movq 8(%1),%%mm3\n"
-      "add %3,%0\n"
-      "add %3,%1\n"
+      "movq (%q0),%%mm0\n"
+      "movq (%q1),%%mm2\n"
+      "movq 8(%q0),%%mm1\n"
+      "movq 8(%q1),%%mm3\n"
+      "add %q3,%q0\n"
+      "add %q3,%q1\n"
       "psubb %%mm2, %%mm0\n"
       "psubb %%mm3, %%mm1\n"
       "pxor %%mm7, %%mm0\n"
@@ -653,7 +653,7 @@ static int vsad16_mmxext(void *v, uint8_t *pix1, uint8_t *pix2,
       "subl $2, %%ecx\n"
       "jnz 1b\n"
 
-      "movd %%mm6,%2\n"
+      "movd %%mm6,%q2\n"
       : "+r" (pix1), "+r" (pix2), "=r"(tmp)
       : "r" ((x86_reg)line_size) , "m" (h)
       : "%ecx");
@@ -666,16 +666,16 @@ static void diff_bytes_mmx(uint8_t *dst, const uint8_t *src1, const uint8_t *src
     if(w>=16)
     __asm__ volatile(
         "1:                             \n\t"
-        "movq  (%2, %0), %%mm0          \n\t"
-        "movq  (%1, %0), %%mm1          \n\t"
+        "movq  (%q2, %q0), %%mm0          \n\t"
+        "movq  (%q1, %q0), %%mm1          \n\t"
         "psubb %%mm0, %%mm1             \n\t"
-        "movq %%mm1, (%3, %0)           \n\t"
-        "movq 8(%2, %0), %%mm0          \n\t"
-        "movq 8(%1, %0), %%mm1          \n\t"
+        "movq %%mm1, (%q3, %q0)           \n\t"
+        "movq 8(%q2, %q0), %%mm0          \n\t"
+        "movq 8(%q1, %q0), %%mm1          \n\t"
         "psubb %%mm0, %%mm1             \n\t"
-        "movq %%mm1, 8(%3, %0)          \n\t"
-        "add $16, %0                    \n\t"
-        "cmp %4, %0                     \n\t"
+        "movq %%mm1, 8(%q3, %q0)          \n\t"
+        "add $16, %q0                    \n\t"
+        "cmp %q4, %q0                     \n\t"
         " jb 1b                         \n\t"
         : "+r" (i)
         : "r"(src1), "r"(src2), "r"(dst), "r"((x86_reg)w-15)
@@ -692,12 +692,12 @@ static void sub_hfyu_median_prediction_mmxext(uint8_t *dst, const uint8_t *src1,
     uint8_t l, lt;
 
     __asm__ volatile(
-        "movq  (%1, %0), %%mm0          \n\t" // LT
+        "movq  (%q1, %q0), %%mm0          \n\t" // LT
         "psllq $8, %%mm0                \n\t"
         "1:                             \n\t"
-        "movq  (%1, %0), %%mm1          \n\t" // T
-        "movq  -1(%2, %0), %%mm2        \n\t" // L
-        "movq  (%2, %0), %%mm3          \n\t" // X
+        "movq  (%q1, %q0), %%mm1          \n\t" // T
+        "movq  -1(%q2, %q0), %%mm2        \n\t" // L
+        "movq  (%q2, %q0), %%mm3          \n\t" // X
         "movq %%mm2, %%mm4              \n\t" // L
         "psubb %%mm0, %%mm2             \n\t"
         "paddb %%mm1, %%mm2             \n\t" // L + T - LT
@@ -707,10 +707,10 @@ static void sub_hfyu_median_prediction_mmxext(uint8_t *dst, const uint8_t *src1,
         "pminub %%mm2, %%mm4            \n\t"
         "pmaxub %%mm1, %%mm4            \n\t"
         "psubb %%mm4, %%mm3             \n\t" // dst - pred
-        "movq %%mm3, (%3, %0)           \n\t"
-        "add $8, %0                     \n\t"
-        "movq -1(%1, %0), %%mm0         \n\t" // LT
-        "cmp %4, %0                     \n\t"
+        "movq %%mm3, (%q3, %q0)           \n\t"
+        "add $8, %q0                     \n\t"
+        "movq -1(%q1, %q0), %%mm0         \n\t" // LT
+        "cmp %q4, %q0                     \n\t"
         " jb 1b                         \n\t"
         : "+r" (i)
         : "r"(src1), "r"(src2), "r"(dst), "r"((x86_reg)w)
@@ -772,10 +772,10 @@ static void sub_hfyu_median_prediction_mmxext(uint8_t *dst, const uint8_t *src1,
     "movd "#a", "#dst"                \n\t"\
 
 #define DCT_SAD4(m,mm,o)\
-    "mov"#m" "#o"+ 0(%1), "#mm"2      \n\t"\
-    "mov"#m" "#o"+16(%1), "#mm"3      \n\t"\
-    "mov"#m" "#o"+32(%1), "#mm"4      \n\t"\
-    "mov"#m" "#o"+48(%1), "#mm"5      \n\t"\
+    "mov"#m" "#o"+ 0(%q1), "#mm"2      \n\t"\
+    "mov"#m" "#o"+16(%q1), "#mm"3      \n\t"\
+    "mov"#m" "#o"+32(%q1), "#mm"4      \n\t"\
+    "mov"#m" "#o"+48(%q1), "#mm"5      \n\t"\
     MMABS_SUM(mm##2, mm##6, mm##0)\
     MMABS_SUM(mm##3, mm##7, mm##1)\
     MMABS_SUM(mm##4, mm##6, mm##0)\
@@ -789,7 +789,7 @@ static void sub_hfyu_median_prediction_mmxext(uint8_t *dst, const uint8_t *src1,
     DCT_SAD4(q, %%mm, 64)\
     DCT_SAD4(q, %%mm, 72)\
     "paddusw %%mm1, %%mm0             \n\t"\
-    HSUM(%%mm0, %%mm1, %0)
+    HSUM(%%mm0, %%mm1, %q0)
 
 #define DCT_SAD_SSE2\
     "pxor %%xmm0, %%xmm0              \n\t"\
@@ -797,7 +797,7 @@ static void sub_hfyu_median_prediction_mmxext(uint8_t *dst, const uint8_t *src1,
     DCT_SAD4(dqa, %%xmm, 0)\
     DCT_SAD4(dqa, %%xmm, 64)\
     "paddusw %%xmm1, %%xmm0           \n\t"\
-    HSUM(%%xmm0, %%xmm1, %0)
+    HSUM(%%xmm0, %%xmm1, %q0)
 
 #define DCT_SAD_FUNC(cpu) \
 static int sum_abs_dctelem_##cpu(int16_t *block){\
@@ -842,10 +842,10 @@ static int ssd_int8_vs_int16_mmx(const int8_t *pix1, const int16_t *pix2, int si
     __asm__ volatile(
         "pxor %%mm4, %%mm4 \n"
         "1: \n"
-        "sub $8, %0 \n"
-        "movq (%2,%0), %%mm2 \n"
-        "movq (%3,%0,2), %%mm0 \n"
-        "movq 8(%3,%0,2), %%mm1 \n"
+        "sub $8, %q0 \n"
+        "movq (%q2,%q0), %%mm2 \n"
+        "movq (%q3,%q0,2), %%mm0 \n"
+        "movq 8(%q3,%q0,2), %%mm1 \n"
         "punpckhbw %%mm2, %%mm3 \n"
         "punpcklbw %%mm2, %%mm2 \n"
         "psraw $8, %%mm3 \n"
@@ -860,7 +860,7 @@ static int ssd_int8_vs_int16_mmx(const int8_t *pix1, const int16_t *pix2, int si
         "movq %%mm4, %%mm3 \n"
         "psrlq $32, %%mm3 \n"
         "paddd %%mm3, %%mm4 \n"
-        "movd %%mm4, %1 \n"
+        "movd %%mm4, %q1 \n"
         :"+r"(i), "=r"(sum)
         :"r"(pix1), "r"(pix2)
     );
diff --git a/libavcodec/x86/fdct.c b/libavcodec/x86/fdct.c
index 11a13bb..78ed2ba 100644
--- a/libavcodec/x86/fdct.c
+++ b/libavcodec/x86/fdct.c
@@ -452,25 +452,25 @@ static av_always_inline void fdct_row_mmxext(const int16_t *in, int16_t *out,
         "movq      %%mm0, %%mm2 \n\t"
         "punpckldq %%mm1, %%mm0 \n\t"
         "punpckhdq %%mm1, %%mm2 \n\t"
-        "movq       (%1), %%mm1 \n\t"
-        "movq      8(%1), %%mm3 \n\t"
-        "movq     16(%1), %%mm4 \n\t"
-        "movq     24(%1), %%mm5 \n\t"
-        "movq     32(%1), %%mm6 \n\t"
-        "movq     40(%1), %%mm7 \n\t"
+        "movq       %%nacl:(%%r15, %q1), %%mm1 \n\t"
+        "movq      %%nacl:8(%%r15, %q1), %%mm3 \n\t"
+        "movq     %%nacl:16(%%r15, %q1), %%mm4 \n\t"
+        "movq     %%nacl:24(%%r15, %q1), %%mm5 \n\t"
+        "movq     %%nacl:32(%%r15, %q1), %%mm6 \n\t"
+        "movq     %%nacl:40(%%r15, %q1), %%mm7 \n\t"
         "pmaddwd   %%mm0, %%mm1 \n\t"
         "pmaddwd   %%mm2, %%mm3 \n\t"
         "pmaddwd   %%mm0, %%mm4 \n\t"
         "pmaddwd   %%mm2, %%mm5 \n\t"
         "pmaddwd   %%mm0, %%mm6 \n\t"
         "pmaddwd   %%mm2, %%mm7 \n\t"
-        "pmaddwd  48(%1), %%mm0 \n\t"
-        "pmaddwd  56(%1), %%mm2 \n\t"
+        "pmaddwd  %%nacl:48(%%r15, %q1), %%mm0 \n\t"
+        "pmaddwd  %%nacl:56(%%r15, %q1), %%mm2 \n\t"
         "paddd     %%mm1, %%mm3 \n\t"
         "paddd     %%mm4, %%mm5 \n\t"
         "paddd     %%mm6, %%mm7 \n\t"
         "paddd     %%mm0, %%mm2 \n\t"
-        "movq       (%2), %%mm0 \n\t"
+        "movq       %%nacl:(%%r15, %q2), %%mm0 \n\t"
         "paddd     %%mm0, %%mm3 \n\t"
         "paddd     %%mm0, %%mm5 \n\t"
         "paddd     %%mm0, %%mm7 \n\t"
@@ -515,13 +515,13 @@ static av_always_inline void fdct_row_mmx(const int16_t *in, int16_t *out, const
         "pmaddwd   %%mm2, %%mm5 \n\t"
         "pmaddwd   %%mm0, %%mm6 \n\t"
         "pmaddwd   %%mm2, %%mm7 \n\t"
-        "pmaddwd  48(%1), %%mm0 \n\t"
-        "pmaddwd  56(%1), %%mm2 \n\t"
+        "pmaddwd  %%nacl:48(%%r15, %q1), %%mm0 \n\t"
+        "pmaddwd  %%nacl:56(%%r15, %q1), %%mm2 \n\t"
         "paddd     %%mm1, %%mm3 \n\t"
         "paddd     %%mm4, %%mm5 \n\t"
         "paddd     %%mm6, %%mm7 \n\t"
         "paddd     %%mm0, %%mm2 \n\t"
-        "movq       (%2), %%mm0 \n\t"
+        "movq       %%nacl:(%%r15, %q2), %%mm0 \n\t"
         "paddd     %%mm0, %%mm3 \n\t"
         "paddd     %%mm0, %%mm5 \n\t"
         "paddd     %%mm0, %%mm7 \n\t"
@@ -532,8 +532,8 @@ static av_always_inline void fdct_row_mmx(const int16_t *in, int16_t *out, const
         "psrad $"S(SHIFT_FRW_ROW)", %%mm2 \n\t"
         "packssdw  %%mm5, %%mm3 \n\t"
         "packssdw  %%mm2, %%mm7 \n\t"
-        "movq      %%mm3, 0(%3) \n\t"
-        "movq      %%mm7, 8(%3) \n\t"
+        "movq      %%mm3, %%nacl:0(%%r15, %q3) \n\t"
+        "movq      %%mm7, %%nacl:8(%%r15, %q3) \n\t"
         :
         : "r" (in), "r" (table), "r" (fdct_r_row), "r" (out));
 }
diff --git a/libavcodec/x86/hpeldsp_rnd_template.c b/libavcodec/x86/hpeldsp_rnd_template.c
index 94e06d8..4b151a1 100644
--- a/libavcodec/x86/hpeldsp_rnd_template.c
+++ b/libavcodec/x86/hpeldsp_rnd_template.c
@@ -32,29 +32,29 @@ static void DEF(put, pixels8_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff_
         "lea    (%3, %3), %%"REG_a"     \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm1            \n\t"
-        "movq   (%1, %3), %%mm2         \n\t"
-        "movq   1(%1, %3), %%mm3        \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm2         \n\t"
+        "naclmovq1   \"1(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm1            \n\t"
-        "movq   (%1, %3), %%mm2         \n\t"
-        "movq   1(%1, %3), %%mm3        \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm2         \n\t"
+        "naclmovq1   \"1(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
         "subl   $4, %0                  \n\t"
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels), "+D"(block)
         :"r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
 
 static void DEF(put, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
@@ -64,43 +64,43 @@ static void DEF(put, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff
         "lea        (%3, %3), %%"REG_a" \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm1            \n\t"
-        "movq   (%1, %3), %%mm2         \n\t"
-        "movq   1(%1, %3), %%mm3        \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm2         \n\t"
+        "naclmovq1   \"1(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
-        "movq   8(%1), %%mm0            \n\t"
-        "movq   9(%1), %%mm1            \n\t"
-        "movq   8(%1, %3), %%mm2        \n\t"
-        "movq   9(%1, %3), %%mm3        \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
+        "movq   %%nacl:8(%%r15, %1), %%mm0            \n\t"
+        "movq   %%nacl:9(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"8(%1, %3)\", %%mm2        \n\t"
+        "naclmovq1   \"9(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, 8(%2)            \n\t"
-        "movq   %%mm5, 8(%2, %3)        \n\t"
+        "movq   %%mm4, %%nacl:8(%%r15, %2)            \n\t"
+        "naclmovq2   %%mm5, \"8(%2, %3)\"        \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm1            \n\t"
-        "movq   (%1, %3), %%mm2         \n\t"
-        "movq   1(%1, %3), %%mm3        \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm2         \n\t"
+        "naclmovq1   \"1(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
-        "movq   8(%1), %%mm0            \n\t"
-        "movq   9(%1), %%mm1            \n\t"
-        "movq   8(%1, %3), %%mm2        \n\t"
-        "movq   9(%1, %3), %%mm3        \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
+        "movq   %%nacl:8(%%r15, %1), %%mm0            \n\t"
+        "movq   %%nacl:9(%%r15, %1), %%mm1            \n\t"
+        "naclmovq1   \"8(%1, %3)\", %%mm2        \n\t"
+        "naclmovq1   \"9(%1, %3)\", %%mm3        \n\t"
         PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)
-        "movq   %%mm4, 8(%2)            \n\t"
-        "movq   %%mm5, 8(%2, %3)        \n\t"
+        "movq   %%mm4, %%nacl:8(%%r15, %2)            \n\t"
+        "naclmovq2   %%mm5, \"8(%2, %3)\"        \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
         "subl   $4, %0                  \n\t"
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels), "+D"(block)
         :"r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
 
 static void DEF(put, pixels8_y2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
@@ -108,28 +108,28 @@ static void DEF(put, pixels8_y2)(uint8_t *block, const uint8_t *pixels, ptrdiff_
     MOVQ_BFE(mm6);
     __asm__ volatile(
         "lea (%3, %3), %%"REG_a"        \n\t"
-        "movq (%1), %%mm0               \n\t"
+        "movq %%nacl:(%%r15, %1), %%mm0               \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1, %3), %%mm1         \n\t"
-        "movq   (%1, %%"REG_a"),%%mm2   \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm1         \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\",%%mm2   \n\t"
         PAVGBP(%%mm1, %%mm0, %%mm4,   %%mm2, %%mm1, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
-        "movq   (%1, %3), %%mm1         \n\t"
-        "movq   (%1, %%"REG_a"),%%mm0   \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm1         \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\",%%mm0   \n\t"
         PAVGBP(%%mm1, %%mm2, %%mm4,   %%mm0, %%mm1, %%mm5)
-        "movq   %%mm4, (%2)             \n\t"
-        "movq   %%mm5, (%2, %3)         \n\t"
+        "movq   %%mm4, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm5, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
         "subl   $4, %0                  \n\t"
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels), "+D"(block)
         :"r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
 
 static void DEF(avg, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)
@@ -152,7 +152,7 @@ static void DEF(avg, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff
             "movq  %%mm0, 8%0           \n\t"
             :"+m"(*block)
             :"m"(*pixels)
-            :"memory");
+            :"memory", "%r14");
         pixels += line_size;
         block += line_size;
     } while (--h);
@@ -163,30 +163,30 @@ static void DEF(avg, pixels8_y2)(uint8_t *block, const uint8_t *pixels, ptrdiff_
     MOVQ_BFE(mm6);
     __asm__ volatile(
         "lea    (%3, %3), %%"REG_a"     \n\t"
-        "movq   (%1), %%mm0             \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1, %3), %%mm1         \n\t"
-        "movq   (%1, %%"REG_a"), %%mm2  \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm1         \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm2  \n\t"
         PAVGBP(%%mm1, %%mm0, %%mm4,   %%mm2, %%mm1, %%mm5)
-        "movq   (%2), %%mm3             \n\t"
+        "movq   %%nacl:(%%r15, %2), %%mm3             \n\t"
         PAVGB_MMX(%%mm3, %%mm4, %%mm0, %%mm6)
-        "movq   (%2, %3), %%mm3         \n\t"
+        "naclmovq1   \"(%2, %3)\", %%mm3         \n\t"
         PAVGB_MMX(%%mm3, %%mm5, %%mm1, %%mm6)
-        "movq   %%mm0, (%2)             \n\t"
-        "movq   %%mm1, (%2, %3)         \n\t"
+        "movq   %%mm0, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm1, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
 
-        "movq   (%1, %3), %%mm1         \n\t"
-        "movq   (%1, %%"REG_a"), %%mm0  \n\t"
+        "naclmovq1   \"(%1, %3)\", %%mm1         \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm0  \n\t"
         PAVGBP(%%mm1, %%mm2, %%mm4,   %%mm0, %%mm1, %%mm5)
-        "movq   (%2), %%mm3             \n\t"
+        "movq   %%nacl:(%%r15, %2), %%mm3             \n\t"
         PAVGB_MMX(%%mm3, %%mm4, %%mm2, %%mm6)
-        "movq   (%2, %3), %%mm3         \n\t"
+        "naclmovq1   \"(%2, %3)\", %%mm3         \n\t"
         PAVGB_MMX(%%mm3, %%mm5, %%mm1, %%mm6)
-        "movq   %%mm2, (%2)             \n\t"
-        "movq   %%mm1, (%2, %3)         \n\t"
+        "movq   %%mm2, %%nacl:(%%r15, %2)             \n\t"
+        "naclmovq2   %%mm1, \"(%2, %3)\"         \n\t"
         "add    %%"REG_a", %1           \n\t"
         "add    %%"REG_a", %2           \n\t"
 
@@ -194,5 +194,5 @@ static void DEF(avg, pixels8_y2)(uint8_t *block, const uint8_t *pixels, ptrdiff_
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels), "+D"(block)
         :"r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
diff --git a/libavcodec/x86/motion_est.c b/libavcodec/x86/motion_est.c
index 5f5d93e..36e32b0 100644
--- a/libavcodec/x86/motion_est.c
+++ b/libavcodec/x86/motion_est.c
@@ -45,15 +45,15 @@ static inline void sad8_1_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
     __asm__ volatile(
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1, %%"REG_a"), %%mm0    \n\t"
-        "movq (%2, %%"REG_a"), %%mm2    \n\t"
-        "movq (%2, %%"REG_a"), %%mm4    \n\t"
-        "add %3, %%"REG_a"              \n\t"
+        "movq (%q1, %%"REG_a"), %%mm0    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm2    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm4    \n\t"
+        "add %q3, %%"REG_a"              \n\t"
         "psubusb %%mm0, %%mm2           \n\t"
         "psubusb %%mm4, %%mm0           \n\t"
-        "movq (%1, %%"REG_a"), %%mm1    \n\t"
-        "movq (%2, %%"REG_a"), %%mm3    \n\t"
-        "movq (%2, %%"REG_a"), %%mm5    \n\t"
+        "movq (%q1, %%"REG_a"), %%mm1    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm3    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm5    \n\t"
         "psubusb %%mm1, %%mm3           \n\t"
         "psubusb %%mm5, %%mm1           \n\t"
         "por %%mm2, %%mm0               \n\t"
@@ -68,7 +68,7 @@ static inline void sad8_1_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
         "paddw %%mm3, %%mm2             \n\t"
         "paddw %%mm2, %%mm0             \n\t"
         "paddw %%mm0, %%mm6             \n\t"
-        "add %3, %%"REG_a"              \n\t"
+        "add %q3, %%"REG_a"              \n\t"
         " js 1b                         \n\t"
         : "+a" (len)
         : "r" (blk1 - len), "r" (blk2 - len), "r" ((x86_reg)stride)
@@ -81,15 +81,15 @@ static inline void sad8_1_mmxext(uint8_t *blk1, uint8_t *blk2,
     __asm__ volatile(
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1), %%mm0               \n\t"
-        "movq (%1, %3), %%mm1           \n\t"
-        "psadbw (%2), %%mm0             \n\t"
-        "psadbw (%2, %3), %%mm1         \n\t"
+        "movq (%q1), %%mm0               \n\t"
+        "movq (%q1, %q3), %%mm1           \n\t"
+        "psadbw (%q2), %%mm0             \n\t"
+        "psadbw (%q2, %q3), %%mm1         \n\t"
         "paddw %%mm0, %%mm6             \n\t"
         "paddw %%mm1, %%mm6             \n\t"
-        "lea (%1,%3,2), %1              \n\t"
-        "lea (%2,%3,2), %2              \n\t"
-        "sub $2, %0                     \n\t"
+        "lea (%q1,%q3,2), %q1              \n\t"
+        "lea (%q2,%q3,2), %q2              \n\t"
+        "sub $2, %q0                     \n\t"
         " jg 1b                         \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2)
         : "r" ((x86_reg)stride)
@@ -103,19 +103,19 @@ static int sad16_sse2(void *v, uint8_t *blk2, uint8_t *blk1, int stride, int h)
         "pxor %%xmm2, %%xmm2            \n\t"
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movdqu (%1), %%xmm0            \n\t"
-        "movdqu (%1, %4), %%xmm1        \n\t"
-        "psadbw (%2), %%xmm0            \n\t"
-        "psadbw (%2, %4), %%xmm1        \n\t"
+        "movdqu (%q1), %%xmm0            \n\t"
+        "movdqu (%q1, %q4), %%xmm1        \n\t"
+        "psadbw (%q2), %%xmm0            \n\t"
+        "psadbw (%q2, %q4), %%xmm1        \n\t"
         "paddw %%xmm0, %%xmm2           \n\t"
         "paddw %%xmm1, %%xmm2           \n\t"
-        "lea (%1,%4,2), %1              \n\t"
-        "lea (%2,%4,2), %2              \n\t"
-        "sub $2, %0                     \n\t"
+        "lea (%q1,%q4,2), %q1              \n\t"
+        "lea (%q2,%q4,2), %q2              \n\t"
+        "sub $2, %q0                     \n\t"
         " jg 1b                         \n\t"
         "movhlps %%xmm2, %%xmm0         \n\t"
         "paddw   %%xmm0, %%xmm2         \n\t"
-        "movd    %%xmm2, %3             \n\t"
+        "movd    %%xmm2, %q3             \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2), "=r"(ret)
         : "r" ((x86_reg)stride)
     );
@@ -128,17 +128,17 @@ static inline void sad8_x2a_mmxext(uint8_t *blk1, uint8_t *blk2,
     __asm__ volatile(
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1), %%mm0               \n\t"
-        "movq (%1, %3), %%mm1           \n\t"
-        "pavgb 1(%1), %%mm0             \n\t"
-        "pavgb 1(%1, %3), %%mm1         \n\t"
-        "psadbw (%2), %%mm0             \n\t"
-        "psadbw (%2, %3), %%mm1         \n\t"
+        "movq (%q1), %%mm0               \n\t"
+        "movq (%q1, %q3), %%mm1           \n\t"
+        "pavgb 1(%q1), %%mm0             \n\t"
+        "pavgb 1(%q1, %q3), %%mm1         \n\t"
+        "psadbw (%q2), %%mm0             \n\t"
+        "psadbw (%q2, %q3), %%mm1         \n\t"
         "paddw %%mm0, %%mm6             \n\t"
         "paddw %%mm1, %%mm6             \n\t"
-        "lea (%1,%3,2), %1              \n\t"
-        "lea (%2,%3,2), %2              \n\t"
-        "sub $2, %0                     \n\t"
+        "lea (%q1,%q3,2), %q1              \n\t"
+        "lea (%q2,%q3,2), %q2              \n\t"
+        "sub $2, %q0                     \n\t"
         " jg 1b                         \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2)
         : "r" ((x86_reg)stride)
@@ -149,22 +149,22 @@ static inline void sad8_y2a_mmxext(uint8_t *blk1, uint8_t *blk2,
                                    int stride, int h)
 {
     __asm__ volatile(
-        "movq (%1), %%mm0               \n\t"
-        "add %3, %1                     \n\t"
+        "movq (%q1), %%mm0               \n\t"
+        "add %q3, %q1                     \n\t"
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1), %%mm1               \n\t"
-        "movq (%1, %3), %%mm2           \n\t"
+        "movq (%q1), %%mm1               \n\t"
+        "movq (%q1, %q3), %%mm2           \n\t"
         "pavgb %%mm1, %%mm0             \n\t"
         "pavgb %%mm2, %%mm1             \n\t"
-        "psadbw (%2), %%mm0             \n\t"
-        "psadbw (%2, %3), %%mm1         \n\t"
+        "psadbw (%q2), %%mm0             \n\t"
+        "psadbw (%q2, %q3), %%mm1         \n\t"
         "paddw %%mm0, %%mm6             \n\t"
         "paddw %%mm1, %%mm6             \n\t"
         "movq %%mm2, %%mm0              \n\t"
-        "lea (%1,%3,2), %1              \n\t"
-        "lea (%2,%3,2), %2              \n\t"
-        "sub $2, %0                     \n\t"
+        "lea (%q1,%q3,2), %q1              \n\t"
+        "lea (%q2,%q3,2), %q2              \n\t"
+        "sub $2, %q0                     \n\t"
         " jg 1b                         \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2)
         : "r" ((x86_reg)stride)
@@ -176,26 +176,26 @@ static inline void sad8_4_mmxext(uint8_t *blk1, uint8_t *blk2,
 {
     __asm__ volatile(
         "movq "MANGLE(bone)", %%mm5     \n\t"
-        "movq (%1), %%mm0               \n\t"
-        "pavgb 1(%1), %%mm0             \n\t"
-        "add %3, %1                     \n\t"
+        "movq (%q1), %%mm0               \n\t"
+        "pavgb 1(%q1), %%mm0             \n\t"
+        "add %q3, %q1                     \n\t"
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1), %%mm1               \n\t"
-        "movq (%1,%3), %%mm2            \n\t"
-        "pavgb 1(%1), %%mm1             \n\t"
-        "pavgb 1(%1,%3), %%mm2          \n\t"
+        "movq (%q1), %%mm1               \n\t"
+        "movq (%q1,%q3), %%mm2            \n\t"
+        "pavgb 1(%q1), %%mm1             \n\t"
+        "pavgb 1(%q1,%q3), %%mm2          \n\t"
         "psubusb %%mm5, %%mm1           \n\t"
         "pavgb %%mm1, %%mm0             \n\t"
         "pavgb %%mm2, %%mm1             \n\t"
-        "psadbw (%2), %%mm0             \n\t"
-        "psadbw (%2,%3), %%mm1          \n\t"
+        "psadbw (%q2), %%mm0             \n\t"
+        "psadbw (%q2,%q3), %%mm1          \n\t"
         "paddw %%mm0, %%mm6             \n\t"
         "paddw %%mm1, %%mm6             \n\t"
         "movq %%mm2, %%mm0              \n\t"
-        "lea (%1,%3,2), %1              \n\t"
-        "lea (%2,%3,2), %2              \n\t"
-        "sub $2, %0                     \n\t"
+        "lea (%q1,%q3,2), %q1              \n\t"
+        "lea (%q2,%q3,2), %q2              \n\t"
+        "sub $2, %q0                     \n\t"
         " jg 1b                         \n\t"
         : "+r" (h), "+r" (blk1), "+r" (blk2)
         : "r" ((x86_reg)stride)
@@ -208,18 +208,18 @@ static inline void sad8_2_mmx(uint8_t *blk1a, uint8_t *blk1b, uint8_t *blk2, int
     __asm__ volatile(
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%1, %%"REG_a"), %%mm0    \n\t"
-        "movq (%2, %%"REG_a"), %%mm1    \n\t"
-        "movq (%1, %%"REG_a"), %%mm2    \n\t"
-        "movq (%2, %%"REG_a"), %%mm3    \n\t"
+        "movq (%q1, %%"REG_a"), %%mm0    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm1    \n\t"
+        "movq (%q1, %%"REG_a"), %%mm2    \n\t"
+        "movq (%q2, %%"REG_a"), %%mm3    \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
         "punpcklbw %%mm7, %%mm1         \n\t"
         "punpckhbw %%mm7, %%mm2         \n\t"
         "punpckhbw %%mm7, %%mm3         \n\t"
         "paddw %%mm0, %%mm1             \n\t"
         "paddw %%mm2, %%mm3             \n\t"
-        "movq (%3, %%"REG_a"), %%mm4    \n\t"
-        "movq (%3, %%"REG_a"), %%mm2    \n\t"
+        "movq (%q3, %%"REG_a"), %%mm4    \n\t"
+        "movq (%q3, %%"REG_a"), %%mm2    \n\t"
         "paddw %%mm5, %%mm1             \n\t"
         "paddw %%mm5, %%mm3             \n\t"
         "psrlw $1, %%mm1                \n\t"
@@ -233,7 +233,7 @@ static inline void sad8_2_mmx(uint8_t *blk1a, uint8_t *blk1b, uint8_t *blk2, int
         "punpckhbw %%mm7, %%mm1         \n\t"
         "paddw %%mm1, %%mm0             \n\t"
         "paddw %%mm0, %%mm6             \n\t"
-        "add %4, %%"REG_a"              \n\t"
+        "add %q4, %%"REG_a"              \n\t"
         " js 1b                         \n\t"
         : "+a" (len)
         : "r" (blk1a - len), "r" (blk1b -len), "r" (blk2 - len), "r" ((x86_reg)stride)
@@ -244,8 +244,8 @@ static inline void sad8_4_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
 {
     x86_reg len= -(x86_reg)stride*h;
     __asm__ volatile(
-        "movq (%1, %%"REG_a"), %%mm0    \n\t"
-        "movq 1(%1, %%"REG_a"), %%mm2   \n\t"
+        "movq (%q1, %%"REG_a"), %%mm0    \n\t"
+        "movq 1(%q1, %%"REG_a"), %%mm2   \n\t"
         "movq %%mm0, %%mm1              \n\t"
         "movq %%mm2, %%mm3              \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
@@ -256,8 +256,8 @@ static inline void sad8_4_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
         "paddw %%mm3, %%mm1             \n\t"
         ".p2align 4                     \n\t"
         "1:                             \n\t"
-        "movq (%2, %%"REG_a"), %%mm2    \n\t"
-        "movq 1(%2, %%"REG_a"), %%mm4   \n\t"
+        "movq (%q2, %%"REG_a"), %%mm2    \n\t"
+        "movq 1(%q2, %%"REG_a"), %%mm4   \n\t"
         "movq %%mm2, %%mm3              \n\t"
         "movq %%mm4, %%mm5              \n\t"
         "punpcklbw %%mm7, %%mm2         \n\t"
@@ -271,8 +271,8 @@ static inline void sad8_4_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
         "paddw %%mm3, %%mm1             \n\t"
         "paddw %%mm5, %%mm0             \n\t"
         "paddw %%mm5, %%mm1             \n\t"
-        "movq (%3, %%"REG_a"), %%mm4    \n\t"
-        "movq (%3, %%"REG_a"), %%mm5    \n\t"
+        "movq (%q3, %%"REG_a"), %%mm4    \n\t"
+        "movq (%q3, %%"REG_a"), %%mm5    \n\t"
         "psrlw $2, %%mm0                \n\t"
         "psrlw $2, %%mm1                \n\t"
         "packuswb %%mm1, %%mm0          \n\t"
@@ -286,7 +286,7 @@ static inline void sad8_4_mmx(uint8_t *blk1, uint8_t *blk2, int stride, int h)
         "paddw %%mm4, %%mm6             \n\t"
         "movq  %%mm2, %%mm0             \n\t"
         "movq  %%mm3, %%mm1             \n\t"
-        "add %4, %%"REG_a"              \n\t"
+        "add %q4, %%"REG_a"              \n\t"
         " js 1b                         \n\t"
         : "+a" (len)
         : "r" (blk1 - len), "r" (blk1 -len + stride), "r" (blk2 - len), "r" ((x86_reg)stride)
@@ -303,7 +303,7 @@ static inline int sum_mmx(void)
         "movq %%mm6, %%mm0              \n\t"
         "psrlq $16, %%mm6               \n\t"
         "paddw %%mm0, %%mm6             \n\t"
-        "movd %%mm6, %0                 \n\t"
+        "movd %%mm6, %q0                 \n\t"
         : "=r" (ret)
     );
     return ret&0xFFFF;
@@ -313,7 +313,7 @@ static inline int sum_mmxext(void)
 {
     int ret;
     __asm__ volatile(
-        "movd %%mm6, %0                 \n\t"
+        "movd %%mm6, %q0                 \n\t"
         : "=r" (ret)
     );
     return ret;
@@ -345,7 +345,7 @@ static int sad8_x2_ ## suf(void *v, uint8_t *blk2, uint8_t *blk1, int stride, in
     av_assert2(h==8);\
     __asm__ volatile("pxor %%mm7, %%mm7     \n\t"\
                  "pxor %%mm6, %%mm6     \n\t"\
-                 "movq %0, %%mm5        \n\t"\
+                 "movq %q0, %%mm5        \n\t"\
                  :: "m"(round_tab[1]) \
                  );\
 \
@@ -359,7 +359,7 @@ static int sad8_y2_ ## suf(void *v, uint8_t *blk2, uint8_t *blk1, int stride, in
     av_assert2(h==8);\
     __asm__ volatile("pxor %%mm7, %%mm7     \n\t"\
                  "pxor %%mm6, %%mm6     \n\t"\
-                 "movq %0, %%mm5        \n\t"\
+                 "movq %q0, %%mm5        \n\t"\
                  :: "m"(round_tab[1]) \
                  );\
 \
@@ -394,7 +394,7 @@ static int sad16_x2_ ## suf(void *v, uint8_t *blk2, uint8_t *blk1, int stride, i
 {\
     __asm__ volatile("pxor %%mm7, %%mm7     \n\t"\
                  "pxor %%mm6, %%mm6     \n\t"\
-                 "movq %0, %%mm5        \n\t"\
+                 "movq %q0, %%mm5        \n\t"\
                  :: "m"(round_tab[1]) \
                  );\
 \
@@ -407,7 +407,7 @@ static int sad16_y2_ ## suf(void *v, uint8_t *blk2, uint8_t *blk1, int stride, i
 {\
     __asm__ volatile("pxor %%mm7, %%mm7     \n\t"\
                  "pxor %%mm6, %%mm6     \n\t"\
-                 "movq %0, %%mm5        \n\t"\
+                 "movq %q0, %%mm5        \n\t"\
                  :: "m"(round_tab[1]) \
                  );\
 \
diff --git a/libavcodec/x86/rnd_template.c b/libavcodec/x86/rnd_template.c
index e37fc19..62fe7a1 100644
--- a/libavcodec/x86/rnd_template.c
+++ b/libavcodec/x86/rnd_template.c
@@ -34,8 +34,8 @@ STATIC void DEF(put, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
     MOVQ_ZERO(mm7);
     SET_RND(mm6); // =2 for rnd  and  =1 for no_rnd version
     __asm__ volatile(
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm4            \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm4            \n\t"
         "movq   %%mm0, %%mm1            \n\t"
         "movq   %%mm4, %%mm5            \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
@@ -48,8 +48,8 @@ STATIC void DEF(put, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "add    %3, %1                  \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1, %%"REG_a"), %%mm0  \n\t"
-        "movq   1(%1, %%"REG_a"), %%mm2 \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm0  \n\t"
+        "naclmovq1   \"1(%1, %%"REG_a")\", %%mm2 \n\t"
         "movq   %%mm0, %%mm1            \n\t"
         "movq   %%mm2, %%mm3            \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
@@ -65,11 +65,11 @@ STATIC void DEF(put, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "psrlw  $2, %%mm4               \n\t"
         "psrlw  $2, %%mm5               \n\t"
         "packuswb  %%mm5, %%mm4         \n\t"
-        "movq   %%mm4, (%2, %%"REG_a")  \n\t"
+        "naclmovq2   %%mm4, \"(%2, %%"REG_a")\"  \n\t"
         "add    %3, %%"REG_a"           \n\t"
 
-        "movq   (%1, %%"REG_a"), %%mm2  \n\t" // 0 <-> 2   1 <-> 3
-        "movq   1(%1, %%"REG_a"), %%mm4 \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm2  \n\t" // 0 <-> 2   1 <-> 3
+        "naclmovq1   \"1(%1, %%"REG_a")\", %%mm4 \n\t"
         "movq   %%mm2, %%mm3            \n\t"
         "movq   %%mm4, %%mm5            \n\t"
         "punpcklbw %%mm7, %%mm2         \n\t"
@@ -85,14 +85,14 @@ STATIC void DEF(put, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "psrlw  $2, %%mm0               \n\t"
         "psrlw  $2, %%mm1               \n\t"
         "packuswb  %%mm1, %%mm0         \n\t"
-        "movq   %%mm0, (%2, %%"REG_a")  \n\t"
+        "naclmovq2   %%mm0, \"(%2, %%"REG_a")\"  \n\t"
         "add    %3, %%"REG_a"           \n\t"
 
         "subl   $2, %0                  \n\t"
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels)
         :"D"(block), "r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
 
 // avg_pixels
@@ -103,8 +103,8 @@ STATIC void DEF(avg, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
     MOVQ_ZERO(mm7);
     SET_RND(mm6); // =2 for rnd  and  =1 for no_rnd version
     __asm__ volatile(
-        "movq   (%1), %%mm0             \n\t"
-        "movq   1(%1), %%mm4            \n\t"
+        "movq   %%nacl:(%%r15, %1), %%mm0             \n\t"
+        "movq   %%nacl:1(%%r15, %1), %%mm4            \n\t"
         "movq   %%mm0, %%mm1            \n\t"
         "movq   %%mm4, %%mm5            \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
@@ -117,8 +117,8 @@ STATIC void DEF(avg, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "add    %3, %1                  \n\t"
         ".p2align 3                     \n\t"
         "1:                             \n\t"
-        "movq   (%1, %%"REG_a"), %%mm0  \n\t"
-        "movq   1(%1, %%"REG_a"), %%mm2 \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm0  \n\t"
+        "naclmovq1   \"1(%1, %%"REG_a")\", %%mm2 \n\t"
         "movq   %%mm0, %%mm1            \n\t"
         "movq   %%mm2, %%mm3            \n\t"
         "punpcklbw %%mm7, %%mm0         \n\t"
@@ -133,16 +133,16 @@ STATIC void DEF(avg, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "paddusw %%mm1, %%mm5           \n\t"
         "psrlw  $2, %%mm4               \n\t"
         "psrlw  $2, %%mm5               \n\t"
-                "movq   (%2, %%"REG_a"), %%mm3  \n\t"
+                "naclmovq1   \"(%2, %%"REG_a")\", %%mm3  \n\t"
         "packuswb  %%mm5, %%mm4         \n\t"
                 "pcmpeqd %%mm2, %%mm2   \n\t"
                 "paddb %%mm2, %%mm2     \n\t"
                 PAVGB_MMX(%%mm3, %%mm4, %%mm5, %%mm2)
-                "movq   %%mm5, (%2, %%"REG_a")  \n\t"
+                "naclmovq1   \"%%mm5, (%2\", %%"REG_a")  \n\t"
         "add    %3, %%"REG_a"                \n\t"
 
-        "movq   (%1, %%"REG_a"), %%mm2  \n\t" // 0 <-> 2   1 <-> 3
-        "movq   1(%1, %%"REG_a"), %%mm4 \n\t"
+        "naclmovq1   \"(%1, %%"REG_a")\", %%mm2  \n\t" // 0 <-> 2   1 <-> 3
+        "naclmovq1   \"1(%1, %%"REG_a")\", %%mm4 \n\t"
         "movq   %%mm2, %%mm3            \n\t"
         "movq   %%mm4, %%mm5            \n\t"
         "punpcklbw %%mm7, %%mm2         \n\t"
@@ -157,17 +157,17 @@ STATIC void DEF(avg, pixels8_xy2)(uint8_t *block, const uint8_t *pixels,
         "paddusw %%mm5, %%mm1           \n\t"
         "psrlw  $2, %%mm0               \n\t"
         "psrlw  $2, %%mm1               \n\t"
-                "movq   (%2, %%"REG_a"), %%mm3  \n\t"
+                "naclmovq1   \"(%2, %%"REG_a")\", %%mm3  \n\t"
         "packuswb  %%mm1, %%mm0         \n\t"
                 "pcmpeqd %%mm2, %%mm2   \n\t"
                 "paddb %%mm2, %%mm2     \n\t"
                 PAVGB_MMX(%%mm3, %%mm0, %%mm1, %%mm2)
-                "movq   %%mm1, (%2, %%"REG_a")  \n\t"
+                "naclmovq2   %%mm1, \"(%2, %%"REG_a")\"  \n\t"
         "add    %3, %%"REG_a"           \n\t"
 
         "subl   $2, %0                  \n\t"
         "jnz    1b                      \n\t"
         :"+g"(h), "+S"(pixels)
         :"D"(block), "r"((x86_reg)line_size)
-        :REG_a, "memory");
+        :REG_a, "%r14", "memory");
 }
diff --git a/libavutil/mem.c b/libavutil/mem.c
index 5aad97a..83665f4 100644
--- a/libavutil/mem.c
+++ b/libavutil/mem.c
@@ -57,6 +57,8 @@ void  free(void *ptr);
 
 #endif /* MALLOC_PREFIX */
 
+int   posix_memalign(void **ptr, size_t align, size_t size);
+
 #define ALIGN (HAVE_AVX ? 32 : 16)
 
 /* NOTE: if you want to override these functions with your own
diff --git a/libavutil/x86/asm.h b/libavutil/x86/asm.h
index 70ccac7..a2ac587 100644
--- a/libavutil/x86/asm.h
+++ b/libavutil/x86/asm.h
@@ -26,6 +26,11 @@
 
 typedef struct xmm_reg { uint64_t a, b; } xmm_reg;
 
+#undef ARCH_X86_32
+#undef ARCH_X86_64
+#define ARCH_X86_64 1
+#define ARCH_X86_32 0
+
 #if ARCH_X86_64
 #    define OPSIZE "q"
 #    define REG_a "rax"
@@ -70,6 +75,55 @@ typedef int32_t x86_reg;
 typedef int x86_reg;
 #endif
 
+// Nacl hacks
+#    define REG_BP_S "rbp"
+typedef uint64_t x86_reg_addr;
+
+
+#ifndef X86_64_ASM_MACRO_DEFINED_
+#define X86_64_ASM_MACRO_DEFINED_
+
+#define DEF_NACL_ASM1(name) \
+      ".macro nacl"#name"1 addr, reg2\n" \
+      ".bundle_lock\n" \
+      "lea \\addr, %r14d\n" \
+      #name" (%r15,%r14), \\reg2\n" \
+      ".bundle_unlock\n" \
+      ".endm\n"
+
+#define DEF_NACL_ASM2(name) \
+      ".macro nacl"#name"2 reg1, addr\n" \
+      ".bundle_lock\n" \
+      "lea \\addr, %r14d\n" \
+      #name " \\reg1, (%r15,%r14)\n" \
+      ".bundle_unlock\n" \
+      ".endm\n"
+
+#define DEF_NACL_ASM(name) \
+    DEF_NACL_ASM1(name) \
+    DEF_NACL_ASM2(name) \
+
+static void x86_64_asm_macro_dummy(void) __attribute__((unused, optimize("-O0"))) ;
+static void x86_64_asm_macro_dummy(void) {
+  __asm__ volatile(
+      DEF_NACL_ASM(movntq)
+      DEF_NACL_ASM(movntdq)
+      DEF_NACL_ASM(movq)
+      DEF_NACL_ASM(movd)
+      DEF_NACL_ASM(movdqa)
+      DEF_NACL_ASM(movdqu)
+      DEF_NACL_ASM(pavgb)
+      DEF_NACL_ASM(pandn)
+      DEF_NACL_ASM(movl)
+      DEF_NACL_ASM(movlps)
+      DEF_NACL_ASM(pmaddwd)
+      DEF_NACL_ASM(pavgusb)
+      DEF_NACL_ASM(pswapd)
+      DEF_NACL_ASM(movaps)
+     );
+}
+#endif  // X86_64_ASM_MACRO_DEFINED_
+
 #define HAVE_7REGS (ARCH_X86_64 || (HAVE_EBX_AVAILABLE && HAVE_EBP_AVAILABLE))
 #define HAVE_6REGS (ARCH_X86_64 || (HAVE_EBX_AVAILABLE || HAVE_EBP_AVAILABLE))
 
@@ -104,7 +158,7 @@ typedef int x86_reg;
 #if ARCH_X86_64 && defined(PIC)
 #    define LOCAL_MANGLE(a) #a "(%%rip)"
 #else
-#    define LOCAL_MANGLE(a) #a
+#    define LOCAL_MANGLE(a) #a "(%%r15)"
 #endif
 
 #define MANGLE(a) EXTERN_PREFIX LOCAL_MANGLE(a)
diff --git a/libavutil/x86/cpu.c b/libavutil/x86/cpu.c
index 18049ea..e666bcf 100644
--- a/libavutil/x86/cpu.c
+++ b/libavutil/x86/cpu.c
@@ -72,20 +72,23 @@
 
 #elif HAVE_INLINE_ASM
 
-static int cpuid_test(void)
-{
-    x86_reg a, c;
-
-    /* Check if CPUID is supported by attempting to toggle the ID bit in
-     * the EFLAGS register. */
-    get_eflags(a);
-    set_eflags(a ^ 0x200000);
-    get_eflags(c);
-
-    return a != c;
-}
+// static int cpuid_test(void)
+// {
+//     x86_reg a, c;
+//
+//     /* Check if CPUID is supported by attempting to toggle the ID bit in
+//      * the EFLAGS register. */
+//     get_eflags(a);
+//     set_eflags(a ^ 0x200000);
+//     get_eflags(c);
+//
+//     return a != c;
+// }
 #endif
 
+#undef cpuid_test
+#define cpuid_test() 1
+
 /* Function to test if multimedia instructions are supported...  */
 int ff_get_cpu_flags_x86(void)
 {
diff --git a/libavutil/x86/float_dsp_init.c b/libavutil/x86/float_dsp_init.c
index 97f7b7c..096965f 100644
--- a/libavutil/x86/float_dsp_init.c
+++ b/libavutil/x86/float_dsp_init.c
@@ -65,10 +65,10 @@ static void vector_fmul_window_3dnowext(float *dst, const float *src0,
     x86_reg j =  len * 4 - 8;
     __asm__ volatile (
         "1:                             \n"
-        "pswapd (%5, %1), %%mm1         \n"
-        "movq   (%5, %0), %%mm0         \n"
-        "pswapd (%4, %1), %%mm5         \n"
-        "movq   (%3, %0), %%mm4         \n"
+        "naclpswapd1 \"(%q5, %q1)\", %%mm1         \n"
+        "naclmovq1   \"(%q5, %q0)\", %%mm0         \n"
+        "naclpswapd1 \"(%q4, %q1)\", %%mm5         \n"
+        "naclmovq1   \"(%q3, %q0)\", %%mm4         \n"
         "movq      %%mm0, %%mm2         \n"
         "movq      %%mm1, %%mm3         \n"
         "pfmul     %%mm4, %%mm2         \n" // src0[len + i] * win[len + i]
@@ -78,14 +78,15 @@ static void vector_fmul_window_3dnowext(float *dst, const float *src0,
         "pfadd     %%mm3, %%mm2         \n"
         "pfsub     %%mm0, %%mm1         \n"
         "pswapd    %%mm2, %%mm2         \n"
-        "movq      %%mm1, (%2, %0)      \n"
-        "movq      %%mm2, (%2, %1)      \n"
-        "sub          $8, %1            \n"
-        "add          $8, %0            \n"
+        "naclmovq2      %%mm1, \"(%q2, %q0)\"      \n"
+        "naclmovq2      %%mm2, \"(%q2, %q1)\"      \n"
+        "sub          $8, %q1            \n"
+        "add          $8, %q0            \n"
         "jl           1b                \n"
         "femms                          \n"
         : "+r"(i), "+r"(j)
         : "r"(dst + len), "r"(src0 + len), "r"(src1), "r"(win + len)
+              : "%r14"
     );
 }
 
@@ -96,10 +97,10 @@ static void vector_fmul_window_sse(float *dst, const float *src0,
     x86_reg j =  len * 4 - 16;
     __asm__ volatile (
         "1:                             \n"
-        "movaps      (%5, %1), %%xmm1   \n"
-        "movaps      (%5, %0), %%xmm0   \n"
-        "movaps      (%4, %1), %%xmm5   \n"
-        "movaps      (%3, %0), %%xmm4   \n"
+        "naclmovaps1      \"(%q5, %q1)\", %%xmm1   \n"
+        "naclmovaps1      \"(%q5, %q0)\", %%xmm0   \n"
+        "naclmovaps1      \"(%q4, %q1)\", %%xmm5   \n"
+        "naclmovaps1      \"(%q3, %q0)\", %%xmm4   \n"
         "shufps $0x1b, %%xmm1, %%xmm1   \n"
         "shufps $0x1b, %%xmm5, %%xmm5   \n"
         "movaps        %%xmm0, %%xmm2   \n"
@@ -111,13 +112,14 @@ static void vector_fmul_window_sse(float *dst, const float *src0,
         "addps         %%xmm3, %%xmm2   \n"
         "subps         %%xmm0, %%xmm1   \n"
         "shufps $0x1b, %%xmm2, %%xmm2   \n"
-        "movaps        %%xmm1, (%2, %0) \n"
-        "movaps        %%xmm2, (%2, %1) \n"
-        "sub              $16, %1       \n"
-        "add              $16, %0       \n"
+        "naclmovaps2        %%xmm1, \"(%q2, %q0)\" \n"
+        "naclmovaps2        %%xmm2, \"(%q2, %q1)\" \n"
+        "sub              $16, %q1       \n"
+        "add              $16, %q0       \n"
         "jl                1b           \n"
         : "+r"(i), "+r"(j)
         : "r"(dst + len), "r"(src0 + len), "r"(src1), "r"(win + len)
+              : "%r14"
     );
 }
 #endif /* HAVE_6REGS && HAVE_INLINE_ASM */
diff --git a/libpostproc/postprocess_template.c b/libpostproc/postprocess_template.c
index 74b0ab4..48e2c5b 100644
--- a/libpostproc/postprocess_template.c
+++ b/libpostproc/postprocess_template.c
@@ -85,6 +85,8 @@
 #define REAL_PAVGB(a,b) "pavgusb " #a ", " #b " \n\t"
 #endif
 #define PAVGB(a,b)  REAL_PAVGB(a,b)
+#define REAL_NACL_PAVGB1(a,b) "naclpavgb1 \"" #a "\", " #b " \n\t"
+#define NACL_PAVGB1(a,b)  REAL_NACL_PAVGB1(a,b)
 
 #if   TEMPLATE_PP_MMXEXT
 #define PMINUB(a,b,t) "pminub " #a ", " #b " \n\t"
@@ -112,18 +114,18 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
     int numEq= 0, dcOk;
     src+= stride*4; // src points to begin of the 8x8 Block
     __asm__ volatile(
-        "movq %0, %%mm7                         \n\t"
-        "movq %1, %%mm6                         \n\t"
+        "movq %q0, %%mm7                         \n\t"
+        "movq %q1, %%mm6                         \n\t"
         : : "m" (c->mmxDcOffset[c->nonBQP]),  "m" (c->mmxDcThreshold[c->nonBQP])
         );
 
     __asm__ volatile(
-        "lea (%2, %3), %%"REG_a"                \n\t"
+        "lea (%q2, %q3), %%"REG_a"                \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %1      eax     eax+%2  eax+2%2 %1+4%2  ecx     ecx+%2  ecx+2%2 %1+8%2  ecx+4%2
+//      %q1      eax     eax+%q2  eax+2%q2 %q1+4%q2  ecx     ecx+%q2  ecx+2%q2 %q1+8%q2  ecx+4%q2
 
-        "movq (%2), %%mm0                       \n\t"
-        "movq (%%"REG_a"), %%mm1                \n\t"
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t"
         "movq %%mm0, %%mm3                      \n\t"
         "movq %%mm0, %%mm4                      \n\t"
         PMAXUB(%%mm1, %%mm4)
@@ -132,7 +134,7 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "paddb %%mm7, %%mm0                     \n\t"
         "pcmpgtb %%mm6, %%mm0                   \n\t"
 
-        "movq (%%"REG_a",%3), %%mm2             \n\t"
+        "naclmovq1 \"(%%"REG_a",%q3)\", %%mm2             \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -140,7 +142,7 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3, 2), %%mm1         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3, 2)\", %%mm1         \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -148,9 +150,9 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "pcmpgtb %%mm6, %%mm2                   \n\t"
         "paddb %%mm2, %%mm0                     \n\t"
 
-        "lea (%%"REG_a", %3, 4), %%"REG_a"      \n\t"
+        "lea (%%"REG_a", %q3, 4), %%"REG_a"      \n\t"
 
-        "movq (%2, %3, 4), %%mm2                \n\t"
+        "naclmovq1 \"(%q2, %q3, 4)\", %%mm2                \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -158,7 +160,7 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a"), %%mm1                \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -166,7 +168,7 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "pcmpgtb %%mm6, %%mm2                   \n\t"
         "paddb %%mm2, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3), %%mm2            \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3)\", %%mm2            \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -174,7 +176,7 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3, 2), %%mm1         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3, 2)\", %%mm1         \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -198,16 +200,16 @@ static inline int RENAME(vertClassify)(uint8_t src[], int stride, PPContext *c){
         "psrlq $32, %%mm0                       \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 #endif
-        "movq %4, %%mm7                         \n\t" // QP,..., QP
+        "movq %q4, %%mm7                         \n\t" // QP,..., QP
         "paddusb %%mm7, %%mm7                   \n\t" // 2QP ... 2QP
         "psubusb %%mm7, %%mm4                   \n\t" // Diff <= 2QP -> 0
         "packssdw %%mm4, %%mm4                  \n\t"
-        "movd %%mm0, %0                         \n\t"
-        "movd %%mm4, %1                         \n\t"
+        "movd %%mm0, %q0                         \n\t"
+        "movd %%mm4, %q1                         \n\t"
 
         : "=r" (numEq), "=r" (dcOk)
-        : "r" (src), "r" ((x86_reg)stride), "m" (c->pQPb)
-        : "%"REG_a
+        : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride), "m" ((x86_reg_addr)c->pQPb)
+        : "%"REG_a, "%r14"
         );
 
     numEq= (-numEq) &0xFF;
@@ -229,12 +231,12 @@ static inline void RENAME(doVertLowPass)(uint8_t *src, int stride, PPContext *c)
 {
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= stride*3;
-    __asm__ volatile(        //"movv %0 %1 %2\n\t"
-        "movq %2, %%mm0                         \n\t"  // QP,..., QP
+    __asm__ volatile(        //"movv %q0 %q1 %q2\n\t"
+        "movq %q2, %%mm0                         \n\t"  // QP,..., QP
         "pxor %%mm4, %%mm4                      \n\t"
 
-        "movq (%0), %%mm6                       \n\t"
-        "movq (%0, %1), %%mm5                   \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm6                       \n\t"
+        "naclmovq1 \"(%q0, %q1)\", %%mm5                   \n\t"
         "movq %%mm5, %%mm1                      \n\t"
         "movq %%mm6, %%mm2                      \n\t"
         "psubusb %%mm6, %%mm5                   \n\t"
@@ -247,12 +249,12 @@ static inline void RENAME(doVertLowPass)(uint8_t *src, int stride, PPContext *c)
         "pandn %%mm1, %%mm2                     \n\t"
         "por %%mm2, %%mm6                       \n\t"// First Line to Filter
 
-        "movq (%0, %1, 8), %%mm5                \n\t"
-        "lea (%0, %1, 4), %%"REG_a"             \n\t"
-        "lea (%0, %1, 8), %%"REG_c"             \n\t"
-        "sub %1, %%"REG_c"                      \n\t"
-        "add %1, %0                             \n\t" // %0 points to line 1 not 0
-        "movq (%0, %1, 8), %%mm7                \n\t"
+        "naclmovq1 \"(%q0, %q1, 8)\", %%mm5                \n\t"
+        "lea (%q0, %q1, 4), %%"REG_a"             \n\t"
+        "lea (%q0, %q1, 8), %%"REG_c"             \n\t"
+        "sub %q1, %%"REG_c"                      \n\t"
+        "add %q1, %q0                             \n\t" // %q0 points to line 1 not 0
+        "naclmovq1 \"(%q0, %q1, 8)\", %%mm7                \n\t"
         "movq %%mm5, %%mm1                      \n\t"
         "movq %%mm7, %%mm2                      \n\t"
         "psubusb %%mm7, %%mm5                   \n\t"
@@ -267,92 +269,92 @@ static inline void RENAME(doVertLowPass)(uint8_t *src, int stride, PPContext *c)
 
 
         //      1       2       3       4       5       6       7       8
-        //      %0      %0+%1   %0+2%1  eax     %0+4%1  eax+2%1 ecx     eax+4%1
+        //      %q0      %q0+%q1   %q0+2%q1  eax     %q0+4%q1  eax+2%q1 ecx     eax+4%q1
         // 6 4 2 2 1 1
         // 6 4 4 2
         // 6 8 2
 
-        "movq (%0, %1), %%mm0                   \n\t" //  1
+        "naclmovq1 \"(%q0, %q1)\", %%mm0                   \n\t" //  1
         "movq %%mm0, %%mm1                      \n\t" //  1
         PAVGB(%%mm6, %%mm0)                           //1 1        /2
         PAVGB(%%mm6, %%mm0)                           //3 1        /4
 
-        "movq (%0, %1, 4), %%mm2                \n\t" //     1
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm2                \n\t" //     1
         "movq %%mm2, %%mm5                      \n\t" //     1
-        PAVGB((%%REGa), %%mm2)                        //    11        /2
-        PAVGB((%0, %1, 2), %%mm2)                     //   211        /4
+        PAVGB(%%nacl:(%%r15, %%REGa), %%mm2)                        //    11        /2
+        NACL_PAVGB1((%q0, %q1, 2), %%mm2)                     //   211        /4
         "movq %%mm2, %%mm3                      \n\t" //   211        /4
-        "movq (%0), %%mm4                       \n\t" // 1
+        "movq %%nacl:(%%r15, %q0), %%mm4                       \n\t" // 1
         PAVGB(%%mm4, %%mm3)                           // 4 211        /8
         PAVGB(%%mm0, %%mm3)                           //642211        /16
-        "movq %%mm3, (%0)                       \n\t" // X
+        "movq %%mm3, %%nacl:(%%r15, %q0)                       \n\t" // X
         // mm1=2 mm2=3(211) mm4=1 mm5=5 mm6=0 mm7=9
         "movq %%mm1, %%mm0                      \n\t" //  1
         PAVGB(%%mm6, %%mm0)                           //1 1        /2
         "movq %%mm4, %%mm3                      \n\t" // 1
-        PAVGB((%0,%1,2), %%mm3)                       // 1 1        /2
-        PAVGB((%%REGa,%1,2), %%mm5)                   //     11        /2
-        PAVGB((%%REGa), %%mm5)                        //    211 /4
+        NACL_PAVGB1((%q0,%q1,2), %%mm3)                       // 1 1        /2
+        NACL_PAVGB1((%%REGa, %q1,2), %%mm5)                   //     11        /2
+        PAVGB(%%nacl:(%%r15, %%REGa), %%mm5)                        //    211 /4
         PAVGB(%%mm5, %%mm3)                           // 2 2211 /8
         PAVGB(%%mm0, %%mm3)                           //4242211 /16
-        "movq %%mm3, (%0,%1)                    \n\t" //  X
+        "naclmovq2 %%mm3, \"(%q0,%q1)\"                    \n\t" //  X
         // mm1=2 mm2=3(211) mm4=1 mm5=4(211) mm6=0 mm7=9
         PAVGB(%%mm4, %%mm6)                                   //11        /2
-        "movq (%%"REG_c"), %%mm0                \n\t" //       1
-        PAVGB((%%REGa, %1, 2), %%mm0)                 //      11/2
+        "movq %%nacl:(%%r15, %%"REG_c"), %%mm0                \n\t" //       1
+        NACL_PAVGB1((%%REGa, %q1, 2), %%mm0)                 //      11/2
         "movq %%mm0, %%mm3                      \n\t" //      11/2
         PAVGB(%%mm1, %%mm0)                           //  2   11/4
         PAVGB(%%mm6, %%mm0)                           //222   11/8
         PAVGB(%%mm2, %%mm0)                           //22242211/16
-        "movq (%0, %1, 2), %%mm2                \n\t" //   1
-        "movq %%mm0, (%0, %1, 2)                \n\t" //   X
+        "naclmovq1 \"(%q0, %q1, 2)\", %%mm2                \n\t" //   1
+        "naclmovq2 %%mm0, \"(%q0, %q1, 2)\"                \n\t" //   X
         // mm1=2 mm2=3 mm3=6(11) mm4=1 mm5=4(211) mm6=0(11) mm7=9
-        "movq (%%"REG_a", %1, 4), %%mm0         \n\t" //        1
-        PAVGB((%%REGc), %%mm0)                        //       11        /2
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm0         \n\t" //        1
+        PAVGB(%%nacl:(%%r15, %%REGc), %%mm0)                        //       11        /2
         PAVGB(%%mm0, %%mm6)                           //11     11        /4
         PAVGB(%%mm1, %%mm4)                           // 11                /2
         PAVGB(%%mm2, %%mm1)                           //  11                /2
         PAVGB(%%mm1, %%mm6)                           //1122   11        /8
         PAVGB(%%mm5, %%mm6)                           //112242211        /16
-        "movq (%%"REG_a"), %%mm5                \n\t" //    1
-        "movq %%mm6, (%%"REG_a")                \n\t" //    X
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm5                \n\t" //    1
+        "movq %%mm6, %%nacl:(%%r15, %%"REG_a")                \n\t" //    X
         // mm0=7(11) mm1=2(11) mm2=3 mm3=6(11) mm4=1(11) mm5=4 mm7=9
-        "movq (%%"REG_a", %1, 4), %%mm6         \n\t" //        1
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm6         \n\t" //        1
         PAVGB(%%mm7, %%mm6)                           //        11        /2
         PAVGB(%%mm4, %%mm6)                           // 11     11        /4
         PAVGB(%%mm3, %%mm6)                           // 11   2211        /8
         PAVGB(%%mm5, %%mm2)                           //   11                /2
-        "movq (%0, %1, 4), %%mm4                \n\t" //     1
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm4                \n\t" //     1
         PAVGB(%%mm4, %%mm2)                           //   112                /4
         PAVGB(%%mm2, %%mm6)                           // 112242211        /16
-        "movq %%mm6, (%0, %1, 4)                \n\t" //     X
+        "naclmovq2 %%mm6, \"(%q0, %q1, 4)\"                \n\t" //     X
         // mm0=7(11) mm1=2(11) mm2=3(112) mm3=6(11) mm4=5 mm5=4 mm7=9
         PAVGB(%%mm7, %%mm1)                           //  11     2        /4
         PAVGB(%%mm4, %%mm5)                           //    11                /2
         PAVGB(%%mm5, %%mm0)                           //    11 11        /4
-        "movq (%%"REG_a", %1, 2), %%mm6         \n\t" //      1
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm6         \n\t" //      1
         PAVGB(%%mm6, %%mm1)                           //  11  4  2        /8
         PAVGB(%%mm0, %%mm1)                           //  11224222        /16
-        "movq %%mm1, (%%"REG_a", %1, 2)         \n\t" //      X
+        "naclmovq2 %%mm1, \"(%%"REG_a", %q1, 2)\"         \n\t" //      X
         // mm2=3(112) mm3=6(11) mm4=5 mm5=4(11) mm6=6 mm7=9
-        PAVGB((%%REGc), %%mm2)                        //   112 4        /8
-        "movq (%%"REG_a", %1, 4), %%mm0         \n\t" //        1
+        PAVGB(%%nacl:(%%r15, %%REGc), %%mm2)                        //   112 4        /8
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm0         \n\t" //        1
         PAVGB(%%mm0, %%mm6)                           //      1 1        /2
         PAVGB(%%mm7, %%mm6)                           //      1 12        /4
         PAVGB(%%mm2, %%mm6)                           //   1122424        /4
-        "movq %%mm6, (%%"REG_c")                \n\t" //       X
+        "movq %%mm6, %%nacl:(%%r15, %%"REG_c")                \n\t" //       X
         // mm0=8 mm3=6(11) mm4=5 mm5=4(11) mm7=9
         PAVGB(%%mm7, %%mm5)                           //    11   2        /4
         PAVGB(%%mm7, %%mm5)                           //    11   6        /8
 
         PAVGB(%%mm3, %%mm0)                           //      112        /4
         PAVGB(%%mm0, %%mm5)                           //    112246        /16
-        "movq %%mm5, (%%"REG_a", %1, 4)         \n\t" //        X
-        "sub %1, %0                             \n\t"
+        "naclmovq2 %%mm5, \"(%%"REG_a", %q1, 4)\"         \n\t" //        X
+        "sub %q1, %q0                             \n\t"
 
         :
-        : "r" (src), "r" ((x86_reg)stride), "m" (c->pQPb)
-        : "%"REG_a, "%"REG_c
+        : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride), "m" (c->pQPb)
+        : "%"REG_a, "%"REG_c, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     const int l1= stride;
@@ -411,18 +413,18 @@ static inline void RENAME(vertX1Filter)(uint8_t *src, int stride, PPContext *co)
 
     __asm__ volatile(
         "pxor %%mm7, %%mm7                      \n\t" // 0
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_c"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_c"      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  ecx     ecx+%1  ecx+2%1 %0+8%1  ecx+4%1
-        "movq (%%"REG_a", %1, 2), %%mm0         \n\t" // line 3
-        "movq (%0, %1, 4), %%mm1                \n\t" // line 4
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  ecx     ecx+%q1  ecx+2%q1 %q0+8%q1  ecx+4%q1
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm0         \n\t" // line 3
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm1                \n\t" // line 4
         "movq %%mm1, %%mm2                      \n\t" // line 4
         "psubusb %%mm0, %%mm1                   \n\t"
         "psubusb %%mm2, %%mm0                   \n\t"
         "por %%mm1, %%mm0                       \n\t" // |l2 - l3|
-        "movq (%%"REG_c"), %%mm3                \n\t" // line 5
-        "movq (%%"REG_c", %1), %%mm4            \n\t" // line 6
+        "movq %%nacl:(%%r15, %%"REG_c"), %%mm3                \n\t" // line 5
+        "naclmovq1 \"(%%"REG_c", %q1)\", %%mm4            \n\t" // line 6
         "movq %%mm3, %%mm5                      \n\t" // line 5
         "psubusb %%mm4, %%mm3                   \n\t"
         "psubusb %%mm5, %%mm4                   \n\t"
@@ -436,7 +438,7 @@ static inline void RENAME(vertX1Filter)(uint8_t *src, int stride, PPContext *co)
         "por %%mm5, %%mm4                       \n\t" // |l4 - l5|
         "psubusb %%mm0, %%mm4                   \n\t" //d = MAX(0, |l4-l5| - (|l2-l3| + |l5-l6|)/2)
         "movq %%mm4, %%mm3                      \n\t" // d
-        "movq %2, %%mm0                         \n\t"
+        "movq %q2, %%mm0                         \n\t"
         "paddusb %%mm0, %%mm0                   \n\t"
         "psubusb %%mm0, %%mm4                   \n\t"
         "pcmpeqb %%mm7, %%mm4                   \n\t" // d <= QP ? -1 : 0
@@ -448,49 +450,49 @@ static inline void RENAME(vertX1Filter)(uint8_t *src, int stride, PPContext *co)
         PAVGB(%%mm7, %%mm3)                           // d/4
         PAVGB(%%mm1, %%mm3)                           // 3*d/8
 
-        "movq (%0, %1, 4), %%mm0                \n\t" // line 4
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm0                \n\t" // line 4
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l4-1 : l4
         "psubusb %%mm3, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%0, %1, 4)                \n\t" // line 4
+        "naclmovq2 %%mm0, \"(%q0, %q1, 4)\"                \n\t" // line 4
 
-        "movq (%%"REG_c"), %%mm0                \n\t" // line 5
+        "movq %%nacl:(%%r15, %%"REG_c"), %%mm0                \n\t" // line 5
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l5-1 : l5
         "paddusb %%mm3, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%%"REG_c")                \n\t" // line 5
+        "movq %%mm0, %%nacl:(%%r15, %%"REG_c")                \n\t" // line 5
 
         PAVGB(%%mm7, %%mm1)                           // d/4
 
-        "movq (%%"REG_a", %1, 2), %%mm0         \n\t" // line 3
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm0         \n\t" // line 3
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l4-1 : l4
         "psubusb %%mm1, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%%"REG_a", %1, 2)         \n\t" // line 3
+        "naclmovq2 %%mm0, \"(%%"REG_a", %q1, 2)\"         \n\t" // line 3
 
-        "movq (%%"REG_c", %1), %%mm0            \n\t" // line 6
+        "naclmovq1 \"(%%"REG_c", %q1)\", %%mm0            \n\t" // line 6
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l5-1 : l5
         "paddusb %%mm1, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%%"REG_c", %1)            \n\t" // line 6
+        "naclmovq2 %%mm0, \"(%%"REG_c", %q1)\"            \n\t" // line 6
 
         PAVGB(%%mm7, %%mm1)                           // d/8
 
-        "movq (%%"REG_a", %1), %%mm0            \n\t" // line 2
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm0            \n\t" // line 2
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l2-1 : l2
         "psubusb %%mm1, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%%"REG_a", %1)            \n\t" // line 2
+        "naclmovq2 %%mm0, \"(%%"REG_a", %q1)\"            \n\t" // line 2
 
-        "movq (%%"REG_c", %1, 2), %%mm0         \n\t" // line 7
+        "naclmovq1 \"(%%"REG_c", %q1, 2)\", %%mm0         \n\t" // line 7
         "pxor %%mm2, %%mm0                      \n\t" //(l4 - l5) <= 0 ? -l7-1 : l7
         "paddusb %%mm1, %%mm0                   \n\t"
         "pxor %%mm2, %%mm0                      \n\t"
-        "movq %%mm0, (%%"REG_c", %1, 2)         \n\t" // line 7
+        "naclmovq2 %%mm0, \"(%%"REG_c", %q1, 2)\"         \n\t" // line 7
 
         :
-        : "r" (src), "r" ((x86_reg)stride), "m" (co->pQPb)
-        : "%"REG_a, "%"REG_c
+        : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride), "m" (co->pQPb)
+        : "%"REG_a, "%"REG_c, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
 
@@ -552,22 +554,22 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
 
 #if 0 //slightly more accurate and slightly slower
         "pxor %%mm7, %%mm7                      \n\t" // 0
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_c"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_c"      \n\t"
 //      0       1       2       3       4       5       6       7
-//      %0      %0+%1   %0+2%1  eax+2%1 %0+4%1  eax+4%1 ecx+%1  ecx+2%1
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  ecx     ecx+%1  ecx+2%1
+//      %q0      %q0+%q1   %q0+2%q1  eax+2%q1 %q0+4%q1  eax+4%q1 ecx+%q1  ecx+2%q1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  ecx     ecx+%q1  ecx+2%q1
 
 
-        "movq (%0, %1, 2), %%mm0                \n\t" // l2
-        "movq (%0), %%mm1                       \n\t" // l0
+        "movq (%q0, %q1, 2), %%mm0                \n\t" // l2
+        "movq (%q0), %%mm1                       \n\t" // l0
         "movq %%mm0, %%mm2                      \n\t" // l2
         PAVGB(%%mm7, %%mm0)                           // ~l2/2
         PAVGB(%%mm1, %%mm0)                           // ~(l2 + 2l0)/4
         PAVGB(%%mm2, %%mm0)                           // ~(5l2 + 2l0)/8
 
         "movq (%%"REG_a"), %%mm1                \n\t" // l1
-        "movq (%%"REG_a", %1, 2), %%mm3         \n\t" // l3
+        "movq (%%"REG_a", %q1, 2), %%mm3         \n\t" // l3
         "movq %%mm1, %%mm4                      \n\t" // l1
         PAVGB(%%mm7, %%mm1)                           // ~l1/2
         PAVGB(%%mm3, %%mm1)                           // ~(l1 + 2l3)/4
@@ -579,7 +581,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "por %%mm0, %%mm1                       \n\t" // ~|2l0 - 5l1 + 5l2 - 2l3|/8
 // mm1= |lenergy|, mm2= l2, mm3= l3, mm7=0
 
-        "movq (%0, %1, 4), %%mm0                \n\t" // l4
+        "movq (%q0, %q1, 4), %%mm0                \n\t" // l4
         "movq %%mm0, %%mm4                      \n\t" // l4
         PAVGB(%%mm7, %%mm0)                           // ~l4/2
         PAVGB(%%mm2, %%mm0)                           // ~(l4 + 2l2)/4
@@ -598,13 +600,13 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "pcmpeqb %%mm7, %%mm0                   \n\t" // SIGN(2l2 - 5l3 + 5l4 - 2l5)
 // mm0= SIGN(menergy), mm1= |lenergy|, mm2= l5, mm3= |menergy|, mm4=l4, mm5= l3, mm7=0
 
-        "movq (%%"REG_c", %1), %%mm6            \n\t" // l6
+        "movq (%%"REG_c", %q1), %%mm6            \n\t" // l6
         "movq %%mm6, %%mm5                      \n\t" // l6
         PAVGB(%%mm7, %%mm6)                           // ~l6/2
         PAVGB(%%mm4, %%mm6)                           // ~(l6 + 2l4)/4
         PAVGB(%%mm5, %%mm6)                           // ~(5l6 + 2l4)/8
 
-        "movq (%%"REG_c", %1, 2), %%mm5         \n\t" // l7
+        "movq (%%"REG_c", %q1, 2), %%mm5         \n\t" // l7
         "movq %%mm2, %%mm4                      \n\t" // l5
         PAVGB(%%mm7, %%mm2)                           // ~l5/2
         PAVGB(%%mm5, %%mm2)                           // ~(l5 + 2l7)/4
@@ -618,7 +620,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
 
 
         PMINUB(%%mm2, %%mm1, %%mm4)                   // MIN(|lenergy|,|renergy|)/8
-        "movq %2, %%mm4                         \n\t" // QP //FIXME QP+1 ?
+        "movq %q2, %%mm4                         \n\t" // QP //FIXME QP+1 ?
         "paddusb "MANGLE(b01)", %%mm4           \n\t"
         "pcmpgtb %%mm3, %%mm4                   \n\t" // |menergy|/8 < QP
         "psubusb %%mm1, %%mm3                   \n\t" // d=|menergy|/8-MIN(|lenergy|,|renergy|)/8
@@ -631,9 +633,9 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "paddusb %%mm1, %%mm3                   \n\t"
 //        "paddusb "MANGLE(b01)", %%mm3           \n\t"
 
-        "movq (%%"REG_a", %1, 2), %%mm6         \n\t" //l3
-        "movq (%0, %1, 4), %%mm5                \n\t" //l4
-        "movq (%0, %1, 4), %%mm4                \n\t" //l4
+        "movq (%%"REG_a", %q1, 2), %%mm6         \n\t" //l3
+        "movq (%q0, %q1, 4), %%mm5                \n\t" //l4
+        "movq (%q0, %q1, 4), %%mm4                \n\t" //l4
         "psubusb %%mm6, %%mm5                   \n\t"
         "psubusb %%mm4, %%mm6                   \n\t"
         "por %%mm6, %%mm5                       \n\t" // |l3-l4|
@@ -645,57 +647,57 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubusb "MANGLE(b01)", %%mm3           \n\t"
         PAVGB(%%mm7, %%mm3)
 
-        "movq (%%"REG_a", %1, 2), %%mm0         \n\t"
-        "movq (%0, %1, 4), %%mm2                \n\t"
+        "movq (%%"REG_a", %q1, 2), %%mm0         \n\t"
+        "movq (%q0, %q1, 4), %%mm2                \n\t"
         "pxor %%mm6, %%mm0                      \n\t"
         "pxor %%mm6, %%mm2                      \n\t"
         "psubb %%mm3, %%mm0                     \n\t"
         "paddb %%mm3, %%mm2                     \n\t"
         "pxor %%mm6, %%mm0                      \n\t"
         "pxor %%mm6, %%mm2                      \n\t"
-        "movq %%mm0, (%%"REG_a", %1, 2)         \n\t"
-        "movq %%mm2, (%0, %1, 4)                \n\t"
+        "movq %%mm0, (%%"REG_a", %q1, 2)         \n\t"
+        "movq %%mm2, (%q0, %q1, 4)                \n\t"
 #endif //0
 
-        "lea (%0, %1), %%"REG_a"                \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
         "pcmpeqb %%mm6, %%mm6                   \n\t" // -1
 //      0       1       2       3       4       5       6       7
-//      %0      %0+%1   %0+2%1  eax+2%1 %0+4%1  eax+4%1 ecx+%1  ecx+2%1
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  ecx     ecx+%1  ecx+2%1
+//      %q0      %q0+%q1   %q0+2%q1  eax+2%q1 %q0+4%q1  eax+4%q1 ecx+%q1  ecx+2%q1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  ecx     ecx+%q1  ecx+2%q1
 
 
-        "movq (%%"REG_a", %1, 2), %%mm1         \n\t" // l3
-        "movq (%0, %1, 4), %%mm0                \n\t" // l4
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm1         \n\t" // l3
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm0                \n\t" // l4
         "pxor %%mm6, %%mm1                      \n\t" // -l3-1
         PAVGB(%%mm1, %%mm0)                           // -q+128 = (l4-l3+256)/2
 // mm1=-l3-1, mm0=128-q
 
-        "movq (%%"REG_a", %1, 4), %%mm2         \n\t" // l5
-        "movq (%%"REG_a", %1), %%mm3            \n\t" // l2
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm2         \n\t" // l5
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm3            \n\t" // l2
         "pxor %%mm6, %%mm2                      \n\t" // -l5-1
         "movq %%mm2, %%mm5                      \n\t" // -l5-1
         "movq "MANGLE(b80)", %%mm4              \n\t" // 128
-        "lea (%%"REG_a", %1, 4), %%"REG_c"      \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_c"      \n\t"
         PAVGB(%%mm3, %%mm2)                           // (l2-l5+256)/2
         PAVGB(%%mm0, %%mm4)                           // ~(l4-l3)/4 + 128
         PAVGB(%%mm2, %%mm4)                           // ~(l2-l5)/4 +(l4-l3)/8 + 128
         PAVGB(%%mm0, %%mm4)                           // ~(l2-l5)/8 +5(l4-l3)/16 + 128
 // mm1=-l3-1, mm0=128-q, mm3=l2, mm4=menergy/16 + 128, mm5= -l5-1
 
-        "movq (%%"REG_a"), %%mm2                \n\t" // l1
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm2                \n\t" // l1
         "pxor %%mm6, %%mm2                      \n\t" // -l1-1
         PAVGB(%%mm3, %%mm2)                           // (l2-l1+256)/2
-        PAVGB((%0), %%mm1)                            // (l0-l3+256)/2
+        PAVGB(%%nacl:(%%r15,%q0), %%mm1)                            // (l0-l3+256)/2
         "movq "MANGLE(b80)", %%mm3              \n\t" // 128
         PAVGB(%%mm2, %%mm3)                           // ~(l2-l1)/4 + 128
         PAVGB(%%mm1, %%mm3)                           // ~(l0-l3)/4 +(l2-l1)/8 + 128
         PAVGB(%%mm2, %%mm3)                           // ~(l0-l3)/8 +5(l2-l1)/16 + 128
 // mm0=128-q, mm3=lenergy/16 + 128, mm4= menergy/16 + 128, mm5= -l5-1
 
-        PAVGB((%%REGc, %1), %%mm5)                    // (l6-l5+256)/2
-        "movq (%%"REG_c", %1, 2), %%mm1         \n\t" // l7
+        NACL_PAVGB1((%%REGc, %q1), %%mm5)                    // (l6-l5+256)/2
+        "naclmovq1 \"(%%"REG_c", %q1, 2)\", %%mm1         \n\t" // l7
         "pxor %%mm6, %%mm1                      \n\t" // -l7-1
-        PAVGB((%0, %1, 4), %%mm1)                     // (l4-l7+256)/2
+        NACL_PAVGB1((%q0, %q1, 4), %%mm1)                     // (l4-l7+256)/2
         "movq "MANGLE(b80)", %%mm2              \n\t" // 128
         PAVGB(%%mm5, %%mm2)                           // ~(l6-l5)/4 + 128
         PAVGB(%%mm1, %%mm2)                           // ~(l4-l7)/4 +(l6-l5)/8 + 128
@@ -713,7 +715,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
 // mm0=128-q, mm3=128 + MIN(|lenergy|,|renergy|)/16, mm4= menergy/16 + 128
 
         "movq "MANGLE(b00)", %%mm7              \n\t" // 0
-        "movq %2, %%mm2                         \n\t" // QP
+        "movq %q2, %%mm2                         \n\t" // QP
         PAVGB(%%mm6, %%mm2)                           // 128 + QP/2
         "psubb %%mm6, %%mm2                     \n\t"
 
@@ -742,20 +744,20 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "pxor %%mm1, %%mm7                      \n\t" // SIGN(d*q)
 
         "pand %%mm7, %%mm4                      \n\t"
-        "movq (%%"REG_a", %1, 2), %%mm0         \n\t"
-        "movq (%0, %1, 4), %%mm2                \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm0         \n\t"
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm2                \n\t"
         "pxor %%mm1, %%mm0                      \n\t"
         "pxor %%mm1, %%mm2                      \n\t"
         "paddb %%mm4, %%mm0                     \n\t"
         "psubb %%mm4, %%mm2                     \n\t"
         "pxor %%mm1, %%mm0                      \n\t"
         "pxor %%mm1, %%mm2                      \n\t"
-        "movq %%mm0, (%%"REG_a", %1, 2)         \n\t"
-        "movq %%mm2, (%0, %1, 4)                \n\t"
+        "naclmovq2 %%mm0, \"(%%"REG_a", %q1, 2)\"         \n\t"
+        "naclmovq2 %%mm2, \"(%q0, %q1, 4)\"                \n\t"
 
         :
         : "r" (src), "r" ((x86_reg)stride), "m" (c->pQPb)
-        : "%"REG_a, "%"REG_c
+        : "%"REG_a, "%"REG_c, "%r14"
     );
 
 /*
@@ -806,7 +808,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
             }
             if(y==4) bias+=d;
             num++;
-            if(num%1000000 == 0){
+            if(num%q1000000 == 0){
                 av_log(c, AV_LOG_INFO, " %d %d %d %d\n", num, sum, max, bias);
             }
         }
@@ -819,21 +821,21 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
     __asm__ volatile(
         "pxor %%mm7, %%mm7                      \n\t"
 //      0       1       2       3       4       5       6       7
-//      %0      %0+%1   %0+2%1  eax+2%1 %0+4%1  eax+4%1 edx+%1  edx+2%1
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1
+//      %q0      %q0+%q1   %q0+2%q1  eax+2%q1 %q0+4%q1  eax+4%q1 edx+%q1  edx+2%q1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1
 
-        "movq (%0), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
         "movq %%mm0, %%mm1                      \n\t"
         "punpcklbw %%mm7, %%mm0                 \n\t" // low part of line 0
         "punpckhbw %%mm7, %%mm1                 \n\t" // high part of line 0
 
-        "movq (%0, %1), %%mm2                   \n\t"
-        "lea (%0, %1, 2), %%"REG_a"             \n\t"
+        "naclmovq1 \"(%q0, %q1)\", %%mm2                   \n\t"
+        "lea (%q0, %q1, 2), %%"REG_a"             \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "punpcklbw %%mm7, %%mm2                 \n\t" // low part of line 1
         "punpckhbw %%mm7, %%mm3                 \n\t" // high part of line 1
 
-        "movq (%%"REG_a"), %%mm4                \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm4                \n\t"
         "movq %%mm4, %%mm5                      \n\t"
         "punpcklbw %%mm7, %%mm4                 \n\t" // low part of line 2
         "punpckhbw %%mm7, %%mm5                 \n\t" // high part of line 2
@@ -850,7 +852,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm2, %%mm0                     \n\t" // 2L0 - 5L1 + 5L2
         "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2
 
-        "movq (%%"REG_a", %1), %%mm2            \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm2            \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "punpcklbw %%mm7, %%mm2                 \n\t" // L3
         "punpckhbw %%mm7, %%mm3                 \n\t" // H3
@@ -859,30 +861,30 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2 - H3
         "psubw %%mm2, %%mm0                     \n\t" // 2L0 - 5L1 + 5L2 - 2L3
         "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2 - 2H3
-        "movq %%mm0, (%3)                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
-        "movq %%mm1, 8(%3)                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
+        "movq %%mm0, %%nacl:(%%r15, %q3)                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
+        "movq %%mm1, %%nacl:8(%%r15, %q3)                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
 
-        "movq (%%"REG_a", %1, 2), %%mm0         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm0         \n\t"
         "movq %%mm0, %%mm1                      \n\t"
         "punpcklbw %%mm7, %%mm0                 \n\t" // L4
         "punpckhbw %%mm7, %%mm1                 \n\t" // H4
 
         "psubw %%mm0, %%mm2                     \n\t" // L3 - L4
         "psubw %%mm1, %%mm3                     \n\t" // H3 - H4
-        "movq %%mm2, 16(%3)                     \n\t" // L3 - L4
-        "movq %%mm3, 24(%3)                     \n\t" // H3 - H4
+        "movq %%mm2, %%nacl:16(%%r15, %q3)                     \n\t" // L3 - L4
+        "movq %%mm3, %%nacl:24(%%r15, %q3)                     \n\t" // H3 - H4
         "paddw %%mm4, %%mm4                     \n\t" // 2L2
         "paddw %%mm5, %%mm5                     \n\t" // 2H2
         "psubw %%mm2, %%mm4                     \n\t" // 2L2 - L3 + L4
         "psubw %%mm3, %%mm5                     \n\t" // 2H2 - H3 + H4
 
-        "lea (%%"REG_a", %1), %0                \n\t"
+        "lea (%%"REG_a", %q1), %q0                \n\t"
         "psllw $2, %%mm2                        \n\t" // 4L3 - 4L4
         "psllw $2, %%mm3                        \n\t" // 4H3 - 4H4
         "psubw %%mm2, %%mm4                     \n\t" // 2L2 - 5L3 + 5L4
         "psubw %%mm3, %%mm5                     \n\t" // 2H2 - 5H3 + 5H4
 //50 opcodes so far
-        "movq (%0, %1, 2), %%mm2                \n\t"
+        "naclmovq1 \"(%q0, %q1, 2)\", %%mm2                \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "punpcklbw %%mm7, %%mm2                 \n\t" // L5
         "punpckhbw %%mm7, %%mm3                 \n\t" // H5
@@ -891,10 +893,10 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm2, %%mm4                     \n\t" // 2L2 - 5L3 + 5L4 - 2L5
         "psubw %%mm3, %%mm5                     \n\t" // 2H2 - 5H3 + 5H4 - 2H5
 
-        "movq (%%"REG_a", %1, 4), %%mm6         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm6         \n\t"
         "punpcklbw %%mm7, %%mm6                 \n\t" // L6
         "psubw %%mm6, %%mm2                     \n\t" // L5 - L6
-        "movq (%%"REG_a", %1, 4), %%mm6         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm6         \n\t"
         "punpckhbw %%mm7, %%mm6                 \n\t" // H6
         "psubw %%mm6, %%mm3                     \n\t" // H5 - H6
 
@@ -908,7 +910,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm2, %%mm0                     \n\t" // 2L4 - 5L5 + 5L6
         "psubw %%mm3, %%mm1                     \n\t" // 2H4 - 5H5 + 5H6
 
-        "movq (%0, %1, 4), %%mm2                \n\t"
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm2                \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "punpcklbw %%mm7, %%mm2                 \n\t" // L7
         "punpckhbw %%mm7, %%mm3                 \n\t" // H7
@@ -918,8 +920,8 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm2, %%mm0                     \n\t" // 2L4 - 5L5 + 5L6 - 2L7
         "psubw %%mm3, %%mm1                     \n\t" // 2H4 - 5H5 + 5H6 - 2H7
 
-        "movq (%3), %%mm2                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
-        "movq 8(%3), %%mm3                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
+        "movq %%nacl:(%%r15, %q3), %%mm2                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
+        "movq %%nacl:8(%%r15, %q3), %%mm3                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
 
 #if TEMPLATE_PP_MMXEXT
         "movq %%mm7, %%mm6                      \n\t" // 0
@@ -965,7 +967,7 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm6, %%mm1                     \n\t"
 #endif
 
-        "movd %2, %%mm2                         \n\t" // QP
+        "movd %q2, %%mm2                         \n\t" // QP
         "punpcklbw %%mm7, %%mm2                 \n\t"
 
         "movq %%mm7, %%mm6                      \n\t" // 0
@@ -997,8 +999,8 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psrlw $6, %%mm4                        \n\t"
         "psrlw $6, %%mm5                        \n\t"
 
-        "movq 16(%3), %%mm0                     \n\t" // L3 - L4
-        "movq 24(%3), %%mm1                     \n\t" // H3 - H4
+        "movq %%nacl:16(%%r15, %q3), %%mm0                     \n\t" // L3 - L4
+        "movq %%nacl:24(%%r15, %q3), %%mm1                     \n\t" // H3 - H4
 
         "pxor %%mm2, %%mm2                      \n\t"
         "pxor %%mm3, %%mm3                      \n\t"
@@ -1033,16 +1035,16 @@ static inline void RENAME(doVertDefFilter)(uint8_t src[], int stride, PPContext
         "psubw %%mm6, %%mm4                     \n\t"
         "psubw %%mm7, %%mm5                     \n\t"
         "packsswb %%mm5, %%mm4                  \n\t"
-        "movq (%0), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
         "paddb   %%mm4, %%mm0                   \n\t"
-        "movq %%mm0, (%0)                       \n\t"
-        "movq (%0, %1), %%mm0                   \n\t"
+        "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t"
+        "naclmovq1 \"(%q0, %q1)\", %%mm0                   \n\t"
         "psubb %%mm4, %%mm0                     \n\t"
-        "movq %%mm0, (%0, %1)                   \n\t"
+        "naclmovq2 %%mm0, \"(%q0, %q1)\"                   \n\t"
 
         : "+r" (src)
         : "r" ((x86_reg)stride), "m" (c->pQPb), "r"(tmp)
-        : "%"REG_a
+        : "%"REG_a, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     const int l1= stride;
@@ -1094,29 +1096,29 @@ static inline void RENAME(dering)(uint8_t src[], int stride, PPContext *c)
     __asm__ volatile(
         "pxor %%mm6, %%mm6                      \n\t"
         "pcmpeqb %%mm7, %%mm7                   \n\t"
-        "movq %2, %%mm0                         \n\t"
+        "movq %q2, %%mm0                         \n\t"
         "punpcklbw %%mm6, %%mm0                 \n\t"
         "psrlw $1, %%mm0                        \n\t"
         "psubw %%mm7, %%mm0                     \n\t"
         "packuswb %%mm0, %%mm0                  \n\t"
-        "movq %%mm0, %3                         \n\t"
+        "movq %%mm0, %q3                         \n\t"
 
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
 
 //        0        1        2        3        4        5        6        7        8        9
-//        %0        eax        eax+%1        eax+2%1        %0+4%1        edx        edx+%1        edx+2%1        %0+8%1        edx+4%1
+//        %q0        eax        eax+%q1        eax+2%q1        %q0+4%q1        edx        edx+%q1        edx+2%q1        %q0+8%q1        edx+4%q1
 
 #undef REAL_FIND_MIN_MAX
 #undef FIND_MIN_MAX
 #if TEMPLATE_PP_MMXEXT
 #define REAL_FIND_MIN_MAX(addr)\
-        "movq " #addr ", %%mm0                  \n\t"\
+        "naclmovq1 \"" #addr "\", %%mm0                  \n\t"\
         "pminub %%mm0, %%mm7                    \n\t"\
         "pmaxub %%mm0, %%mm6                    \n\t"
 #else
 #define REAL_FIND_MIN_MAX(addr)\
-        "movq " #addr ", %%mm0                  \n\t"\
+        "naclmovq1 \"" #addr "\", %%mm0                  \n\t"\
         "movq %%mm7, %%mm1                      \n\t"\
         "psubusb %%mm0, %%mm6                   \n\t"\
         "paddb %%mm0, %%mm6                     \n\t"\
@@ -1126,13 +1128,13 @@ static inline void RENAME(dering)(uint8_t src[], int stride, PPContext *c)
 #define FIND_MIN_MAX(addr)  REAL_FIND_MIN_MAX(addr)
 
 FIND_MIN_MAX((%%REGa))
-FIND_MIN_MAX((%%REGa, %1))
-FIND_MIN_MAX((%%REGa, %1, 2))
-FIND_MIN_MAX((%0, %1, 4))
+FIND_MIN_MAX((%%REGa, %q1))
+FIND_MIN_MAX((%%REGa, %q1, 2))
+FIND_MIN_MAX((%q0, %q1, 4))
 FIND_MIN_MAX((%%REGd))
-FIND_MIN_MAX((%%REGd, %1))
-FIND_MIN_MAX((%%REGd, %1, 2))
-FIND_MIN_MAX((%0, %1, 8))
+FIND_MIN_MAX((%%REGd, %q1))
+FIND_MIN_MAX((%%REGd, %q1, 2))
+FIND_MIN_MAX((%q0, %q1, 8))
 
         "movq %%mm7, %%mm4                      \n\t"
         "psrlq $8, %%mm7                        \n\t"
@@ -1181,24 +1183,24 @@ FIND_MIN_MAX((%0, %1, 8))
 #endif
         "movq %%mm6, %%mm0                      \n\t" // max
         "psubb %%mm7, %%mm6                     \n\t" // max - min
-        "push %4                              \n\t"
+        "push %q4                              \n\t"
         "movd %%mm6, %k4                        \n\t"
         "cmpb "MANGLE(deringThreshold)", %b4    \n\t"
-        "pop %4                               \n\t"
+        "pop %q4                               \n\t"
         " jb 1f                                 \n\t"
         PAVGB(%%mm0, %%mm7)                           // a=(max + min)/2
         "punpcklbw %%mm7, %%mm7                 \n\t"
         "punpcklbw %%mm7, %%mm7                 \n\t"
         "punpcklbw %%mm7, %%mm7                 \n\t"
-        "movq %%mm7, (%4)                       \n\t"
+        "movq %%mm7, %%nacl:(%%r15, %q4)                       \n\t"
 
-        "movq (%0), %%mm0                       \n\t" // L10
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L10
         "movq %%mm0, %%mm1                      \n\t" // L10
         "movq %%mm0, %%mm2                      \n\t" // L10
         "psllq $8, %%mm1                        \n\t"
         "psrlq $8, %%mm2                        \n\t"
-        "movd -4(%0), %%mm3                     \n\t"
-        "movd 8(%0), %%mm4                      \n\t"
+        "movd %%nacl:-4(%%r15, %q0), %%mm3                     \n\t"
+        "movd %%nacl:8(%%r15, %q0), %%mm4                      \n\t"
         "psrlq $24, %%mm3                       \n\t"
         "psllq $56, %%mm4                       \n\t"
         "por %%mm3, %%mm1                       \n\t" // L00
@@ -1215,13 +1217,13 @@ FIND_MIN_MAX((%0, %1, 8))
         "paddb %%mm2, %%mm0                     \n\t"
         "paddb %%mm3, %%mm0                     \n\t"
 
-        "movq (%%"REG_a"), %%mm2                \n\t" // L11
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm2                \n\t" // L11
         "movq %%mm2, %%mm3                      \n\t" // L11
         "movq %%mm2, %%mm4                      \n\t" // L11
         "psllq $8, %%mm3                        \n\t"
         "psrlq $8, %%mm4                        \n\t"
-        "movd -4(%%"REG_a"), %%mm5              \n\t"
-        "movd 8(%%"REG_a"), %%mm6               \n\t"
+        "movd %%nacl:-4(%%r15, %%"REG_a"), %%mm5              \n\t"
+        "movd %%nacl:8(%%r15, %%"REG_a"), %%mm6               \n\t"
         "psrlq $24, %%mm5                       \n\t"
         "psllq $56, %%mm6                       \n\t"
         "por %%mm5, %%mm3                       \n\t" // L01
@@ -1239,23 +1241,23 @@ FIND_MIN_MAX((%0, %1, 8))
         "paddb %%mm5, %%mm2                     \n\t"
 // 0, 2, 3, 1
 #define REAL_DERING_CORE(dst,src,ppsx,psx,sx,pplx,plx,lx,t0,t1) \
-        "movq " #src ", " #sx "                 \n\t" /* src[0] */\
+        "naclmovq1 \"" #src "\", " #sx "                 \n\t" /* src[0] */\
         "movq " #sx ", " #lx "                  \n\t" /* src[0] */\
         "movq " #sx ", " #t0 "                  \n\t" /* src[0] */\
         "psllq $8, " #lx "                      \n\t"\
         "psrlq $8, " #t0 "                      \n\t"\
-        "movd -4" #src ", " #t1 "               \n\t"\
+        "naclmovd1 \"-4" #src "\", " #t1 "               \n\t"\
         "psrlq $24, " #t1 "                     \n\t"\
         "por " #t1 ", " #lx "                   \n\t" /* src[-1] */\
-        "movd 8" #src ", " #t1 "                \n\t"\
+        "naclmovd1 \"8" #src "\", " #t1 "                \n\t"\
         "psllq $56, " #t1 "                     \n\t"\
         "por " #t1 ", " #t0 "                   \n\t" /* src[+1] */\
         "movq " #lx ", " #t1 "                  \n\t" /* src[-1] */\
         PAVGB(t0, lx)                                 /* (src[-1] + src[+1])/2 */\
         PAVGB(sx, lx)                                 /* (src[-1] + 2src[0] + src[+1])/4 */\
         PAVGB(lx, pplx)                                     \
-        "movq " #lx ", 8(%4)                    \n\t"\
-        "movq (%4), " #lx "                     \n\t"\
+        "movq " #lx ", %%nacl:8(%%r15, %q4)                    \n\t"\
+        "movq %%nacl:(%%r15, %q4), " #lx "                     \n\t"\
         "psubusb " #lx ", " #t1 "               \n\t"\
         "psubusb " #lx ", " #t0 "               \n\t"\
         "psubusb " #lx ", " #sx "               \n\t"\
@@ -1267,10 +1269,10 @@ FIND_MIN_MAX((%0, %1, 8))
         "paddb " #t0 ", " #sx "                 \n\t"\
 \
         PAVGB(plx, pplx)                              /* filtered */\
-        "movq " #dst ", " #t0 "                 \n\t" /* dst */\
+        "naclmovq1 \"" #dst "\", " #t0 "                 \n\t" /* dst */\
         "movq " #t0 ", " #t1 "                  \n\t" /* dst */\
-        "psubusb %3, " #t0 "                    \n\t"\
-        "paddusb %3, " #t1 "                    \n\t"\
+        "psubusb %q3, " #t0 "                    \n\t"\
+        "paddusb %q3, " #t1 "                    \n\t"\
         PMAXUB(t0, pplx)\
         PMINUB(t1, pplx, t0)\
         "paddb " #sx ", " #ppsx "               \n\t"\
@@ -1279,10 +1281,10 @@ FIND_MIN_MAX((%0, %1, 8))
         "pand "MANGLE(b08)", " #ppsx "          \n\t"\
         "pcmpeqb " #lx ", " #ppsx "             \n\t"\
         "pand " #ppsx ", " #pplx "              \n\t"\
-        "pandn " #dst ", " #ppsx "              \n\t"\
+        "naclpandn1 \"" #dst "\", " #ppsx "              \n\t"\
         "por " #pplx ", " #ppsx "               \n\t"\
-        "movq " #ppsx ", " #dst "               \n\t"\
-        "movq 8(%4), " #lx "                    \n\t"
+        "naclmovq2 " #ppsx ", \"" #dst "\"               \n\t"\
+        "movq %%nacl:8(%%r15, %q4), " #lx "                    \n\t"
 
 #define DERING_CORE(dst,src,ppsx,psx,sx,pplx,plx,lx,t0,t1) \
    REAL_DERING_CORE(dst,src,ppsx,psx,sx,pplx,plx,lx,t0,t1)
@@ -1302,18 +1304,18 @@ FIND_MIN_MAX((%0, %1, 8))
 
 */
 //DERING_CORE(dst          ,src            ,ppsx ,psx  ,sx   ,pplx ,plx  ,lx   ,t0   ,t1)
-DERING_CORE((%%REGa)       ,(%%REGa, %1)   ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
-DERING_CORE((%%REGa, %1)   ,(%%REGa, %1, 2),%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
-DERING_CORE((%%REGa, %1, 2),(%0, %1, 4)    ,%%mm4,%%mm0,%%mm2,%%mm5,%%mm1,%%mm3,%%mm6,%%mm7)
-DERING_CORE((%0, %1, 4)    ,(%%REGd)       ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
-DERING_CORE((%%REGd)       ,(%%REGd, %1)   ,%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
-DERING_CORE((%%REGd, %1)   ,(%%REGd, %1, 2),%%mm4,%%mm0,%%mm2,%%mm5,%%mm1,%%mm3,%%mm6,%%mm7)
-DERING_CORE((%%REGd, %1, 2),(%0, %1, 8)    ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
-DERING_CORE((%0, %1, 8)    ,(%%REGd, %1, 4),%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
+DERING_CORE((%%REGa)       ,(%%REGa, %q1)   ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
+DERING_CORE((%%REGa, %q1)   ,(%%REGa, %q1, 2),%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
+DERING_CORE((%%REGa, %q1, 2),(%q0, %q1, 4)    ,%%mm4,%%mm0,%%mm2,%%mm5,%%mm1,%%mm3,%%mm6,%%mm7)
+DERING_CORE((%q0, %q1, 4)    ,(%%REGd)       ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
+DERING_CORE((%%REGd)       ,(%%REGd, %q1)   ,%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
+DERING_CORE((%%REGd, %q1)   ,(%%REGd, %q1, 2),%%mm4,%%mm0,%%mm2,%%mm5,%%mm1,%%mm3,%%mm6,%%mm7)
+DERING_CORE((%%REGd, %q1, 2),(%q0, %q1, 8)    ,%%mm0,%%mm2,%%mm4,%%mm1,%%mm3,%%mm5,%%mm6,%%mm7)
+DERING_CORE((%q0, %q1, 8)    ,(%%REGd, %q1, 4),%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,%%mm6,%%mm7)
 
         "1:                        \n\t"
-        : : "r" (src), "r" ((x86_reg)stride), "m" (c->pQPb), "m"(c->pQPb2), "q"(tmp)
-        : "%"REG_a, "%"REG_d, "%"REG_SP
+        : : "r" (src), "r" ((x86_reg)stride), "m" (c->pQPb), "m"(c->pQPb2), "q"((x86_reg_addr)tmp)
+        : "%"REG_a, "%"REG_d, "%"REG_SP, "%r14"
     );
 #else // HAVE_7REGS && (TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW)
     int y;
@@ -1405,8 +1407,8 @@ DERING_CORE((%0, %1, 8)    ,(%%REGd, %1, 4),%%mm2,%%mm4,%%mm0,%%mm3,%%mm5,%%mm1,
                         errorSum+= error;
 
                         if(1024LL*1024LL*1024LL % numSkipped == 0){
-                            av_log(c, AV_LOG_INFO, "sum:%1.3f, skip:%d, wQP:%d, "
-                                   "wRange:%d, wDiff:%d, relSkip:%1.3f\n",
+                            av_log(c, AV_LOG_INFO, "sum:%q1.3f, skip:%d, wQP:%d, "
+                                   "wRange:%d, wDiff:%d, relSkip:%q1.3f\n",
                                    (float)errorSum/numSkipped, numSkipped, worstQP, worstRange,
                                    worstDiff, (float)numSkipped/numPixels);
                         }
@@ -1448,27 +1450,27 @@ static inline void RENAME(deInterlaceInterpolateLinear)(uint8_t src[], int strid
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= 4*stride;
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_c"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_c"      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  ecx     ecx+%1  ecx+2%1 %0+8%1  ecx+4%1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  ecx     ecx+%q1  ecx+2%q1 %q0+8%q1  ecx+4%q1
 
-        "movq (%0), %%mm0                       \n\t"
-        "movq (%%"REG_a", %1), %%mm1            \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm1            \n\t"
         PAVGB(%%mm1, %%mm0)
-        "movq %%mm0, (%%"REG_a")                \n\t"
-        "movq (%0, %1, 4), %%mm0                \n\t"
+        "movq %%mm0, %%nacl:(%%r15, %%"REG_a")                \n\t"
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm0                \n\t"
         PAVGB(%%mm0, %%mm1)
-        "movq %%mm1, (%%"REG_a", %1, 2)         \n\t"
-        "movq (%%"REG_c", %1), %%mm1            \n\t"
+        "naclmovq2 %%mm1, \"(%%"REG_a", %q1, 2)\"         \n\t"
+        "naclmovq1 \"(%%"REG_c", %q1)\", %%mm1            \n\t"
         PAVGB(%%mm1, %%mm0)
-        "movq %%mm0, (%%"REG_c")                \n\t"
-        "movq (%0, %1, 8), %%mm0                \n\t"
+        "movq %%mm0, %%nacl:(%%r15, %%"REG_c")                \n\t"
+        "naclmovq1 \"(%q0, %q1, 8)\", %%mm0                \n\t"
         PAVGB(%%mm0, %%mm1)
-        "movq %%mm1, (%%"REG_c", %1, 2)         \n\t"
+        "naclmovq2 %%mm1, \"(%%"REG_c", %q1, 2)\"         \n\t"
 
         : : "r" (src), "r" ((x86_reg)stride)
-        : "%"REG_a, "%"REG_c
+        : "%"REG_a, "%"REG_c, "%r14"
     );
 #else
     int a, b, x;
@@ -1501,17 +1503,17 @@ static inline void RENAME(deInterlaceInterpolateCubic)(uint8_t src[], int stride
 #if TEMPLATE_PP_SSE2 || TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= stride*3;
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
-        "lea (%%"REG_d", %1, 4), %%"REG_c"      \n\t"
-        "add %1, %%"REG_c"                      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
+        "lea (%%"REG_d", %q1, 4), %%"REG_c"      \n\t"
+        "add %q1, %%"REG_c"                      \n\t"
 #if TEMPLATE_PP_SSE2
         "pxor %%xmm7, %%xmm7                    \n\t"
 #define REAL_DEINT_CUBIC(a,b,c,d,e)\
-        "movq " #a ", %%xmm0                    \n\t"\
-        "movq " #b ", %%xmm1                    \n\t"\
-        "movq " #d ", %%xmm2                    \n\t"\
-        "movq " #e ", %%xmm3                    \n\t"\
+        "naclmovq1 \"" #a "\", %%xmm0                    \n\t"\
+        "naclmovq1 \"" #b "\", %%xmm1                    \n\t"\
+        "naclmovq1 \"" #d "\", %%xmm2                    \n\t"\
+        "naclmovq1 \"" #e "\", %%xmm3                    \n\t"\
         "pavgb %%xmm2, %%xmm1                   \n\t"\
         "pavgb %%xmm3, %%xmm0                   \n\t"\
         "punpcklbw %%xmm7, %%xmm0               \n\t"\
@@ -1520,17 +1522,17 @@ static inline void RENAME(deInterlaceInterpolateCubic)(uint8_t src[], int stride
         "psraw $3, %%xmm0                       \n\t"\
         "psubw %%xmm0, %%xmm1                   \n\t"\
         "packuswb %%xmm1, %%xmm1                \n\t"\
-        "movlps %%xmm1, " #c "                  \n\t"
+        "naclmovlps2 %%xmm1, \"" #c "\"                  \n\t"
 #else //TEMPLATE_PP_SSE2
         "pxor %%mm7, %%mm7                      \n\t"
 //      0       1       2       3       4       5       6       7       8       9       10
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1 ecx
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1 ecx
 
 #define REAL_DEINT_CUBIC(a,b,c,d,e)\
-        "movq " #a ", %%mm0                     \n\t"\
-        "movq " #b ", %%mm1                     \n\t"\
-        "movq " #d ", %%mm2                     \n\t"\
-        "movq " #e ", %%mm3                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm0                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm1                     \n\t"\
+        "naclmovq1 \"" #d "\", %%mm2                     \n\t"\
+        "naclmovq1 \"" #e "\", %%mm3                     \n\t"\
         PAVGB(%%mm2, %%mm1)                             /* (b+d) /2 */\
         PAVGB(%%mm3, %%mm0)                             /* (a+e) /2 */\
         "movq %%mm0, %%mm2                      \n\t"\
@@ -1546,21 +1548,21 @@ static inline void RENAME(deInterlaceInterpolateCubic)(uint8_t src[], int stride
         "psubw %%mm0, %%mm1                     \n\t"   /* L(9b + 9d - a - e)/16 */\
         "psubw %%mm2, %%mm3                     \n\t"   /* H(9b + 9d - a - e)/16 */\
         "packuswb %%mm3, %%mm1                  \n\t"\
-        "movq %%mm1, " #c "                     \n\t"
+        "naclmovq2 %%mm1, \"" #c "\"                     \n\t"
 #endif //TEMPLATE_PP_SSE2
 #define DEINT_CUBIC(a,b,c,d,e)  REAL_DEINT_CUBIC(a,b,c,d,e)
 
-DEINT_CUBIC((%0)        , (%%REGa, %1), (%%REGa, %1, 2), (%0, %1, 4) , (%%REGd, %1))
-DEINT_CUBIC((%%REGa, %1), (%0, %1, 4) , (%%REGd)       , (%%REGd, %1), (%0, %1, 8))
-DEINT_CUBIC((%0, %1, 4) , (%%REGd, %1), (%%REGd, %1, 2), (%0, %1, 8) , (%%REGc))
-DEINT_CUBIC((%%REGd, %1), (%0, %1, 8) , (%%REGd, %1, 4), (%%REGc)    , (%%REGc, %1, 2))
+DEINT_CUBIC((%q0)        , (%%REGa, %q1), (%%REGa, %q1, 2), (%q0, %q1, 4) , (%%REGd, %q1))
+DEINT_CUBIC((%%REGa, %q1), (%q0, %q1, 4) , (%%REGd)       , (%%REGd, %q1), (%q0, %q1, 8))
+DEINT_CUBIC((%q0, %q1, 4) , (%%REGd, %q1), (%%REGd, %q1, 2), (%q0, %q1, 8) , (%%REGc))
+DEINT_CUBIC((%%REGd, %q1), (%q0, %q1, 8) , (%%REGd, %q1, 4), (%%REGc)    , (%%REGc, %q1, 2))
 
-        : : "r" (src), "r" ((x86_reg)stride)
+        : : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride)
         :
 #if TEMPLATE_PP_SSE2
         XMM_CLOBBERS("%xmm0", "%xmm1", "%xmm2", "%xmm3", "%xmm7",)
 #endif
-        "%"REG_a, "%"REG_d, "%"REG_c
+        "%"REG_a, "%"REG_d, "%"REG_c, "%r14"
     );
 #undef REAL_DEINT_CUBIC
 #else //TEMPLATE_PP_SSE2 || TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
@@ -1588,18 +1590,18 @@ static inline void RENAME(deInterlaceFF)(uint8_t src[], int stride, uint8_t *tmp
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= stride*4;
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
         "pxor %%mm7, %%mm7                      \n\t"
-        "movq (%2), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t"
 //      0       1       2       3       4       5       6       7       8       9       10
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1 ecx
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1 ecx
 
 #define REAL_DEINT_FF(a,b,c,d)\
-        "movq " #a ", %%mm1                     \n\t"\
-        "movq " #b ", %%mm2                     \n\t"\
-        "movq " #c ", %%mm3                     \n\t"\
-        "movq " #d ", %%mm4                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm1                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm2                     \n\t"\
+        "naclmovq1 \"" #c "\", %%mm3                     \n\t"\
+        "naclmovq1 \"" #d "\", %%mm4                     \n\t"\
         PAVGB(%%mm3, %%mm1)                          \
         PAVGB(%%mm4, %%mm0)                          \
         "movq %%mm0, %%mm3                      \n\t"\
@@ -1621,18 +1623,18 @@ static inline void RENAME(deInterlaceFF)(uint8_t src[], int stride, uint8_t *tmp
         "psraw $2, %%mm1                        \n\t"\
         "psraw $2, %%mm4                        \n\t"\
         "packuswb %%mm4, %%mm1                  \n\t"\
-        "movq %%mm1, " #b "                     \n\t"\
+        "naclmovq2 %%mm1, \"" #b "\"                     \n\t"\
 
 #define DEINT_FF(a,b,c,d)  REAL_DEINT_FF(a,b,c,d)
 
-DEINT_FF((%0)        , (%%REGa)       , (%%REGa, %1), (%%REGa, %1, 2))
-DEINT_FF((%%REGa, %1), (%%REGa, %1, 2), (%0, %1, 4) , (%%REGd)       )
-DEINT_FF((%0, %1, 4) , (%%REGd)       , (%%REGd, %1), (%%REGd, %1, 2))
-DEINT_FF((%%REGd, %1), (%%REGd, %1, 2), (%0, %1, 8) , (%%REGd, %1, 4))
+DEINT_FF((%q0)        , (%%REGa)       , (%%REGa, %q1), (%%REGa, %q1, 2))
+DEINT_FF((%%REGa, %q1), (%%REGa, %q1, 2), (%q0, %q1, 4) , (%%REGd)       )
+DEINT_FF((%q0, %q1, 4) , (%%REGd)       , (%%REGd, %q1), (%%REGd, %q1, 2))
+DEINT_FF((%%REGd, %q1), (%%REGd, %q1, 2), (%q0, %q1, 8) , (%%REGd, %q1, 4))
 
-        "movq %%mm0, (%2)                       \n\t"
-        : : "r" (src), "r" ((x86_reg)stride), "r"(tmp)
-        : "%"REG_a, "%"REG_d
+        "movq %%mm0, %%nacl:(%%r15, %q2)                       \n\t"
+        : : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride), "r"((x86_reg_addr)tmp)
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     int x;
@@ -1667,18 +1669,18 @@ static inline void RENAME(deInterlaceL5)(uint8_t src[], int stride, uint8_t *tmp
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= stride*4;
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
         "pxor %%mm7, %%mm7                      \n\t"
-        "movq (%2), %%mm0                       \n\t"
-        "movq (%3), %%mm1                       \n\t"
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %q3), %%mm1                       \n\t"
 //      0       1       2       3       4       5       6       7       8       9       10
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1 ecx
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1 ecx
 
 #define REAL_DEINT_L5(t1,t2,a,b,c)\
-        "movq " #a ", %%mm2                     \n\t"\
-        "movq " #b ", %%mm3                     \n\t"\
-        "movq " #c ", %%mm4                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm2                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm3                     \n\t"\
+        "naclmovq1 \"" #c "\", %%mm4                     \n\t"\
         PAVGB(t2, %%mm3)                             \
         PAVGB(t1, %%mm4)                             \
         "movq %%mm2, %%mm5                      \n\t"\
@@ -1706,23 +1708,24 @@ static inline void RENAME(deInterlaceL5)(uint8_t src[], int stride, uint8_t *tmp
         "psraw $2, %%mm2                        \n\t"\
         "psraw $2, %%mm5                        \n\t"\
         "packuswb %%mm5, %%mm2                  \n\t"\
-        "movq %%mm2, " #a "                     \n\t"\
+        "naclmovq2 %%mm2, \"" #a "\"                     \n\t"\
 
 #define DEINT_L5(t1,t2,a,b,c)  REAL_DEINT_L5(t1,t2,a,b,c)
 
-DEINT_L5(%%mm0, %%mm1, (%0)           , (%%REGa)       , (%%REGa, %1)   )
-DEINT_L5(%%mm1, %%mm0, (%%REGa)       , (%%REGa, %1)   , (%%REGa, %1, 2))
-DEINT_L5(%%mm0, %%mm1, (%%REGa, %1)   , (%%REGa, %1, 2), (%0, %1, 4)   )
-DEINT_L5(%%mm1, %%mm0, (%%REGa, %1, 2), (%0, %1, 4)    , (%%REGd)       )
-DEINT_L5(%%mm0, %%mm1, (%0, %1, 4)    , (%%REGd)       , (%%REGd, %1)   )
-DEINT_L5(%%mm1, %%mm0, (%%REGd)       , (%%REGd, %1)   , (%%REGd, %1, 2))
-DEINT_L5(%%mm0, %%mm1, (%%REGd, %1)   , (%%REGd, %1, 2), (%0, %1, 8)   )
-DEINT_L5(%%mm1, %%mm0, (%%REGd, %1, 2), (%0, %1, 8)    , (%%REGd, %1, 4))
-
-        "movq %%mm0, (%2)                       \n\t"
-        "movq %%mm1, (%3)                       \n\t"
-        : : "r" (src), "r" ((x86_reg)stride), "r"(tmp), "r"(tmp2)
-        : "%"REG_a, "%"REG_d
+DEINT_L5(%%mm0, %%mm1, (%q0)           , (%%REGa)       , (%%REGa, %q1)   )
+DEINT_L5(%%mm1, %%mm0, (%%REGa)       , (%%REGa, %q1)   , (%%REGa, %q1, 2))
+DEINT_L5(%%mm0, %%mm1, (%%REGa, %q1)   , (%%REGa, %q1, 2), (%q0, %q1, 4)   )
+DEINT_L5(%%mm1, %%mm0, (%%REGa, %q1, 2), (%q0, %q1, 4)    , (%%REGd)       )
+DEINT_L5(%%mm0, %%mm1, (%q0, %q1, 4)    , (%%REGd)       , (%%REGd, %q1)   )
+DEINT_L5(%%mm1, %%mm0, (%%REGd)       , (%%REGd, %q1)   , (%%REGd, %q1, 2))
+DEINT_L5(%%mm0, %%mm1, (%%REGd, %q1)   , (%%REGd, %q1, 2), (%q0, %q1, 8)   )
+DEINT_L5(%%mm1, %%mm0, (%%REGd, %q1, 2), (%q0, %q1, 8)    , (%%REGd, %q1, 4))
+
+        "movq %%mm0, %%nacl:(%%r15, %q2)                       \n\t"
+        "movq %%mm1, %%nacl:(%%r15, %q3)                       \n\t"
+        : : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride),
+        "r"((x86_reg_addr)tmp), "r"((x86_reg_addr)tmp2)
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     int x;
@@ -1768,49 +1771,50 @@ static inline void RENAME(deInterlaceBlendLinear)(uint8_t src[], int stride, uin
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     src+= 4*stride;
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1
 
-        "movq (%2), %%mm0                       \n\t" // L0
-        "movq (%%"REG_a"), %%mm1                \n\t" // L2
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t" // L0
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t" // L2
         PAVGB(%%mm1, %%mm0)                           // L0+L2
-        "movq (%0), %%mm2                       \n\t" // L1
+        "movq %%nacl:(%%r15, %q0), %%mm2                       \n\t" // L1
         PAVGB(%%mm2, %%mm0)
-        "movq %%mm0, (%0)                       \n\t"
-        "movq (%%"REG_a", %1), %%mm0            \n\t" // L3
+        "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm0            \n\t" // L3
         PAVGB(%%mm0, %%mm2)                           // L1+L3
         PAVGB(%%mm1, %%mm2)                           // 2L2 + L1 + L3
-        "movq %%mm2, (%%"REG_a")                \n\t"
-        "movq (%%"REG_a", %1, 2), %%mm2         \n\t" // L4
+        "movq %%mm2, %%nacl:(%%r15, %%"REG_a")                \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm2         \n\t" // L4
         PAVGB(%%mm2, %%mm1)                           // L2+L4
         PAVGB(%%mm0, %%mm1)                           // 2L3 + L2 + L4
-        "movq %%mm1, (%%"REG_a", %1)            \n\t"
-        "movq (%0, %1, 4), %%mm1                \n\t" // L5
+        "naclmovq2 %%mm1, \"(%%"REG_a", %q1)\"            \n\t"
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm1                \n\t" // L5
         PAVGB(%%mm1, %%mm0)                           // L3+L5
         PAVGB(%%mm2, %%mm0)                           // 2L4 + L3 + L5
-        "movq %%mm0, (%%"REG_a", %1, 2)         \n\t"
-        "movq (%%"REG_d"), %%mm0                \n\t" // L6
+        "naclmovq2 %%mm0, \"(%%"REG_a", %q1, 2)\"         \n\t"
+        "movq %%nacl:(%%r15, %%"REG_d"), %%mm0                \n\t" // L6
         PAVGB(%%mm0, %%mm2)                           // L4+L6
         PAVGB(%%mm1, %%mm2)                           // 2L5 + L4 + L6
-        "movq %%mm2, (%0, %1, 4)                \n\t"
-        "movq (%%"REG_d", %1), %%mm2            \n\t" // L7
+        "naclmovq2 %%mm2, \"(%q0, %q1, 4)\"                \n\t"
+        "naclmovq1 \"(%%"REG_d", %q1)\", %%mm2            \n\t" // L7
         PAVGB(%%mm2, %%mm1)                           // L5+L7
         PAVGB(%%mm0, %%mm1)                           // 2L6 + L5 + L7
-        "movq %%mm1, (%%"REG_d")                \n\t"
-        "movq (%%"REG_d", %1, 2), %%mm1         \n\t" // L8
+        "movq %%mm1, %%nacl:(%%r15, %%"REG_d")                \n\t"
+        "naclmovq1 \"(%%"REG_d", %q1, 2)\", %%mm1         \n\t" // L8
         PAVGB(%%mm1, %%mm0)                           // L6+L8
         PAVGB(%%mm2, %%mm0)                           // 2L7 + L6 + L8
-        "movq %%mm0, (%%"REG_d", %1)            \n\t"
-        "movq (%0, %1, 8), %%mm0                \n\t" // L9
+        "naclmovq2 %%mm0, \"(%%"REG_d", %q1)\"            \n\t"
+        "naclmovq1 \"(%q0, %q1, 8)\", %%mm0                \n\t" // L9
         PAVGB(%%mm0, %%mm2)                           // L7+L9
         PAVGB(%%mm1, %%mm2)                           // 2L8 + L7 + L9
-        "movq %%mm2, (%%"REG_d", %1, 2)         \n\t"
-        "movq %%mm1, (%2)                       \n\t"
+        "naclmovq2 %%mm2, \"(%%"REG_d", %q1, 2)\"         \n\t"
+        "movq %%mm1, %%nacl:(%%r15, %q2)                       \n\t"
 
-        : : "r" (src), "r" ((x86_reg)stride), "r" (tmp)
-        : "%"REG_a, "%"REG_d
+        : : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride),
+          "r" ((x86_reg_addr)tmp)
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 #else //TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     int a, b, c, x;
@@ -1870,65 +1874,65 @@ static inline void RENAME(deInterlaceMedian)(uint8_t src[], int stride)
     src+= 4*stride;
 #if TEMPLATE_PP_MMXEXT
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1
 
-        "movq (%0), %%mm0                       \n\t"
-        "movq (%%"REG_a", %1), %%mm2            \n\t"
-        "movq (%%"REG_a"), %%mm1                \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm2            \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t"
         "movq %%mm0, %%mm3                      \n\t"
         "pmaxub %%mm1, %%mm0                    \n\t"
         "pminub %%mm3, %%mm1                    \n\t"
         "pmaxub %%mm2, %%mm1                    \n\t"
         "pminub %%mm1, %%mm0                    \n\t"
-        "movq %%mm0, (%%"REG_a")                \n\t"
+        "naclmovq2 %%mm0, \"(%%"REG_a")\"                \n\t"
 
-        "movq (%0, %1, 4), %%mm0                \n\t"
-        "movq (%%"REG_a", %1, 2), %%mm1         \n\t"
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm0                \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm1         \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "pmaxub %%mm1, %%mm2                    \n\t"
         "pminub %%mm3, %%mm1                    \n\t"
         "pmaxub %%mm0, %%mm1                    \n\t"
         "pminub %%mm1, %%mm2                    \n\t"
-        "movq %%mm2, (%%"REG_a", %1, 2)         \n\t"
+        "naclmovq2 %%mm2, \"(%%"REG_a", %q1, 2)\"         \n\t"
 
-        "movq (%%"REG_d"), %%mm2                \n\t"
-        "movq (%%"REG_d", %1), %%mm1            \n\t"
+        "movq %%nacl:(%%r15, %%"REG_d"), %%mm2                \n\t"
+        "naclmovq1 \"(%%"REG_d", %q1)\", %%mm1            \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "pmaxub %%mm0, %%mm2                    \n\t"
         "pminub %%mm3, %%mm0                    \n\t"
         "pmaxub %%mm1, %%mm0                    \n\t"
         "pminub %%mm0, %%mm2                    \n\t"
-        "movq %%mm2, (%%"REG_d")                \n\t"
+        "movq %%mm2, %%nacl:(%%r15, %%"REG_d")                \n\t"
 
-        "movq (%%"REG_d", %1, 2), %%mm2         \n\t"
-        "movq (%0, %1, 8), %%mm0                \n\t"
+        "naclmovq1 \"(%%"REG_d", %q1, 2)\", %%mm2         \n\t"
+        "naclmovq1 \"(%q0, %q1, 8)\", %%mm0                \n\t"
         "movq %%mm2, %%mm3                      \n\t"
         "pmaxub %%mm0, %%mm2                    \n\t"
         "pminub %%mm3, %%mm0                    \n\t"
         "pmaxub %%mm1, %%mm0                    \n\t"
         "pminub %%mm0, %%mm2                    \n\t"
-        "movq %%mm2, (%%"REG_d", %1, 2)         \n\t"
+        "naclmovq2 %%mm2, \"(%%"REG_d", %q1, 2)\"         \n\t"
 
 
-        : : "r" (src), "r" ((x86_reg)stride)
-        : "%"REG_a, "%"REG_d
+        : : "r" ((x86_reg_addr)src), "r" ((x86_reg)stride)
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 
 #else // MMX without MMX2
     __asm__ volatile(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a", %1, 4), %%"REG_d"      \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_d"      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1
         "pxor %%mm7, %%mm7                      \n\t"
 
 #define REAL_MEDIAN(a,b,c)\
-        "movq " #a ", %%mm0                     \n\t"\
-        "movq " #b ", %%mm2                     \n\t"\
-        "movq " #c ", %%mm1                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm0                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm2                     \n\t"\
+        "naclmovq1 \"" #c "\", %%mm1                     \n\t"\
         "movq %%mm0, %%mm3                      \n\t"\
         "movq %%mm1, %%mm4                      \n\t"\
         "movq %%mm2, %%mm5                      \n\t"\
@@ -1947,16 +1951,16 @@ static inline void RENAME(deInterlaceMedian)(uint8_t src[], int stride)
         "por %%mm5, %%mm0                       \n\t"\
         "pand %%mm2, %%mm0                      \n\t"\
         "pand %%mm1, %%mm0                      \n\t"\
-        "movq %%mm0, " #b "                     \n\t"
+        "naclmovq2 %%mm0, \"" #b "\"                     \n\t"
 #define MEDIAN(a,b,c)  REAL_MEDIAN(a,b,c)
 
-MEDIAN((%0)        , (%%REGa)       , (%%REGa, %1))
-MEDIAN((%%REGa, %1), (%%REGa, %1, 2), (%0, %1, 4))
-MEDIAN((%0, %1, 4) , (%%REGd)       , (%%REGd, %1))
-MEDIAN((%%REGd, %1), (%%REGd, %1, 2), (%0, %1, 8))
+MEDIAN((%q0)        , (%%REGa)       , (%%REGa, %q1))
+MEDIAN((%%REGa, %q1), (%%REGa, %q1, 2), (%q0, %q1, 4))
+MEDIAN((%q0, %q1, 4) , (%%REGd)       , (%%REGd, %q1))
+MEDIAN((%%REGd, %q1), (%%REGd, %q1, 2), (%q0, %q1, 8))
 
         : : "r" (src), "r" ((x86_reg)stride)
-        : "%"REG_a, "%"REG_d
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 #endif //TEMPLATE_PP_MMXEXT
 #else //TEMPLATE_PP_MMX
@@ -1988,17 +1992,17 @@ MEDIAN((%%REGd, %1), (%%REGd, %1, 2), (%0, %1, 8))
 static inline void RENAME(transpose1)(uint8_t *dst1, uint8_t *dst2, uint8_t *src, int srcStride)
 {
     __asm__(
-        "lea (%0, %1), %%"REG_a"                \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1
-        "movq (%0), %%mm0                       \n\t" // 12345678
-        "movq (%%"REG_a"), %%mm1                \n\t" // abcdefgh
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // 12345678
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t" // abcdefgh
         "movq %%mm0, %%mm2                      \n\t" // 12345678
         "punpcklbw %%mm1, %%mm0                 \n\t" // 1a2b3c4d
         "punpckhbw %%mm1, %%mm2                 \n\t" // 5e6f7g8h
 
-        "movq (%%"REG_a", %1), %%mm1            \n\t"
-        "movq (%%"REG_a", %1, 2), %%mm3         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm1            \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm3         \n\t"
         "movq %%mm1, %%mm4                      \n\t"
         "punpcklbw %%mm3, %%mm1                 \n\t"
         "punpckhbw %%mm3, %%mm4                 \n\t"
@@ -2010,31 +2014,31 @@ static inline void RENAME(transpose1)(uint8_t *dst1, uint8_t *dst2, uint8_t *src
         "punpcklwd %%mm4, %%mm2                 \n\t"
         "punpckhwd %%mm4, %%mm1                 \n\t"
 
-        "movd %%mm0, 128(%2)                    \n\t"
+        "movd %%mm0, %%nacl:128(%%r15, %q2)                    \n\t"
         "psrlq $32, %%mm0                       \n\t"
-        "movd %%mm0, 144(%2)                    \n\t"
-        "movd %%mm3, 160(%2)                    \n\t"
+        "movd %%mm0, %%nacl:144(%%r15, %q2)                    \n\t"
+        "movd %%mm3, %%nacl:160(%%r15, %q2)                    \n\t"
         "psrlq $32, %%mm3                       \n\t"
-        "movd %%mm3, 176(%2)                    \n\t"
-        "movd %%mm3, 48(%3)                     \n\t"
-        "movd %%mm2, 192(%2)                    \n\t"
-        "movd %%mm2, 64(%3)                     \n\t"
+        "movd %%mm3, %%nacl:176(%%r15, %q2)                    \n\t"
+        "movd %%mm3, %%nacl:48(%%r15, %q3)                     \n\t"
+        "movd %%mm2, %%nacl:192(%%r15, %q2)                    \n\t"
+        "movd %%mm2, %%nacl:64(%%r15, %q3)                     \n\t"
         "psrlq $32, %%mm2                       \n\t"
-        "movd %%mm2, 80(%3)                     \n\t"
-        "movd %%mm1, 96(%3)                     \n\t"
+        "movd %%mm2, %%nacl:80(%%r15, %q3)                     \n\t"
+        "movd %%mm1, %%nacl:96(%%r15, %q3)                     \n\t"
         "psrlq $32, %%mm1                       \n\t"
-        "movd %%mm1, 112(%3)                    \n\t"
+        "movd %%mm1, %%nacl:112(%%r15, %q3)                    \n\t"
 
-        "lea (%%"REG_a", %1, 4), %%"REG_a"      \n\t"
+        "lea (%%"REG_a", %q1, 4), %%"REG_a"      \n\t"
 
-        "movq (%0, %1, 4), %%mm0                \n\t" // 12345678
-        "movq (%%"REG_a"), %%mm1                \n\t" // abcdefgh
+        "naclmovq1 \"(%q0, %q1, 4)\", %%mm0                \n\t" // 12345678
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t" // abcdefgh
         "movq %%mm0, %%mm2                      \n\t" // 12345678
         "punpcklbw %%mm1, %%mm0                 \n\t" // 1a2b3c4d
         "punpckhbw %%mm1, %%mm2                 \n\t" // 5e6f7g8h
 
-        "movq (%%"REG_a", %1), %%mm1            \n\t"
-        "movq (%%"REG_a", %1, 2), %%mm3         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1)\", %%mm1            \n\t"
+        "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm3         \n\t"
         "movq %%mm1, %%mm4                      \n\t"
         "punpcklbw %%mm3, %%mm1                 \n\t"
         "punpckhbw %%mm3, %%mm4                 \n\t"
@@ -2046,24 +2050,24 @@ static inline void RENAME(transpose1)(uint8_t *dst1, uint8_t *dst2, uint8_t *src
         "punpcklwd %%mm4, %%mm2                 \n\t"
         "punpckhwd %%mm4, %%mm1                 \n\t"
 
-        "movd %%mm0, 132(%2)                    \n\t"
+        "movd %%mm0, %%nacl:132(%%r15, %q2)                    \n\t"
         "psrlq $32, %%mm0                       \n\t"
-        "movd %%mm0, 148(%2)                    \n\t"
-        "movd %%mm3, 164(%2)                    \n\t"
+        "movd %%mm0, %%nacl:148(%%r15, %q2)                    \n\t"
+        "movd %%mm3, %%nacl:164(%%r15, %q2)                    \n\t"
         "psrlq $32, %%mm3                       \n\t"
-        "movd %%mm3, 180(%2)                    \n\t"
-        "movd %%mm3, 52(%3)                     \n\t"
-        "movd %%mm2, 196(%2)                    \n\t"
-        "movd %%mm2, 68(%3)                     \n\t"
+        "movd %%mm3, %%nacl:180(%%r15, %q2)                    \n\t"
+        "movd %%mm3, %%nacl:52(%%r15, %q3)                     \n\t"
+        "movd %%mm2, %%nacl:196(%%r15, %q2)                    \n\t"
+        "movd %%mm2, %%nacl:68(%%r15, %q3)                     \n\t"
         "psrlq $32, %%mm2                       \n\t"
-        "movd %%mm2, 84(%3)                     \n\t"
-        "movd %%mm1, 100(%3)                    \n\t"
+        "movd %%mm2, %%nacl:84(%%r15, %q3)                     \n\t"
+        "movd %%mm1, %%nacl:100(%%r15, %q3)                    \n\t"
         "psrlq $32, %%mm1                       \n\t"
-        "movd %%mm1, 116(%3)                    \n\t"
+        "movd %%mm1, %%nacl:116(%%r15, %q3)                    \n\t"
 
 
         :: "r" (src), "r" ((x86_reg)srcStride), "r" (dst1), "r" (dst2)
-        : "%"REG_a
+        : "%"REG_a, "%r14"
     );
 }
 
@@ -2073,18 +2077,18 @@ static inline void RENAME(transpose1)(uint8_t *dst1, uint8_t *dst2, uint8_t *src
 static inline void RENAME(transpose2)(uint8_t *dst, int dstStride, uint8_t *src)
 {
     __asm__(
-        "lea (%0, %1), %%"REG_a"                \n\t"
-        "lea (%%"REG_a",%1,4), %%"REG_d"        \n\t"
+        "lea (%q0, %q1), %%"REG_a"                \n\t"
+        "lea (%%"REG_a",%q1,4), %%"REG_d"        \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  edx     edx+%1  edx+2%1 %0+8%1  edx+4%1
-        "movq (%2), %%mm0                       \n\t" // 12345678
-        "movq 16(%2), %%mm1                     \n\t" // abcdefgh
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  edx     edx+%q1  edx+2%q1 %q0+8%q1  edx+4%q1
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t" // 12345678
+        "movq %%nacl:16(%%r15, %q2), %%mm1                     \n\t" // abcdefgh
         "movq %%mm0, %%mm2                      \n\t" // 12345678
         "punpcklbw %%mm1, %%mm0                 \n\t" // 1a2b3c4d
         "punpckhbw %%mm1, %%mm2                 \n\t" // 5e6f7g8h
 
-        "movq 32(%2), %%mm1                     \n\t"
-        "movq 48(%2), %%mm3                     \n\t"
+        "movq %%nacl:32(%%r15, %q2), %%mm1                     \n\t"
+        "movq %%nacl:48(%%r15, %q2), %%mm3                     \n\t"
         "movq %%mm1, %%mm4                      \n\t"
         "punpcklbw %%mm3, %%mm1                 \n\t"
         "punpckhbw %%mm3, %%mm4                 \n\t"
@@ -2096,28 +2100,28 @@ static inline void RENAME(transpose2)(uint8_t *dst, int dstStride, uint8_t *src)
         "punpcklwd %%mm4, %%mm2                 \n\t"
         "punpckhwd %%mm4, %%mm1                 \n\t"
 
-        "movd %%mm0, (%0)                       \n\t"
+        "movd %%mm0, %%nacl:(%%r15, %q0)                       \n\t"
         "psrlq $32, %%mm0                       \n\t"
-        "movd %%mm0, (%%"REG_a")                \n\t"
-        "movd %%mm3, (%%"REG_a", %1)            \n\t"
+        "movd %%mm0, %%nacl:(%%r15, %%"REG_a")                \n\t"
+        "naclmovd2 %%mm3, \"(%%"REG_a", %q1)\"            \n\t"
         "psrlq $32, %%mm3                       \n\t"
-        "movd %%mm3, (%%"REG_a", %1, 2)         \n\t"
-        "movd %%mm2, (%0, %1, 4)                \n\t"
+        "naclmovd2 %%mm3, \"(%%"REG_a", %q1, 2)\"         \n\t"
+        "naclmovd2 %%mm2, \"(%q0, %q1, 4)\"                \n\t"
         "psrlq $32, %%mm2                       \n\t"
-        "movd %%mm2, (%%"REG_d")                \n\t"
-        "movd %%mm1, (%%"REG_d", %1)            \n\t"
+        "movd %%mm2, %%nacl:(%%r15, %%"REG_d")                \n\t"
+        "naclmovd2 %%mm1, \"(%%"REG_d", %q1)\"            \n\t"
         "psrlq $32, %%mm1                       \n\t"
-        "movd %%mm1, (%%"REG_d", %1, 2)         \n\t"
+        "naclmovd2 %%mm1, \"(%%"REG_d", %q1, 2)\"         \n\t"
 
 
-        "movq 64(%2), %%mm0                     \n\t" // 12345678
-        "movq 80(%2), %%mm1                     \n\t" // abcdefgh
+        "movq %%nacl:64(%%r15, %q2), %%mm0                     \n\t" // 12345678
+        "movq %%nacl:80(%%r15, %q2), %%mm1                     \n\t" // abcdefgh
         "movq %%mm0, %%mm2                      \n\t" // 12345678
         "punpcklbw %%mm1, %%mm0                 \n\t" // 1a2b3c4d
         "punpckhbw %%mm1, %%mm2                 \n\t" // 5e6f7g8h
 
-        "movq 96(%2), %%mm1                     \n\t"
-        "movq 112(%2), %%mm3                    \n\t"
+        "movq %%nacl:96(%%r15, %q2), %%mm1                     \n\t"
+        "movq %%nacl:112(%%r15, %q2), %%mm3                    \n\t"
         "movq %%mm1, %%mm4                      \n\t"
         "punpcklbw %%mm3, %%mm1                 \n\t"
         "punpckhbw %%mm3, %%mm4                 \n\t"
@@ -2129,21 +2133,21 @@ static inline void RENAME(transpose2)(uint8_t *dst, int dstStride, uint8_t *src)
         "punpcklwd %%mm4, %%mm2                 \n\t"
         "punpckhwd %%mm4, %%mm1                 \n\t"
 
-        "movd %%mm0, 4(%0)                      \n\t"
+        "movd %%mm0, %%nacl:4(%%r15, %q0)                      \n\t"
         "psrlq $32, %%mm0                       \n\t"
-        "movd %%mm0, 4(%%"REG_a")               \n\t"
-        "movd %%mm3, 4(%%"REG_a", %1)           \n\t"
+        "movd %%mm0, %%nacl:4(%%r15, %%"REG_a")               \n\t"
+        "naclmovd2 %%mm3, \"4(%%"REG_a", %q1)\"           \n\t"
         "psrlq $32, %%mm3                       \n\t"
-        "movd %%mm3, 4(%%"REG_a", %1, 2)        \n\t"
-        "movd %%mm2, 4(%0, %1, 4)               \n\t"
+        "naclmovd2 %%mm3, \"4(%%"REG_a", %q1, 2)\"        \n\t"
+        "naclmovd2 %%mm2, \"4(%q0, %q1, 4)\"               \n\t"
         "psrlq $32, %%mm2                       \n\t"
-        "movd %%mm2, 4(%%"REG_d")               \n\t"
-        "movd %%mm1, 4(%%"REG_d", %1)           \n\t"
+        "movd %%mm2, %%nacl:4(%%r15, %%"REG_d")               \n\t"
+        "naclmovd2 %%mm1, \"4(%%"REG_d", %q1)\"           \n\t"
         "psrlq $32, %%mm1                       \n\t"
-        "movd %%mm1, 4(%%"REG_d", %1, 2)        \n\t"
+        "naclmovd2 %%mm1, \"4(%%"REG_d", %q1, 2)\"        \n\t"
 
         :: "r" (dst), "r" ((x86_reg)dstStride), "r" (src)
-        : "%"REG_a, "%"REG_d
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 }
 #endif //TEMPLATE_PP_MMX
@@ -2162,34 +2166,34 @@ static inline void RENAME(tempNoiseReducer)(uint8_t *src, int stride,
 //#define L1_DIFF //u should change the thresholds too if u try that one
 #if TEMPLATE_PP_MMXEXT || TEMPLATE_PP_3DNOW
     __asm__ volatile(
-        "lea (%2, %2, 2), %%"REG_a"             \n\t" // 3*stride
-        "lea (%2, %2, 4), %%"REG_d"             \n\t" // 5*stride
-        "lea (%%"REG_d", %2, 2), %%"REG_c"      \n\t" // 7*stride
+        "lea (%q2, %q2, 2), %%"REG_a"             \n\t" // 3*stride
+        "lea (%q2, %q2, 4), %%"REG_d"             \n\t" // 5*stride
+        "lea (%%"REG_d", %q2, 2), %%"REG_c"      \n\t" // 7*stride
 //      0       1       2       3       4       5       6       7       8       9
-//      %x      %x+%2   %x+2%2  %x+eax  %x+4%2  %x+edx  %x+2eax %x+ecx  %x+8%2
+//      %x      %x+%q2   %x+2%q2  %x+eax  %x+4%q2  %x+edx  %x+2eax %x+ecx  %x+8%q2
 //FIXME reorder?
 #ifdef L1_DIFF //needs mmx2
-        "movq (%0), %%mm0                       \n\t" // L0
-        "psadbw (%1), %%mm0                     \n\t" // |L0-R0|
-        "movq (%0, %2), %%mm1                   \n\t" // L1
-        "psadbw (%1, %2), %%mm1                 \n\t" // |L1-R1|
-        "movq (%0, %2, 2), %%mm2                \n\t" // L2
-        "psadbw (%1, %2, 2), %%mm2              \n\t" // |L2-R2|
-        "movq (%0, %%"REG_a"), %%mm3            \n\t" // L3
-        "psadbw (%1, %%"REG_a"), %%mm3          \n\t" // |L3-R3|
-
-        "movq (%0, %2, 4), %%mm4                \n\t" // L4
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L0
+        "psadbw %%nacl:(%%r15, %q1), %%mm0                     \n\t" // |L0-R0|
+        "naclmovq1 \"(%q0, %q2)\", %%mm1                   \n\t" // L1
+        "psadbw (%q1, %q2), %%mm1                 \n\t" // |L1-R1|
+        "naclmovq1 \"(%q0, %q2, 2)\", %%mm2                \n\t" // L2
+        "psadbw (%q1, %q2, 2), %%mm2              \n\t" // |L2-R2|
+        "naclmovq1 \"(%q0, %%"REG_a")\", %%mm3            \n\t" // L3
+        "psadbw (%q1, %%"REG_a"), %%mm3          \n\t" // |L3-R3|
+
+        "naclmovq1 \"(%q0, %q2, 4)\", %%mm4                \n\t" // L4
         "paddw %%mm1, %%mm0                     \n\t"
-        "psadbw (%1, %2, 4), %%mm4              \n\t" // |L4-R4|
-        "movq (%0, %%"REG_d"), %%mm5            \n\t" // L5
+        "psadbw (%q1, %q2, 4), %%mm4              \n\t" // |L4-R4|
+        "naclmovq1 \"(%q0, %%"REG_d")\", %%mm5            \n\t" // L5
         "paddw %%mm2, %%mm0                     \n\t"
-        "psadbw (%1, %%"REG_d"), %%mm5          \n\t" // |L5-R5|
-        "movq (%0, %%"REG_a", 2), %%mm6         \n\t" // L6
+        "psadbw (%q1, %%"REG_d"), %%mm5          \n\t" // |L5-R5|
+        "naclmovq1 \"(%q0, %%"REG_a", 2)\", %%mm6         \n\t" // L6
         "paddw %%mm3, %%mm0                     \n\t"
-        "psadbw (%1, %%"REG_a", 2), %%mm6       \n\t" // |L6-R6|
-        "movq (%0, %%"REG_c"), %%mm7            \n\t" // L7
+        "psadbw (%q1, %%"REG_a", 2), %%mm6       \n\t" // |L6-R6|
+        "naclmovq1 \"(%q0, %%"REG_c")\", %%mm7            \n\t" // L7
         "paddw %%mm4, %%mm0                     \n\t"
-        "psadbw (%1, %%"REG_c"), %%mm7          \n\t" // |L7-R7|
+        "psadbw (%q1, %%"REG_c"), %%mm7          \n\t" // |L7-R7|
         "paddw %%mm5, %%mm6                     \n\t"
         "paddw %%mm7, %%mm6                     \n\t"
         "paddw %%mm6, %%mm0                     \n\t"
@@ -2199,8 +2203,8 @@ static inline void RENAME(tempNoiseReducer)(uint8_t *src, int stride,
         "movq "MANGLE(b80)", %%mm6              \n\t"
         "pxor %%mm0, %%mm0                      \n\t"
 #define REAL_L2_DIFF_CORE(a, b)\
-        "movq " #a ", %%mm5                     \n\t"\
-        "movq " #b ", %%mm2                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm5                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm2                     \n\t"\
         "pxor %%mm7, %%mm2                      \n\t"\
         PAVGB(%%mm2, %%mm5)\
         "paddb %%mm6, %%mm5                     \n\t"\
@@ -2216,8 +2220,8 @@ static inline void RENAME(tempNoiseReducer)(uint8_t *src, int stride,
         "pxor %%mm7, %%mm7                      \n\t"
         "pxor %%mm0, %%mm0                      \n\t"
 #define REAL_L2_DIFF_CORE(a, b)\
-        "movq " #a ", %%mm5                     \n\t"\
-        "movq " #b ", %%mm2                     \n\t"\
+        "naclmovq1 \"" #a "\", %%mm5                     \n\t"\
+        "naclmovq1 \"" #b "\", %%mm2                     \n\t"\
         "movq %%mm5, %%mm1                      \n\t"\
         "movq %%mm2, %%mm3                      \n\t"\
         "punpcklbw %%mm7, %%mm5                 \n\t"\
@@ -2235,14 +2239,14 @@ static inline void RENAME(tempNoiseReducer)(uint8_t *src, int stride,
 
 #define L2_DIFF_CORE(a, b)  REAL_L2_DIFF_CORE(a, b)
 
-L2_DIFF_CORE((%0)          , (%1))
-L2_DIFF_CORE((%0, %2)      , (%1, %2))
-L2_DIFF_CORE((%0, %2, 2)   , (%1, %2, 2))
-L2_DIFF_CORE((%0, %%REGa)  , (%1, %%REGa))
-L2_DIFF_CORE((%0, %2, 4)   , (%1, %2, 4))
-L2_DIFF_CORE((%0, %%REGd)  , (%1, %%REGd))
-L2_DIFF_CORE((%0, %%REGa,2), (%1, %%REGa,2))
-L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
+L2_DIFF_CORE((%q0)          , (%q1))
+L2_DIFF_CORE((%q0, %q2)      , (%q1, %q2))
+L2_DIFF_CORE((%q0, %q2, 2)   , (%q1, %q2, 2))
+L2_DIFF_CORE((%q0, %%REGa)  , (%q1, %%REGa))
+L2_DIFF_CORE((%q0, %q2, 4)   , (%q1, %q2, 4))
+L2_DIFF_CORE((%q0, %%REGd)  , (%q1, %%REGd))
+L2_DIFF_CORE((%q0, %%REGa,2), (%q1, %%REGa,2))
+L2_DIFF_CORE((%q0, %%REGc)  , (%q1, %%REGc))
 
 #endif //L1_DIFF
 
@@ -2251,94 +2255,94 @@ L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
         "paddd %%mm0, %%mm4                     \n\t"
         "movd %%mm4, %%ecx                      \n\t"
         "shll $2, %%ecx                         \n\t"
-        "mov %3, %%"REG_d"                      \n\t"
-        "addl -4(%%"REG_d"), %%ecx              \n\t"
-        "addl 4(%%"REG_d"), %%ecx               \n\t"
-        "addl -1024(%%"REG_d"), %%ecx           \n\t"
+        "mov %q3, %%"REG_d"                      \n\t"
+        "addl %%nacl:-4(%%r15, %%"REG_d"), %%ecx              \n\t"
+        "addl %%nacl:4(%%r15, %%"REG_d"), %%ecx               \n\t"
+        "addl %%nacl:-1024(%%r15, %%"REG_d"), %%ecx           \n\t"
         "addl $4, %%ecx                         \n\t"
-        "addl 1024(%%"REG_d"), %%ecx            \n\t"
+        "addl %%nacl:1024(%%r15, %%"REG_d"), %%ecx            \n\t"
         "shrl $3, %%ecx                         \n\t"
-        "movl %%ecx, (%%"REG_d")                \n\t"
+        "movl %%ecx, %%nacl:(%%r15, %%"REG_d")                \n\t"
 
-//        "mov %3, %%"REG_c"                      \n\t"
+//        "mov %q3, %%"REG_c"                      \n\t"
 //        "mov %%"REG_c", test                    \n\t"
 //        "jmp 4f                                 \n\t"
-        "cmpl 512(%%"REG_d"), %%ecx             \n\t"
+        "cmpl %%nacl:512(%%r15, %%"REG_d"), %%ecx             \n\t"
         " jb 2f                                 \n\t"
-        "cmpl 516(%%"REG_d"), %%ecx             \n\t"
+        "cmpl %%nacl:516(%%r15, %%"REG_d"), %%ecx             \n\t"
         " jb 1f                                 \n\t"
 
-        "lea (%%"REG_a", %2, 2), %%"REG_d"      \n\t" // 5*stride
-        "lea (%%"REG_d", %2, 2), %%"REG_c"      \n\t" // 7*stride
-        "movq (%0), %%mm0                       \n\t" // L0
-        "movq (%0, %2), %%mm1                   \n\t" // L1
-        "movq (%0, %2, 2), %%mm2                \n\t" // L2
-        "movq (%0, %%"REG_a"), %%mm3            \n\t" // L3
-        "movq (%0, %2, 4), %%mm4                \n\t" // L4
-        "movq (%0, %%"REG_d"), %%mm5            \n\t" // L5
-        "movq (%0, %%"REG_a", 2), %%mm6         \n\t" // L6
-        "movq (%0, %%"REG_c"), %%mm7            \n\t" // L7
-        "movq %%mm0, (%1)                       \n\t" // L0
-        "movq %%mm1, (%1, %2)                   \n\t" // L1
-        "movq %%mm2, (%1, %2, 2)                \n\t" // L2
-        "movq %%mm3, (%1, %%"REG_a")            \n\t" // L3
-        "movq %%mm4, (%1, %2, 4)                \n\t" // L4
-        "movq %%mm5, (%1, %%"REG_d")            \n\t" // L5
-        "movq %%mm6, (%1, %%"REG_a", 2)         \n\t" // L6
-        "movq %%mm7, (%1, %%"REG_c")            \n\t" // L7
+        "lea (%%"REG_a", %q2, 2), %%"REG_d"      \n\t" // 5*stride
+        "lea (%%"REG_d", %q2, 2), %%"REG_c"      \n\t" // 7*stride
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L0
+        "naclmovq1 \"(%q0, %q2)\", %%mm1                   \n\t" // L1
+        "naclmovq1 \"(%q0, %q2, 2)\", %%mm2                \n\t" // L2
+        "naclmovq1 \"(%q0, %%"REG_a")\", %%mm3            \n\t" // L3
+        "naclmovq1 \"(%q0, %q2, 4)\", %%mm4                \n\t" // L4
+        "naclmovq1 \"(%q0, %%"REG_d")\", %%mm5            \n\t" // L5
+        "naclmovq1 \"(%q0, %%"REG_a", 2)\", %%mm6         \n\t" // L6
+        "naclmovq1 \"(%q0, %%"REG_c")\", %%mm7            \n\t" // L7
+        "movq %%mm0, %%nacl:(%%r15, %q1)                       \n\t" // L0
+        "naclmovq2 %%mm1, \"(%q1, %q2)\"                   \n\t" // L1
+        "naclmovq2 %%mm2, \"(%q1, %q2, 2)\"                \n\t" // L2
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_a")\"            \n\t" // L3
+        "naclmovq2 %%mm4, \"(%q1, %q2, 4)\"                \n\t" // L4
+        "naclmovq2 %%mm5, \"(%q1, %%"REG_d")\"            \n\t" // L5
+        "naclmovq2 %%mm6, \"(%q1, %%"REG_a", 2)\"         \n\t" // L6
+        "naclmovq2 %%mm7, \"(%q1, %%"REG_c")\"            \n\t" // L7
         "jmp 4f                                 \n\t"
 
         "1:                                     \n\t"
-        "lea (%%"REG_a", %2, 2), %%"REG_d"      \n\t" // 5*stride
-        "lea (%%"REG_d", %2, 2), %%"REG_c"      \n\t" // 7*stride
-        "movq (%0), %%mm0                       \n\t" // L0
-        PAVGB((%1), %%mm0)                            // L0
-        "movq (%0, %2), %%mm1                   \n\t" // L1
-        PAVGB((%1, %2), %%mm1)                        // L1
-        "movq (%0, %2, 2), %%mm2                \n\t" // L2
-        PAVGB((%1, %2, 2), %%mm2)                     // L2
-        "movq (%0, %%"REG_a"), %%mm3            \n\t" // L3
-        PAVGB((%1, %%REGa), %%mm3)                    // L3
-        "movq (%0, %2, 4), %%mm4                \n\t" // L4
-        PAVGB((%1, %2, 4), %%mm4)                     // L4
-        "movq (%0, %%"REG_d"), %%mm5            \n\t" // L5
-        PAVGB((%1, %%REGd), %%mm5)                    // L5
-        "movq (%0, %%"REG_a", 2), %%mm6         \n\t" // L6
-        PAVGB((%1, %%REGa, 2), %%mm6)                 // L6
-        "movq (%0, %%"REG_c"), %%mm7            \n\t" // L7
-        PAVGB((%1, %%REGc), %%mm7)                    // L7
-        "movq %%mm0, (%1)                       \n\t" // R0
-        "movq %%mm1, (%1, %2)                   \n\t" // R1
-        "movq %%mm2, (%1, %2, 2)                \n\t" // R2
-        "movq %%mm3, (%1, %%"REG_a")            \n\t" // R3
-        "movq %%mm4, (%1, %2, 4)                \n\t" // R4
-        "movq %%mm5, (%1, %%"REG_d")            \n\t" // R5
-        "movq %%mm6, (%1, %%"REG_a", 2)         \n\t" // R6
-        "movq %%mm7, (%1, %%"REG_c")            \n\t" // R7
-        "movq %%mm0, (%0)                       \n\t" // L0
-        "movq %%mm1, (%0, %2)                   \n\t" // L1
-        "movq %%mm2, (%0, %2, 2)                \n\t" // L2
-        "movq %%mm3, (%0, %%"REG_a")            \n\t" // L3
-        "movq %%mm4, (%0, %2, 4)                \n\t" // L4
-        "movq %%mm5, (%0, %%"REG_d")            \n\t" // L5
-        "movq %%mm6, (%0, %%"REG_a", 2)         \n\t" // L6
-        "movq %%mm7, (%0, %%"REG_c")            \n\t" // L7
+        "lea (%%"REG_a", %q2, 2), %%"REG_d"      \n\t" // 5*stride
+        "lea (%%"REG_d", %q2, 2), %%"REG_c"      \n\t" // 7*stride
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L0
+        PAVGB(%%nacl:(%%r15, %q1), %%mm0)                            // L0
+        "naclmovq1 \"(%q0, %q2)\", %%mm1                   \n\t" // L1
+        NACL_PAVGB1((%q1, %q2), %%mm1)                        // L1
+        "naclmovq1 \"(%q0, %q2, 2)\", %%mm2                \n\t" // L2
+        NACL_PAVGB1((%q1, %q2, 2), %%mm2)                     // L2
+        "naclmovq1 \"(%q0, %%"REG_a")\", %%mm3            \n\t" // L3
+        NACL_PAVGB1((%q1, %%REGa), %%mm3)                    // L3
+        "naclmovq1 \"(%q0, %q2, 4)\", %%mm4                \n\t" // L4
+        NACL_PAVGB1((%q1, %q2, 4), %%mm4)                     // L4
+        "naclmovq1 \"(%q0, %%"REG_d")\", %%mm5            \n\t" // L5
+        NACL_PAVGB1((%q1, %%REGd), %%mm5)                    // L5
+        "naclmovq1 \"(%q0, %%"REG_a", 2)\", %%mm6         \n\t" // L6
+        NACL_PAVGB1((%q1, %%REGa, 2), %%mm6)                 // L6
+        "naclmovq1 \"(%q0, %%"REG_c")\", %%mm7            \n\t" // L7
+        NACL_PAVGB1((%q1, %%REGc), %%mm7)                    // L7
+        "movq %%mm0, %%nacl:(%%r15, %q1)                       \n\t" // R0
+        "naclmovq2 %%mm1, \"(%q1, %q2)\"                   \n\t" // R1
+        "naclmovq2 %%mm2, \"(%q1, %q2, 2)\"                \n\t" // R2
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_a")\"            \n\t" // R3
+        "naclmovq2 %%mm4, \"(%q1, %q2, 4)\"                \n\t" // R4
+        "naclmovq2 %%mm5, \"(%q1, %%"REG_d")\"            \n\t" // R5
+        "naclmovq2 %%mm6, \"(%q1, %%"REG_a", 2)\"         \n\t" // R6
+        "naclmovq2 %%mm7, \"(%q1, %%"REG_c")\"            \n\t" // R7
+        "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t" // L0
+        "naclmovq2 %%mm1, \"(%q0, %q2)\"                   \n\t" // L1
+        "naclmovq2 %%mm2, \"(%q0, %q2, 2)\"                \n\t" // L2
+        "naclmovq2 %%mm3, \"(%q0, %%"REG_a")\"            \n\t" // L3
+        "naclmovq2 %%mm4, \"(%q0, %q2, 4)\"                \n\t" // L4
+        "naclmovq2 %%mm5, \"(%q0, %%"REG_d")\"            \n\t" // L5
+        "naclmovq2 %%mm6, \"(%q0, %%"REG_a", 2)\"         \n\t" // L6
+        "naclmovq2 %%mm7, \"(%q0, %%"REG_c")\"            \n\t" // L7
         "jmp 4f                                 \n\t"
 
         "2:                                     \n\t"
-        "cmpl 508(%%"REG_d"), %%ecx             \n\t"
+        "cmpl %%nacl:508(%%r15, %%"REG_d"), %%ecx             \n\t"
         " jb 3f                                 \n\t"
 
-        "lea (%%"REG_a", %2, 2), %%"REG_d"      \n\t" // 5*stride
-        "lea (%%"REG_d", %2, 2), %%"REG_c"      \n\t" // 7*stride
-        "movq (%0), %%mm0                       \n\t" // L0
-        "movq (%0, %2), %%mm1                   \n\t" // L1
-        "movq (%0, %2, 2), %%mm2                \n\t" // L2
-        "movq (%0, %%"REG_a"), %%mm3            \n\t" // L3
-        "movq (%1), %%mm4                       \n\t" // R0
-        "movq (%1, %2), %%mm5                   \n\t" // R1
-        "movq (%1, %2, 2), %%mm6                \n\t" // R2
-        "movq (%1, %%"REG_a"), %%mm7            \n\t" // R3
+        "lea (%%"REG_a", %q2, 2), %%"REG_d"      \n\t" // 5*stride
+        "lea (%%"REG_d", %q2, 2), %%"REG_c"      \n\t" // 7*stride
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L0
+        "naclmovq1 \"(%q0, %q2)\", %%mm1                   \n\t" // L1
+        "naclmovq1 \"(%q0, %q2, 2)\", %%mm2                \n\t" // L2
+        "naclmovq1 \"(%q0, %%"REG_a")\", %%mm3            \n\t" // L3
+        "movq %%nacl:(%%r15, %q1), %%mm4                       \n\t" // R0
+        "naclmovq1 \"(%q1, %q2)\", %%mm5                   \n\t" // R1
+        "naclmovq1 \"(%q1, %q2, 2)\", %%mm6                \n\t" // R2
+        "naclmovq1 \"(%q1, %%"REG_a")\", %%mm7            \n\t" // R3
         PAVGB(%%mm4, %%mm0)
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
@@ -2347,23 +2351,23 @@ L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
         PAVGB(%%mm7, %%mm3)
-        "movq %%mm0, (%1)                       \n\t" // R0
-        "movq %%mm1, (%1, %2)                   \n\t" // R1
-        "movq %%mm2, (%1, %2, 2)                \n\t" // R2
-        "movq %%mm3, (%1, %%"REG_a")            \n\t" // R3
-        "movq %%mm0, (%0)                       \n\t" // L0
-        "movq %%mm1, (%0, %2)                   \n\t" // L1
-        "movq %%mm2, (%0, %2, 2)                \n\t" // L2
-        "movq %%mm3, (%0, %%"REG_a")            \n\t" // L3
-
-        "movq (%0, %2, 4), %%mm0                \n\t" // L4
-        "movq (%0, %%"REG_d"), %%mm1            \n\t" // L5
-        "movq (%0, %%"REG_a", 2), %%mm2         \n\t" // L6
-        "movq (%0, %%"REG_c"), %%mm3            \n\t" // L7
-        "movq (%1, %2, 4), %%mm4                \n\t" // R4
-        "movq (%1, %%"REG_d"), %%mm5            \n\t" // R5
-        "movq (%1, %%"REG_a", 2), %%mm6         \n\t" // R6
-        "movq (%1, %%"REG_c"), %%mm7            \n\t" // R7
+        "movq %%mm0, %%nacl:(%%r15, %q1)                       \n\t" // R0
+        "naclmovq2 %%mm1, \"(%q1, %q2)\"                   \n\t" // R1
+        "naclmovq2 %%mm2, \"(%q1, %q2, 2)\"                \n\t" // R2
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_a")\"            \n\t" // R3
+        "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t" // L0
+        "naclmovq2 %%mm1, \"(%q0, %q2)\"                   \n\t" // L1
+        "naclmovq2 %%mm2, \"(%q0, %q2, 2)\"                \n\t" // L2
+        "naclmovq2 %%mm3, \"(%q0, %%"REG_a")\"            \n\t" // L3
+
+        "naclmovq1 \"(%q0, %q2, 4)\", %%mm0                \n\t" // L4
+        "naclmovq1 \"(%q0, %%"REG_d")\", %%mm1            \n\t" // L5
+        "naclmovq1 \"(%q0, %%"REG_a", 2)\", %%mm2         \n\t" // L6
+        "naclmovq1 \"(%q0, %%"REG_c")\", %%mm3            \n\t" // L7
+        "naclmovq1 \"(%q1, %q2, 4)\", %%mm4                \n\t" // R4
+        "naclmovq1 \"(%q1, %%"REG_d")\", %%mm5            \n\t" // R5
+        "naclmovq1 \"(%q1, %%"REG_a", 2)\", %%mm6         \n\t" // R6
+        "naclmovq1 \"(%q1, %%"REG_c")\", %%mm7            \n\t" // R7
         PAVGB(%%mm4, %%mm0)
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
@@ -2372,27 +2376,27 @@ L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
         PAVGB(%%mm7, %%mm3)
-        "movq %%mm0, (%1, %2, 4)                \n\t" // R4
-        "movq %%mm1, (%1, %%"REG_d")            \n\t" // R5
-        "movq %%mm2, (%1, %%"REG_a", 2)         \n\t" // R6
-        "movq %%mm3, (%1, %%"REG_c")            \n\t" // R7
-        "movq %%mm0, (%0, %2, 4)                \n\t" // L4
-        "movq %%mm1, (%0, %%"REG_d")            \n\t" // L5
-        "movq %%mm2, (%0, %%"REG_a", 2)         \n\t" // L6
-        "movq %%mm3, (%0, %%"REG_c")            \n\t" // L7
+        "naclmovq2 %%mm0, \"(%q1, %q2, 4)\"                \n\t" // R4
+        "naclmovq2 %%mm1, \"(%q1, %%"REG_d")\"            \n\t" // R5
+        "naclmovq2 %%mm2, \"(%q1, %%"REG_a", 2)\"         \n\t" // R6
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_c")\"            \n\t" // R7
+        "naclmovq2 %%mm0, \"(%q0, %q2, 4)\"                \n\t" // L4
+        "naclmovq2 %%mm1, \"(%q0, %%"REG_d")\"            \n\t" // L5
+        "naclmovq2 %%mm2, \"(%q0, %%"REG_a", 2)\"         \n\t" // L6
+        "naclmovq2 %%mm3, \"(%q0, %%"REG_c")\"            \n\t" // L7
         "jmp 4f                                 \n\t"
 
         "3:                                     \n\t"
-        "lea (%%"REG_a", %2, 2), %%"REG_d"      \n\t" // 5*stride
-        "lea (%%"REG_d", %2, 2), %%"REG_c"      \n\t" // 7*stride
-        "movq (%0), %%mm0                       \n\t" // L0
-        "movq (%0, %2), %%mm1                   \n\t" // L1
-        "movq (%0, %2, 2), %%mm2                \n\t" // L2
-        "movq (%0, %%"REG_a"), %%mm3            \n\t" // L3
-        "movq (%1), %%mm4                       \n\t" // R0
-        "movq (%1, %2), %%mm5                   \n\t" // R1
-        "movq (%1, %2, 2), %%mm6                \n\t" // R2
-        "movq (%1, %%"REG_a"), %%mm7            \n\t" // R3
+        "lea (%%"REG_a", %q2, 2), %%"REG_d"      \n\t" // 5*stride
+        "lea (%%"REG_d", %q2, 2), %%"REG_c"      \n\t" // 7*stride
+        "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t" // L0
+        "naclmovq1 \"(%q0, %q2)\", %%mm1                   \n\t" // L1
+        "naclmovq1 \"(%q0, %q2, 2)\", %%mm2                \n\t" // L2
+        "naclmovq1 \"(%q0, %%"REG_a")\", %%mm3            \n\t" // L3
+        "movq %%nacl:(%%r15, %q1), %%mm4                       \n\t" // R0
+        "naclmovq1 \"(%q1, %q2)\", %%mm5                   \n\t" // R1
+        "naclmovq1 \"(%q1, %q2, 2)\", %%mm6                \n\t" // R2
+        "naclmovq1 \"(%q1, %%"REG_a")\", %%mm7            \n\t" // R3
         PAVGB(%%mm4, %%mm0)
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
@@ -2405,23 +2409,23 @@ L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
         PAVGB(%%mm7, %%mm3)
-        "movq %%mm0, (%1)                       \n\t" // R0
-        "movq %%mm1, (%1, %2)                   \n\t" // R1
-        "movq %%mm2, (%1, %2, 2)                \n\t" // R2
-        "movq %%mm3, (%1, %%"REG_a")            \n\t" // R3
-        "movq %%mm0, (%0)                       \n\t" // L0
-        "movq %%mm1, (%0, %2)                   \n\t" // L1
-        "movq %%mm2, (%0, %2, 2)                \n\t" // L2
-        "movq %%mm3, (%0, %%"REG_a")            \n\t" // L3
-
-        "movq (%0, %2, 4), %%mm0                \n\t" // L4
-        "movq (%0, %%"REG_d"), %%mm1            \n\t" // L5
-        "movq (%0, %%"REG_a", 2), %%mm2         \n\t" // L6
-        "movq (%0, %%"REG_c"), %%mm3            \n\t" // L7
-        "movq (%1, %2, 4), %%mm4                \n\t" // R4
-        "movq (%1, %%"REG_d"), %%mm5            \n\t" // R5
-        "movq (%1, %%"REG_a", 2), %%mm6         \n\t" // R6
-        "movq (%1, %%"REG_c"), %%mm7            \n\t" // R7
+        "movq %%mm0, %%nacl:(%%r15, %q1)                       \n\t" // R0
+        "naclmovq2 %%mm1, \"(%q1, %q2)\"                   \n\t" // R1
+        "naclmovq2 %%mm2, \"(%q1, %q2, 2)\"                \n\t" // R2
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_a")\"            \n\t" // R3
+        "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t" // L0
+        "naclmovq2 %%mm1, \"(%q0, %q2)\"                   \n\t" // L1
+        "naclmovq2 %%mm2, \"(%q0, %q2, 2)\"                \n\t" // L2
+        "naclmovq2 %%mm3, \"(%q0, %%"REG_a")\"            \n\t" // L3
+
+        "naclmovq1 \"(%q0, %q2, 4)\", %%mm0                \n\t" // L4
+        "naclmovq1 \"(%q0, %%"REG_d")\", %%mm1            \n\t" // L5
+        "naclmovq1 \"(%q0, %%"REG_a", 2)\", %%mm2         \n\t" // L6
+        "naclmovq1 \"(%q0, %%"REG_c")\", %%mm3            \n\t" // L7
+        "naclmovq1 \"(%q1, %q2, 4)\", %%mm4                \n\t" // R4
+        "naclmovq1 \"(%q1, %%"REG_d")\", %%mm5            \n\t" // R5
+        "naclmovq1 \"(%q1, %%"REG_a", 2)\", %%mm6         \n\t" // R6
+        "naclmovq1 \"(%q1, %%"REG_c")\", %%mm7            \n\t" // R7
         PAVGB(%%mm4, %%mm0)
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
@@ -2434,14 +2438,14 @@ L2_DIFF_CORE((%0, %%REGc)  , (%1, %%REGc))
         PAVGB(%%mm5, %%mm1)
         PAVGB(%%mm6, %%mm2)
         PAVGB(%%mm7, %%mm3)
-        "movq %%mm0, (%1, %2, 4)                \n\t" // R4
-        "movq %%mm1, (%1, %%"REG_d")            \n\t" // R5
-        "movq %%mm2, (%1, %%"REG_a", 2)         \n\t" // R6
-        "movq %%mm3, (%1, %%"REG_c")            \n\t" // R7
-        "movq %%mm0, (%0, %2, 4)                \n\t" // L4
-        "movq %%mm1, (%0, %%"REG_d")            \n\t" // L5
-        "movq %%mm2, (%0, %%"REG_a", 2)         \n\t" // L6
-        "movq %%mm3, (%0, %%"REG_c")            \n\t" // L7
+        "naclmovq2 %%mm0, \"(%q1, %q2, 4)\"                \n\t" // R4
+        "naclmovq2 %%mm1, \"(%q1, %%"REG_d")\"            \n\t" // R5
+        "naclmovq2 %%mm2, \"(%q1, %%"REG_a", 2)\"         \n\t" // R6
+        "naclmovq2 %%mm3, \"(%q1, %%"REG_c")\"            \n\t" // R7
+        "naclmovq2 %%mm0, \"(%q0, %q2, 4)\"                \n\t" // L4
+        "naclmovq2 %%mm1, \"(%q0, %%"REG_d")\"            \n\t" // L5
+        "naclmovq2 %%mm2, \"(%q0, %%"REG_a", 2)\"         \n\t" // L6
+        "naclmovq2 %%mm3, \"(%q0, %%"REG_c")\"            \n\t" // L7
 
         "4:                                     \n\t"
 
@@ -2545,25 +2549,25 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
     src+= step*3; // src points to begin of the 8x8 Block
     //{ START_TIMER
     __asm__ volatile(
-        "movq %0, %%mm7                         \n\t"
-        "movq %1, %%mm6                         \n\t"
+        "movq %q0, %%mm7                         \n\t"
+        "movq %q1, %%mm6                         \n\t"
         : : "m" (c->mmxDcOffset[c->nonBQP]),  "m" (c->mmxDcThreshold[c->nonBQP])
         );
 
     __asm__ volatile(
-        "lea (%2, %3), %%"REG_a"                \n\t"
+        "lea (%q2, %q3), %%"REG_a"                \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %1      eax     eax+%2  eax+2%2 %1+4%2  ecx     ecx+%2  ecx+2%2 %1+8%2  ecx+4%2
+//      %q1      eax     eax+%q2  eax+2%q2 %q1+4%q2  ecx     ecx+%q2  ecx+2%q2 %q1+8%q2  ecx+4%q2
 
-        "movq (%2), %%mm0                       \n\t"
-        "movq (%%"REG_a"), %%mm1                \n\t"
+        "movq %%nacl:(%%r15, %q2), %%mm0                       \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t"
         "movq %%mm1, %%mm3                      \n\t"
         "movq %%mm1, %%mm4                      \n\t"
         "psubb %%mm1, %%mm0                     \n\t" // mm0 = difference
         "paddb %%mm7, %%mm0                     \n\t"
         "pcmpgtb %%mm6, %%mm0                   \n\t"
 
-        "movq (%%"REG_a",%3), %%mm2             \n\t"
+        "naclmovq1 \"(%%"REG_a",%q3)\", %%mm2             \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -2571,7 +2575,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3, 2), %%mm1         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3, 2)\", %%mm1         \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -2579,9 +2583,9 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm2                   \n\t"
         "paddb %%mm2, %%mm0                     \n\t"
 
-        "lea (%%"REG_a", %3, 4), %%"REG_a"      \n\t"
+        "lea (%%"REG_a", %q3, 4), %%"REG_a"      \n\t"
 
-        "movq (%2, %3, 4), %%mm2                \n\t"
+        "naclmovq1 \"(%q2, %q3, 4)\", %%mm2                \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -2589,7 +2593,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a"), %%mm1                \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm1                \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -2597,7 +2601,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm2                   \n\t"
         "paddb %%mm2, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3), %%mm2            \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3)\", %%mm2            \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -2605,7 +2609,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3, 2), %%mm1         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3, 2)\", %%mm1         \n\t"
         PMAXUB(%%mm1, %%mm4)
         PMINUB(%%mm1, %%mm3, %%mm5)
         "psubb %%mm1, %%mm2                     \n\t"
@@ -2613,7 +2617,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm2                   \n\t"
         "paddb %%mm2, %%mm0                     \n\t"
 
-        "movq (%2, %3, 8), %%mm2                \n\t"
+        "naclmovq1 \"(%q2, %q3, 8)\", %%mm2                \n\t"
         PMAXUB(%%mm2, %%mm4)
         PMINUB(%%mm2, %%mm3, %%mm5)
         "psubb %%mm2, %%mm1                     \n\t"
@@ -2621,7 +2625,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "pcmpgtb %%mm6, %%mm1                   \n\t"
         "paddb %%mm1, %%mm0                     \n\t"
 
-        "movq (%%"REG_a", %3, 4), %%mm1         \n\t"
+        "naclmovq1 \"(%%"REG_a", %q3, 4)\", %%mm1         \n\t"
         "psubb %%mm1, %%mm2                     \n\t"
         "paddb %%mm7, %%mm2                     \n\t"
         "pcmpgtb %%mm6, %%mm2                   \n\t"
@@ -2629,24 +2633,24 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         "psubusb %%mm3, %%mm4                   \n\t"
 
         "pxor %%mm6, %%mm6                      \n\t"
-        "movq %4, %%mm7                         \n\t" // QP,..., QP
+        "movq %q4, %%mm7                         \n\t" // QP,..., QP
         "paddusb %%mm7, %%mm7                   \n\t" // 2QP ... 2QP
         "psubusb %%mm4, %%mm7                   \n\t" // Diff >=2QP -> 0
         "pcmpeqb %%mm6, %%mm7                   \n\t" // Diff < 2QP -> 0
         "pcmpeqb %%mm6, %%mm7                   \n\t" // Diff < 2QP -> 0
-        "movq %%mm7, %1                         \n\t"
+        "movq %%mm7, %q1                         \n\t"
 
-        "movq %5, %%mm7                         \n\t"
+        "movq %q5, %%mm7                         \n\t"
         "punpcklbw %%mm7, %%mm7                 \n\t"
         "punpcklbw %%mm7, %%mm7                 \n\t"
         "punpcklbw %%mm7, %%mm7                 \n\t"
         "psubb %%mm0, %%mm6                     \n\t"
         "pcmpgtb %%mm7, %%mm6                   \n\t"
-        "movq %%mm6, %0                         \n\t"
+        "movq %%mm6, %q0                         \n\t"
 
         : "=m" (eq_mask), "=m" (dc_mask)
         : "r" (src), "r" ((x86_reg)step), "m" (c->pQPb), "m"(c->ppMode.flatnessThreshold)
-        : "%"REG_a
+        : "%"REG_a, "%r14"
     );
 
     both_masks = dc_mask & eq_mask;
@@ -2656,11 +2660,11 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         int64_t *temp_sums= sums;
 
         __asm__ volatile(
-            "movq %2, %%mm0                         \n\t"  // QP,..., QP
+            "movq %q2, %%mm0                         \n\t"  // QP,..., QP
             "pxor %%mm4, %%mm4                      \n\t"
 
-            "movq (%0), %%mm6                       \n\t"
-            "movq (%0, %1), %%mm5                   \n\t"
+            "movq %%nacl:(%%r15, %q0), %%mm6                       \n\t"
+            "naclmovq1 \"(%q0, %q1)\", %%mm5                   \n\t"
             "movq %%mm5, %%mm1                      \n\t"
             "movq %%mm6, %%mm2                      \n\t"
             "psubusb %%mm6, %%mm5                   \n\t"
@@ -2674,15 +2678,15 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "pxor %%mm1, %%mm6                      \n\t"
             // 0:QP  6:First
 
-            "movq (%0, %1, 8), %%mm5                \n\t"
-            "add %1, %0                             \n\t" // %0 points to line 1 not 0
-            "movq (%0, %1, 8), %%mm7                \n\t"
+            "naclmovq1 \"(%q0, %q1, 8)\", %%mm5                \n\t"
+            "add %q1, %q0                             \n\t" // %q0 points to line 1 not 0
+            "naclmovq1 \"(%q0, %q1, 8)\", %%mm7                \n\t"
             "movq %%mm5, %%mm1                      \n\t"
             "movq %%mm7, %%mm2                      \n\t"
             "psubusb %%mm7, %%mm5                   \n\t"
             "psubusb %%mm1, %%mm2                   \n\t"
             "por %%mm5, %%mm2                       \n\t" // ABS Diff of lines
-            "movq %2, %%mm0                         \n\t"  // QP,..., QP
+            "movq %q2, %%mm0                         \n\t"  // QP,..., QP
             "psubusb %%mm2, %%mm0                   \n\t" // diff >= QP -> 0
             "pcmpeqb %%mm4, %%mm0                   \n\t" // diff >= QP -> FF
 
@@ -2703,18 +2707,18 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "paddw "MANGLE(w04)", %%mm1             \n\t"
 
 #define NEXT\
-            "movq (%0), %%mm2                       \n\t"\
-            "movq (%0), %%mm3                       \n\t"\
-            "add %1, %0                             \n\t"\
+            "movq %%nacl:(%%r15, %q0), %%mm2                       \n\t"\
+            "movq %%nacl:(%%r15, %q0), %%mm3                       \n\t"\
+            "add %q1, %q0                             \n\t"\
             "punpcklbw %%mm4, %%mm2                 \n\t"\
             "punpckhbw %%mm4, %%mm3                 \n\t"\
             "paddw %%mm2, %%mm0                     \n\t"\
             "paddw %%mm3, %%mm1                     \n\t"
 
 #define PREV\
-            "movq (%0), %%mm2                       \n\t"\
-            "movq (%0), %%mm3                       \n\t"\
-            "add %1, %0                             \n\t"\
+            "movq %%nacl:(%%r15, %q0), %%mm2                       \n\t"\
+            "movq %%nacl:(%%r15, %q0), %%mm3                       \n\t"\
+            "add %q1, %q0                             \n\t"\
             "punpcklbw %%mm4, %%mm2                 \n\t"\
             "punpckhbw %%mm4, %%mm3                 \n\t"\
             "psubw %%mm2, %%mm0                     \n\t"\
@@ -2724,69 +2728,69 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             NEXT //0
             NEXT //1
             NEXT //2
-            "movq %%mm0, (%3)                       \n\t"
-            "movq %%mm1, 8(%3)                      \n\t"
+            "movq %%mm0, %%nacl:(%%r15, %q3)                       \n\t"
+            "movq %%mm1, %%nacl:8(%%r15, %q3)                      \n\t"
 
             NEXT //3
             "psubw %%mm5, %%mm0                     \n\t"
             "psubw %%mm6, %%mm1                     \n\t"
-            "movq %%mm0, 16(%3)                     \n\t"
-            "movq %%mm1, 24(%3)                     \n\t"
+            "movq %%mm0, %%nacl:16(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:24(%%r15, %q3)                     \n\t"
 
             NEXT //4
             "psubw %%mm5, %%mm0                     \n\t"
             "psubw %%mm6, %%mm1                     \n\t"
-            "movq %%mm0, 32(%3)                     \n\t"
-            "movq %%mm1, 40(%3)                     \n\t"
+            "movq %%mm0, %%nacl:32(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:40(%%r15, %q3)                     \n\t"
 
             NEXT //5
             "psubw %%mm5, %%mm0                     \n\t"
             "psubw %%mm6, %%mm1                     \n\t"
-            "movq %%mm0, 48(%3)                     \n\t"
-            "movq %%mm1, 56(%3)                     \n\t"
+            "movq %%mm0, %%nacl:48(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:56(%%r15, %q3)                     \n\t"
 
             NEXT //6
             "psubw %%mm5, %%mm0                     \n\t"
             "psubw %%mm6, %%mm1                     \n\t"
-            "movq %%mm0, 64(%3)                     \n\t"
-            "movq %%mm1, 72(%3)                     \n\t"
+            "movq %%mm0, %%nacl:64(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:72(%%r15, %q3)                     \n\t"
 
             "movq %%mm7, %%mm6                      \n\t"
             "punpckhbw %%mm4, %%mm7                 \n\t"
             "punpcklbw %%mm4, %%mm6                 \n\t"
 
             NEXT //7
-            "mov %4, %0                             \n\t"
-            "add %1, %0                             \n\t"
+            "mov %q4, %q0                             \n\t"
+            "add %q1, %q0                             \n\t"
             PREV //0
-            "movq %%mm0, 80(%3)                     \n\t"
-            "movq %%mm1, 88(%3)                     \n\t"
+            "movq %%mm0, %%nacl:80(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:88(%%r15, %q3)                     \n\t"
 
             PREV //1
             "paddw %%mm6, %%mm0                     \n\t"
             "paddw %%mm7, %%mm1                     \n\t"
-            "movq %%mm0, 96(%3)                     \n\t"
-            "movq %%mm1, 104(%3)                    \n\t"
+            "movq %%mm0, %%nacl:96(%%r15, %q3)                     \n\t"
+            "movq %%mm1, %%nacl:104(%%r15, %q3)                    \n\t"
 
             PREV //2
             "paddw %%mm6, %%mm0                     \n\t"
             "paddw %%mm7, %%mm1                     \n\t"
-            "movq %%mm0, 112(%3)                    \n\t"
-            "movq %%mm1, 120(%3)                    \n\t"
+            "movq %%mm0, %%nacl:112(%%r15, %q3)                    \n\t"
+            "movq %%mm1, %%nacl:120(%%r15, %q3)                    \n\t"
 
             PREV //3
             "paddw %%mm6, %%mm0                     \n\t"
             "paddw %%mm7, %%mm1                     \n\t"
-            "movq %%mm0, 128(%3)                    \n\t"
-            "movq %%mm1, 136(%3)                    \n\t"
+            "movq %%mm0, %%nacl:128(%%r15, %q3)                    \n\t"
+            "movq %%mm1, %%nacl:136(%%r15, %q3)                    \n\t"
 
             PREV //4
             "paddw %%mm6, %%mm0                     \n\t"
             "paddw %%mm7, %%mm1                     \n\t"
-            "movq %%mm0, 144(%3)                    \n\t"
-            "movq %%mm1, 152(%3)                    \n\t"
+            "movq %%mm0, %%nacl:144(%%r15, %q3)                    \n\t"
+            "movq %%mm1, %%nacl:152(%%r15, %q3)                    \n\t"
 
-            "mov %4, %0                             \n\t" //FIXME
+            "mov %q4, %q0                             \n\t" //FIXME
 
             : "+&r"(src)
             : "r" ((x86_reg)step), "m" (c->pQPb), "r"(sums), "g"(src)
@@ -2795,17 +2799,17 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         src+= step; // src points to begin of the 8x8 Block
 
         __asm__ volatile(
-            "movq %4, %%mm6                         \n\t"
+            "movq %q4, %%mm6                         \n\t"
             "pcmpeqb %%mm5, %%mm5                   \n\t"
             "pxor %%mm6, %%mm5                      \n\t"
             "pxor %%mm7, %%mm7                      \n\t"
 
             "1:                                     \n\t"
-            "movq (%1), %%mm0                       \n\t"
-            "movq 8(%1), %%mm1                      \n\t"
-            "paddw 32(%1), %%mm0                    \n\t"
-            "paddw 40(%1), %%mm1                    \n\t"
-            "movq (%0, %3), %%mm2                   \n\t"
+            "movq %%nacl:(%%r15, %q1), %%mm0                       \n\t"
+            "movq %%nacl:8(%%r15, %q1), %%mm1                      \n\t"
+            "paddw %%nacl:32(%%r15, %q1), %%mm0                    \n\t"
+            "paddw %%nacl:40(%%r15, %q1), %%mm1                    \n\t"
+            "naclmovq1 \"(%q0, %q3)\", %%mm2                   \n\t"
             "movq %%mm2, %%mm3                      \n\t"
             "movq %%mm2, %%mm4                      \n\t"
             "punpcklbw %%mm7, %%mm2                 \n\t"
@@ -2820,13 +2824,14 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "pand %%mm6, %%mm0                      \n\t"
             "pand %%mm5, %%mm4                      \n\t"
             "por %%mm4, %%mm0                       \n\t"
-            "movq %%mm0, (%0, %3)                   \n\t"
-            "add $16, %1                            \n\t"
-            "add %2, %0                             \n\t"
+            "naclmovq2 %%mm0, \"(%q0, %q3)\"                   \n\t"
+            "add $16, %q1                            \n\t"
+            "add %q2, %q0                             \n\t"
             " js 1b                                 \n\t"
 
             : "+r"(offset), "+r"(temp_sums)
             : "r" ((x86_reg)step), "r"(src - offset), "m"(both_masks)
+                    : "%r14"
         );
     }else
         src+= step; // src points to begin of the 8x8 Block
@@ -2837,20 +2842,20 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
         __asm__ volatile(
             "pxor %%mm7, %%mm7                      \n\t"
 //      0       1       2       3       4       5       6       7       8       9
-//      %0      eax     eax+%1  eax+2%1 %0+4%1  ecx     ecx+%1  ecx+2%1 %1+8%1  ecx+4%1
+//      %q0      eax     eax+%q1  eax+2%q1 %q0+4%q1  ecx     ecx+%q1  ecx+2%q1 %q1+8%q1  ecx+4%q1
 
-            "movq (%0), %%mm0                       \n\t"
+            "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
             "movq %%mm0, %%mm1                      \n\t"
             "punpcklbw %%mm7, %%mm0                 \n\t" // low part of line 0
             "punpckhbw %%mm7, %%mm1                 \n\t" // high part of line 0
 
-            "movq (%0, %1), %%mm2                   \n\t"
-            "lea (%0, %1, 2), %%"REG_a"             \n\t"
+            "naclmovq1 \"(%q0, %q1)\", %%mm2                   \n\t"
+            "lea (%q0, %q1, 2), %%"REG_a"             \n\t"
             "movq %%mm2, %%mm3                      \n\t"
             "punpcklbw %%mm7, %%mm2                 \n\t" // low part of line 1
             "punpckhbw %%mm7, %%mm3                 \n\t" // high part of line 1
 
-            "movq (%%"REG_a"), %%mm4                \n\t"
+            "movq %%nacl:(%%r15, %%"REG_a"), %%mm4                \n\t"
             "movq %%mm4, %%mm5                      \n\t"
             "punpcklbw %%mm7, %%mm4                 \n\t" // low part of line 2
             "punpckhbw %%mm7, %%mm5                 \n\t" // high part of line 2
@@ -2867,7 +2872,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm2, %%mm0                     \n\t" // 2L0 - 5L1 + 5L2
             "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2
 
-            "movq (%%"REG_a", %1), %%mm2            \n\t"
+            "naclmovq1 \"(%%"REG_a", %q1)\", %%mm2            \n\t"
             "movq %%mm2, %%mm3                      \n\t"
             "punpcklbw %%mm7, %%mm2                 \n\t" // L3
             "punpckhbw %%mm7, %%mm3                 \n\t" // H3
@@ -2876,30 +2881,30 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2 - H3
             "psubw %%mm2, %%mm0                     \n\t" // 2L0 - 5L1 + 5L2 - 2L3
             "psubw %%mm3, %%mm1                     \n\t" // 2H0 - 5H1 + 5H2 - 2H3
-            "movq %%mm0, (%4)                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
-            "movq %%mm1, 8(%4)                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
+            "movq %%mm0, %%nacl:(%%r15, %q4)                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
+            "movq %%mm1, %%nacl:8(%%r15, %q4)                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
 
-            "movq (%%"REG_a", %1, 2), %%mm0         \n\t"
+            "naclmovq1 \"(%%"REG_a", %q1, 2)\", %%mm0         \n\t"
             "movq %%mm0, %%mm1                      \n\t"
             "punpcklbw %%mm7, %%mm0                 \n\t" // L4
             "punpckhbw %%mm7, %%mm1                 \n\t" // H4
 
             "psubw %%mm0, %%mm2                     \n\t" // L3 - L4
             "psubw %%mm1, %%mm3                     \n\t" // H3 - H4
-            "movq %%mm2, 16(%4)                     \n\t" // L3 - L4
-            "movq %%mm3, 24(%4)                     \n\t" // H3 - H4
+            "movq %%mm2, %%nacl:16(%%r15, %q4)                     \n\t" // L3 - L4
+            "movq %%mm3, %%nacl:24(%%r15, %q4)                     \n\t" // H3 - H4
             "paddw %%mm4, %%mm4                     \n\t" // 2L2
             "paddw %%mm5, %%mm5                     \n\t" // 2H2
             "psubw %%mm2, %%mm4                     \n\t" // 2L2 - L3 + L4
             "psubw %%mm3, %%mm5                     \n\t" // 2H2 - H3 + H4
 
-            "lea (%%"REG_a", %1), %0                \n\t"
+            "lea (%%"REG_a", %q1), %q0                \n\t"
             "psllw $2, %%mm2                        \n\t" // 4L3 - 4L4
             "psllw $2, %%mm3                        \n\t" // 4H3 - 4H4
             "psubw %%mm2, %%mm4                     \n\t" // 2L2 - 5L3 + 5L4
             "psubw %%mm3, %%mm5                     \n\t" // 2H2 - 5H3 + 5H4
 //50 opcodes so far
-            "movq (%0, %1, 2), %%mm2                \n\t"
+            "naclmovq1 \"(%q0, %q1, 2)\", %%mm2                \n\t"
             "movq %%mm2, %%mm3                      \n\t"
             "punpcklbw %%mm7, %%mm2                 \n\t" // L5
             "punpckhbw %%mm7, %%mm3                 \n\t" // H5
@@ -2908,10 +2913,10 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm2, %%mm4                     \n\t" // 2L2 - 5L3 + 5L4 - 2L5
             "psubw %%mm3, %%mm5                     \n\t" // 2H2 - 5H3 + 5H4 - 2H5
 
-            "movq (%%"REG_a", %1, 4), %%mm6         \n\t"
+            "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm6         \n\t"
             "punpcklbw %%mm7, %%mm6                 \n\t" // L6
             "psubw %%mm6, %%mm2                     \n\t" // L5 - L6
-            "movq (%%"REG_a", %1, 4), %%mm6         \n\t"
+            "naclmovq1 \"(%%"REG_a", %q1, 4)\", %%mm6         \n\t"
             "punpckhbw %%mm7, %%mm6                 \n\t" // H6
             "psubw %%mm6, %%mm3                     \n\t" // H5 - H6
 
@@ -2925,7 +2930,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm2, %%mm0                     \n\t" // 2L4 - 5L5 + 5L6
             "psubw %%mm3, %%mm1                     \n\t" // 2H4 - 5H5 + 5H6
 
-            "movq (%0, %1, 4), %%mm2                \n\t"
+            "naclmovq1 \"(%q0, %q1, 4)\", %%mm2                \n\t"
             "movq %%mm2, %%mm3                      \n\t"
             "punpcklbw %%mm7, %%mm2                 \n\t" // L7
             "punpckhbw %%mm7, %%mm3                 \n\t" // H7
@@ -2935,8 +2940,8 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm2, %%mm0                     \n\t" // 2L4 - 5L5 + 5L6 - 2L7
             "psubw %%mm3, %%mm1                     \n\t" // 2H4 - 5H5 + 5H6 - 2H7
 
-            "movq (%4), %%mm2                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
-            "movq 8(%4), %%mm3                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
+            "movq %%nacl:(%%r15, %q4), %%mm2                       \n\t" // 2L0 - 5L1 + 5L2 - 2L3
+            "movq %%nacl:8(%%r15, %q4), %%mm3                      \n\t" // 2H0 - 5H1 + 5H2 - 2H3
 
 #if TEMPLATE_PP_MMXEXT
             "movq %%mm7, %%mm6                      \n\t" // 0
@@ -2982,7 +2987,7 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm6, %%mm1                     \n\t"
 #endif
 
-            "movd %2, %%mm2                         \n\t" // QP
+            "movd %q2, %%mm2                         \n\t" // QP
             "punpcklbw %%mm7, %%mm2                 \n\t"
 
             "movq %%mm7, %%mm6                      \n\t" // 0
@@ -3014,8 +3019,8 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psrlw $6, %%mm4                        \n\t"
             "psrlw $6, %%mm5                        \n\t"
 
-            "movq 16(%4), %%mm0                     \n\t" // L3 - L4
-            "movq 24(%4), %%mm1                     \n\t" // H3 - H4
+            "movq %%nacl:16(%%r15, %q4), %%mm0                     \n\t" // L3 - L4
+            "movq %%nacl:24(%%r15, %q4), %%mm1                     \n\t" // H3 - H4
 
             "pxor %%mm2, %%mm2                      \n\t"
             "pxor %%mm3, %%mm3                      \n\t"
@@ -3050,18 +3055,18 @@ static av_always_inline void RENAME(do_a_deblock)(uint8_t *src, int step, int st
             "psubw %%mm6, %%mm4                     \n\t"
             "psubw %%mm7, %%mm5                     \n\t"
             "packsswb %%mm5, %%mm4                  \n\t"
-            "movq %3, %%mm1                         \n\t"
+            "movq %q3, %%mm1                         \n\t"
             "pandn %%mm4, %%mm1                     \n\t"
-            "movq (%0), %%mm0                       \n\t"
+            "movq %%nacl:(%%r15, %q0), %%mm0                       \n\t"
             "paddb   %%mm1, %%mm0                   \n\t"
-            "movq %%mm0, (%0)                       \n\t"
-            "movq (%0, %1), %%mm0                   \n\t"
+            "movq %%mm0, %%nacl:(%%r15, %q0)                       \n\t"
+            "naclmovq1 \"(%q0, %q1)\", %%mm0                   \n\t"
             "psubb %%mm1, %%mm0                     \n\t"
-            "movq %%mm0, (%0, %1)                   \n\t"
+            "naclmovq2 %%mm0, \"(%q0, %q1)\"                   \n\t"
 
             : "+r" (temp_src)
             : "r" ((x86_reg)step), "m" (c->pQPb), "m"(eq_mask), "r"(tmp)
-            : "%"REG_a
+            : "%"REG_a, "%r14"
         );
     }
 /*if(step==16){
@@ -3092,17 +3097,17 @@ static inline void RENAME(blockCopy)(uint8_t dst[], int dstStride, const uint8_t
     if(levelFix){
 #if TEMPLATE_PP_MMX
     __asm__ volatile(
-        "movq (%%"REG_a"), %%mm2        \n\t" // packedYOffset
-        "movq 8(%%"REG_a"), %%mm3       \n\t" // packedYScale
-        "lea (%2,%4), %%"REG_a"         \n\t"
-        "lea (%3,%5), %%"REG_d"         \n\t"
+        "movq %%nacl:(%%r15, %%"REG_a"), %%mm2        \n\t" // packedYOffset
+        "movq %%nacl:8(%%r15, %%"REG_a"), %%mm3       \n\t" // packedYScale
+        "lea (%q2,%q4), %%"REG_a"         \n\t"
+        "lea (%q3,%q5), %%"REG_d"         \n\t"
         "pxor %%mm4, %%mm4              \n\t"
 #if TEMPLATE_PP_MMXEXT
 #define REAL_SCALED_CPY(src1, src2, dst1, dst2)                                                \
-        "movq " #src1 ", %%mm0          \n\t"\
-        "movq " #src1 ", %%mm5          \n\t"\
-        "movq " #src2 ", %%mm1          \n\t"\
-        "movq " #src2 ", %%mm6          \n\t"\
+        "naclmovq1 \"" #src1 "\", %%mm0          \n\t"\
+        "naclmovq1 \"" #src1 "\", %%mm5          \n\t"\
+        "naclmovq1 \"" #src2 "\", %%mm1          \n\t"\
+        "naclmovq1 \"" #src2 "\", %%mm6          \n\t"\
         "punpcklbw %%mm0, %%mm0         \n\t"\
         "punpckhbw %%mm5, %%mm5         \n\t"\
         "punpcklbw %%mm1, %%mm1         \n\t"\
@@ -3117,22 +3122,22 @@ static inline void RENAME(blockCopy)(uint8_t dst[], int dstStride, const uint8_t
         "psubw %%mm2, %%mm6             \n\t"\
         "packuswb %%mm5, %%mm0          \n\t"\
         "packuswb %%mm6, %%mm1          \n\t"\
-        "movq %%mm0, " #dst1 "          \n\t"\
-        "movq %%mm1, " #dst2 "          \n\t"\
+        "naclmovq2 %%mm0, \"" #dst1 "\"          \n\t"\
+        "naclmovq2 %%mm1, \"" #dst2 "\"          \n\t"\
 
 #else //TEMPLATE_PP_MMXEXT
 #define REAL_SCALED_CPY(src1, src2, dst1, dst2)                                        \
-        "movq " #src1 ", %%mm0          \n\t"\
-        "movq " #src1 ", %%mm5          \n\t"\
+        "naclmovq1 \"" #src1 "\", %%mm0          \n\t"\
+        "naclmovq1 \"" #src1 "\", %%mm5          \n\t"\
         "punpcklbw %%mm4, %%mm0         \n\t"\
         "punpckhbw %%mm4, %%mm5         \n\t"\
         "psubw %%mm2, %%mm0             \n\t"\
         "psubw %%mm2, %%mm5             \n\t"\
-        "movq " #src2 ", %%mm1          \n\t"\
+        "naclmovq1 \"" #src2 "\", %%mm1          \n\t"\
         "psllw $6, %%mm0                \n\t"\
         "psllw $6, %%mm5                \n\t"\
         "pmulhw %%mm3, %%mm0            \n\t"\
-        "movq " #src2 ", %%mm6          \n\t"\
+        "naclmovq1 \"" #src2 "\", %%mm6          \n\t"\
         "pmulhw %%mm3, %%mm5            \n\t"\
         "punpcklbw %%mm4, %%mm1         \n\t"\
         "punpckhbw %%mm4, %%mm6         \n\t"\
@@ -3144,28 +3149,28 @@ static inline void RENAME(blockCopy)(uint8_t dst[], int dstStride, const uint8_t
         "pmulhw %%mm3, %%mm6            \n\t"\
         "packuswb %%mm5, %%mm0          \n\t"\
         "packuswb %%mm6, %%mm1          \n\t"\
-        "movq %%mm0, " #dst1 "          \n\t"\
-        "movq %%mm1, " #dst2 "          \n\t"\
+        "naclmovq2 %%mm0, \"" #dst1 "\"          \n\t"\
+        "naclmovq2 %%mm1, \"" #dst2 "\"          \n\t"\
 
 #endif //TEMPLATE_PP_MMXEXT
 #define SCALED_CPY(src1, src2, dst1, dst2)\
    REAL_SCALED_CPY(src1, src2, dst1, dst2)
 
-SCALED_CPY((%2)       , (%2, %4)      , (%3)       , (%3, %5))
-SCALED_CPY((%2, %4, 2), (%%REGa, %4, 2), (%3, %5, 2), (%%REGd, %5, 2))
-SCALED_CPY((%2, %4, 4), (%%REGa, %4, 4), (%3, %5, 4), (%%REGd, %5, 4))
-        "lea (%%"REG_a",%4,4), %%"REG_a"        \n\t"
-        "lea (%%"REG_d",%5,4), %%"REG_d"        \n\t"
-SCALED_CPY((%%REGa, %4), (%%REGa, %4, 2), (%%REGd, %5), (%%REGd, %5, 2))
+SCALED_CPY((%q2)       , (%q2, %q4)      , (%q3)       , (%q3, %q5))
+SCALED_CPY((%q2, %q4, 2), (%%REGa, %q4, 2), (%q3, %q5, 2), (%%REGd, %q5, 2))
+SCALED_CPY((%q2, %q4, 4), (%%REGa, %q4, 4), (%q3, %q5, 4), (%%REGd, %q5, 4))
+        "lea (%%"REG_a",%q4,4), %%"REG_a"        \n\t"
+        "lea (%%"REG_d",%q5,4), %%"REG_d"        \n\t"
+SCALED_CPY((%%REGa, %q4), (%%REGa, %q4, 2), (%%REGd, %q5), (%%REGd, %q5, 2))
 
 
         : "=&a" (packedOffsetAndScale)
-        : "0" (packedOffsetAndScale),
-        "r"(src),
-        "r"(dst),
+        : "0" ((x86_reg_addr)packedOffsetAndScale),
+        "r"((x86_reg_addr)src),
+        "r"((x86_reg_addr)dst),
         "r" ((x86_reg)srcStride),
         "r" ((x86_reg)dstStride)
-        : "%"REG_d
+        : "%"REG_d, "%r14"
     );
 #else //TEMPLATE_PP_MMX
     for(i=0; i<8; i++)
@@ -3175,30 +3180,30 @@ SCALED_CPY((%%REGa, %4), (%%REGa, %4, 2), (%%REGd, %5), (%%REGd, %5, 2))
     }else{
 #if TEMPLATE_PP_MMX
     __asm__ volatile(
-        "lea (%0,%2), %%"REG_a"                 \n\t"
-        "lea (%1,%3), %%"REG_d"                 \n\t"
+        "lea (%q0,%q2), %%"REG_a"                 \n\t"
+        "lea (%q1,%q3), %%"REG_d"                 \n\t"
 
 #define REAL_SIMPLE_CPY(src1, src2, dst1, dst2)                              \
-        "movq " #src1 ", %%mm0          \n\t"\
-        "movq " #src2 ", %%mm1          \n\t"\
-        "movq %%mm0, " #dst1 "          \n\t"\
-        "movq %%mm1, " #dst2 "          \n\t"\
+        "naclmovq1 \"" #src1 "\", %%mm0          \n\t"\
+        "naclmovq1 \"" #src2 "\", %%mm1          \n\t"\
+        "naclmovq2 %%mm0, \"" #dst1 "\"          \n\t"\
+        "naclmovq2 %%mm1, \"" #dst2 "\"          \n\t"\
 
 #define SIMPLE_CPY(src1, src2, dst1, dst2)\
    REAL_SIMPLE_CPY(src1, src2, dst1, dst2)
 
-SIMPLE_CPY((%0)       , (%0, %2)       , (%1)       , (%1, %3))
-SIMPLE_CPY((%0, %2, 2), (%%REGa, %2, 2), (%1, %3, 2), (%%REGd, %3, 2))
-SIMPLE_CPY((%0, %2, 4), (%%REGa, %2, 4), (%1, %3, 4), (%%REGd, %3, 4))
-        "lea (%%"REG_a",%2,4), %%"REG_a"        \n\t"
-        "lea (%%"REG_d",%3,4), %%"REG_d"        \n\t"
-SIMPLE_CPY((%%REGa, %2), (%%REGa, %2, 2), (%%REGd, %3), (%%REGd, %3, 2))
+SIMPLE_CPY((%q0)       , (%q0, %q2)       , (%q1)       , (%q1, %q3))
+SIMPLE_CPY((%q0, %q2, 2), (%%REGa, %q2, 2), (%q1, %q3, 2), (%%REGd, %q3, 2))
+SIMPLE_CPY((%q0, %q2, 4), (%%REGa, %q2, 4), (%q1, %q3, 4), (%%REGd, %q3, 4))
+        "lea (%%"REG_a",%q2,4), %%"REG_a"        \n\t"
+        "lea (%%"REG_d",%q3,4), %%"REG_d"        \n\t"
+SIMPLE_CPY((%%REGa, %q2), (%%REGa, %q2, 2), (%%REGd, %q3), (%%REGd, %q3, 2))
 
-        : : "r" (src),
-        "r" (dst),
+        : : "r" ((x86_reg_addr)src),
+        "r" ((x86_reg_addr)dst),
         "r" ((x86_reg)srcStride),
         "r" ((x86_reg)dstStride)
-        : "%"REG_a, "%"REG_d
+        : "%"REG_a, "%"REG_d, "%r14"
     );
 #else //TEMPLATE_PP_MMX
     for(i=0; i<8; i++)
@@ -3215,15 +3220,16 @@ static inline void RENAME(duplicate)(uint8_t src[], int stride)
 {
 #if TEMPLATE_PP_MMX
     __asm__ volatile(
-        "movq (%0), %%mm0               \n\t"
-        "movq %%mm0, (%0, %1, 4)        \n\t"
-        "add %1, %0                     \n\t"
-        "movq %%mm0, (%0)               \n\t"
-        "movq %%mm0, (%0, %1)           \n\t"
-        "movq %%mm0, (%0, %1, 2)        \n\t"
-        "movq %%mm0, (%0, %1, 4)        \n\t"
+        "movq %%nacl:(%%r15, %q0), %%mm0               \n\t"
+        "naclmovq2 %%mm0, \"(%q0, %q1, 4)\"        \n\t"
+        "add %q1, %q0                     \n\t"
+        "movq %%mm0, %%nacl:(%%r15, %q0)               \n\t"
+        "naclmovq2 %%mm0, \"(%q0, %q1)\"           \n\t"
+        "naclmovq2 %%mm0, \"(%q0, %q1, 2)\"        \n\t"
+        "naclmovq2 %%mm0, \"(%q0, %q1, 4)\"        \n\t"
         : "+r" (src)
         : "r" ((x86_reg)-stride)
+        : "%r14"
     );
 #else
     int i;
@@ -3365,19 +3371,19 @@ static void RENAME(postProcess)(const uint8_t src[], int srcStride, uint8_t dst[
 */
 
             __asm__(
-                "mov %4, %%"REG_a"              \n\t"
+                "mov %q4, %%"REG_a"              \n\t"
                 "shr $2, %%"REG_a"              \n\t"
                 "and $6, %%"REG_a"              \n\t"
-                "add %5, %%"REG_a"              \n\t"
+                "add %q5, %%"REG_a"              \n\t"
                 "mov %%"REG_a", %%"REG_d"       \n\t"
-                "imul %1, %%"REG_a"             \n\t"
-                "imul %3, %%"REG_d"             \n\t"
-                "prefetchnta 32(%%"REG_a", %0)  \n\t"
-                "prefetcht0 32(%%"REG_d", %2)   \n\t"
-                "add %1, %%"REG_a"              \n\t"
-                "add %3, %%"REG_d"              \n\t"
-                "prefetchnta 32(%%"REG_a", %0)  \n\t"
-                "prefetcht0 32(%%"REG_d", %2)   \n\t"
+                "imul %q1, %%"REG_a"             \n\t"
+                "imul %q3, %%"REG_d"             \n\t"
+                "prefetchnta 32(%%"REG_a", %q0)  \n\t"
+                "prefetcht0 32(%%"REG_d", %q2)   \n\t"
+                "add %q1, %%"REG_a"              \n\t"
+                "add %q3, %%"REG_d"              \n\t"
+                "prefetchnta 32(%%"REG_a", %q0)  \n\t"
+                "prefetcht0 32(%%"REG_d", %q2)   \n\t"
                 :: "r" (srcBlock), "r" ((x86_reg)srcStride), "r" (dstBlock), "r" ((x86_reg)dstStride),
                 "g" ((x86_reg)x), "g" ((x86_reg)copyAhead)
                 : "%"REG_a, "%"REG_d
@@ -3481,11 +3487,11 @@ static void RENAME(postProcess)(const uint8_t src[], int srcStride, uint8_t dst[
             c.QP= QP;
 #if TEMPLATE_PP_MMX
             __asm__ volatile(
-                "movd %1, %%mm7         \n\t"
+                "movd %q1, %%mm7         \n\t"
                 "packuswb %%mm7, %%mm7  \n\t" // 0, 0, 0, QP, 0, 0, 0, QP
                 "packuswb %%mm7, %%mm7  \n\t" // 0,QP, 0, QP, 0,QP, 0, QP
                 "packuswb %%mm7, %%mm7  \n\t" // QP,..., QP
-                "movq %%mm7, %0         \n\t"
+                "movq %%mm7, %q0         \n\t"
                 : "=m" (c.pQPb)
                 : "r" (QP)
             );
@@ -3501,19 +3507,19 @@ static void RENAME(postProcess)(const uint8_t src[], int srcStride, uint8_t dst[
 */
 
             __asm__(
-                "mov %4, %%"REG_a"              \n\t"
+                "mov %q4, %%"REG_a"              \n\t"
                 "shr $2, %%"REG_a"              \n\t"
                 "and $6, %%"REG_a"              \n\t"
-                "add %5, %%"REG_a"              \n\t"
+                "add %q5, %%"REG_a"              \n\t"
                 "mov %%"REG_a", %%"REG_d"       \n\t"
-                "imul %1, %%"REG_a"             \n\t"
-                "imul %3, %%"REG_d"             \n\t"
-                "prefetchnta 32(%%"REG_a", %0)  \n\t"
-                "prefetcht0 32(%%"REG_d", %2)   \n\t"
-                "add %1, %%"REG_a"              \n\t"
-                "add %3, %%"REG_d"              \n\t"
-                "prefetchnta 32(%%"REG_a", %0)  \n\t"
-                "prefetcht0 32(%%"REG_d", %2)   \n\t"
+                "imul %q1, %%"REG_a"             \n\t"
+                "imul %q3, %%"REG_d"             \n\t"
+                "prefetchnta 32(%%"REG_a", %q0)  \n\t"
+                "prefetcht0 32(%%"REG_d", %q2)   \n\t"
+                "add %q1, %%"REG_a"              \n\t"
+                "add %q3, %%"REG_d"              \n\t"
+                "prefetchnta 32(%%"REG_a", %q0)  \n\t"
+                "prefetcht0 32(%%"REG_d", %q2)   \n\t"
                 :: "r" (srcBlock), "r" ((x86_reg)srcStride), "r" (dstBlock), "r" ((x86_reg)dstStride),
                 "g" ((x86_reg)x), "g" ((x86_reg)copyAhead)
                 : "%"REG_a, "%"REG_d
diff --git a/libswresample/x86/resample_mmx.h b/libswresample/x86/resample_mmx.h
index d96fd5a..26394e5 100644
--- a/libswresample/x86/resample_mmx.h
+++ b/libswresample/x86/resample_mmx.h
@@ -32,20 +32,21 @@ DECLARE_ALIGNED(16, const uint64_t, ff_resample_int16_rounder)[2]    = { 0x00000
 __asm__ volatile(\
     "movq "MANGLE(ff_resample_int16_rounder)", %%mm0 \n\t"\
     "1:                         \n\t"\
-    "movq    (%1, %0), %%mm1    \n\t"\
-    "pmaddwd (%2, %0), %%mm1    \n\t"\
+    "naclmovq1    \"(%q1, %q0)\", %%mm1    \n\t"\
+    "naclpmaddwd1 \"(%q2, %q0)\", %%mm1    \n\t"\
     "paddd  %%mm1, %%mm0        \n\t"\
-    "add       $8, %0           \n\t"\
+    "add       $8, %q0           \n\t"\
     " js 1b                     \n\t"\
     "pshufw $0x0E, %%mm0, %%mm1 \n\t"\
     "paddd %%mm1, %%mm0         \n\t"\
     "psrad    $15, %%mm0        \n\t"\
     "packssdw %%mm0, %%mm0      \n\t"\
-    "movd %%mm0, (%3)           \n\t"\
+    "movd %%mm0, %%nacl:(%%r15, %q3)           \n\t"\
     : "+r" (len)\
     : "r" (((uint8_t*)(src+sample_index))-len),\
       "r" (((uint8_t*)filter)-len),\
       "r" (dst+dst_index)\
+    : "%r14" \
 );
 
 #define COMMON_CORE_INT16_SSSE3 \
@@ -53,18 +54,19 @@ __asm__ volatile(\
 __asm__ volatile(\
     "movdqa "MANGLE(ff_resample_int16_rounder)", %%xmm0 \n\t"\
     "1:                           \n\t"\
-    "movdqu  (%1, %0), %%xmm1     \n\t"\
-    "pmaddwd (%2, %0), %%xmm1     \n\t"\
+    "naclmovdqu1  \"(%q1, %q0)\", %%xmm1     \n\t"\
+    "naclpmaddwd1 \"(%q2, %q0)\", %%xmm1     \n\t"\
     "paddd  %%xmm1, %%xmm0        \n\t"\
-    "add       $16, %0            \n\t"\
+    "add       $16, %q0            \n\t"\
     " js 1b                       \n\t"\
     "phaddd %%xmm0, %%xmm0        \n\t"\
     "phaddd %%xmm0, %%xmm0        \n\t"\
     "psrad    $15, %%xmm0         \n\t"\
     "packssdw %%xmm0, %%xmm0      \n\t"\
-    "movd %%xmm0, (%3)            \n\t"\
+    "movd %%xmm0, %%nacl:(%%r15, %q3)            \n\t"\
     : "+r" (len)\
     : "r" (((uint8_t*)(src+sample_index))-len),\
       "r" (((uint8_t*)filter)-len),\
       "r" (dst+dst_index)\
+    : "%r14" \
 );
diff --git a/libswscale/utils.c b/libswscale/utils.c
index 69087dc..089302e 100644
--- a/libswscale/utils.c
+++ b/libswscale/utils.c
@@ -685,9 +685,9 @@ static av_cold int init_hscaler_mmxext(int dstW, int xInc, uint8_t *filterCode,
         "jmp                         9f                 \n\t"
         // Begin
         "0:                                             \n\t"
-        "movq    (%%"REG_d", %%"REG_a"), %%mm3          \n\t"
-        "movd    (%%"REG_c", %%"REG_S"), %%mm0          \n\t"
-        "movd   1(%%"REG_c", %%"REG_S"), %%mm1          \n\t"
+        "naclmovq1    \"(%%"REG_d", %%"REG_a")\", %%mm3          \n\t"
+        "naclmovq1    \"(%%"REG_c", %%"REG_S")\", %%mm0          \n\t"
+        "naclmovq1   \"1(%%"REG_c", %%"REG_S")\", %%mm1          \n\t"
         "punpcklbw                %%mm7, %%mm1          \n\t"
         "punpcklbw                %%mm7, %%mm0          \n\t"
         "pshufw                   $0xFF, %%mm1, %%mm1   \n\t"
@@ -695,68 +695,70 @@ static av_cold int init_hscaler_mmxext(int dstW, int xInc, uint8_t *filterCode,
         "pshufw                   $0xFF, %%mm0, %%mm0   \n\t"
         "2:                                             \n\t"
         "psubw                    %%mm1, %%mm0          \n\t"
-        "movl   8(%%"REG_b", %%"REG_a"), %%esi          \n\t"
+        "naclmovl1   \"8(%%"REG_b", %%"REG_a")\", %%esi          \n\t"
         "pmullw                   %%mm3, %%mm0          \n\t"
         "psllw                       $7, %%mm1          \n\t"
         "paddw                    %%mm1, %%mm0          \n\t"
 
-        "movq                     %%mm0, (%%"REG_D", %%"REG_a") \n\t"
+        "naclmovq2                     %%mm0, \"(%%"REG_D", %%"REG_a")\" \n\t"
 
         "add                         $8, %%"REG_a"      \n\t"
         // End
         "9:                                             \n\t"
         // "int $3                                         \n\t"
-        "lea       " LOCAL_MANGLE(0b) ", %0             \n\t"
-        "lea       " LOCAL_MANGLE(1b) ", %1             \n\t"
-        "lea       " LOCAL_MANGLE(2b) ", %2             \n\t"
-        "dec                         %1                 \n\t"
-        "dec                         %2                 \n\t"
-        "sub                         %0, %1             \n\t"
-        "sub                         %0, %2             \n\t"
-        "lea       " LOCAL_MANGLE(9b) ", %3             \n\t"
-        "sub                         %0, %3             \n\t"
+        "lea       " LOCAL_MANGLE(0b) ", %q0             \n\t"
+        "lea       " LOCAL_MANGLE(1b) ", %q1             \n\t"
+        "lea       " LOCAL_MANGLE(2b) ", %q2             \n\t"
+        "dec                         %q1                 \n\t"
+        "dec                         %q2                 \n\t"
+        "sub                         %q0, %q1             \n\t"
+        "sub                         %q0, %q2             \n\t"
+        "lea       " LOCAL_MANGLE(9b) ", %q3             \n\t"
+        "sub                         %q0, %q3             \n\t"
 
 
         : "=r" (fragmentA), "=r" (imm8OfPShufW1A), "=r" (imm8OfPShufW2A),
           "=r" (fragmentLengthA)
+            :: "%r14"
         );
 
     __asm__ volatile (
         "jmp                         9f                 \n\t"
         // Begin
         "0:                                             \n\t"
-        "movq    (%%"REG_d", %%"REG_a"), %%mm3          \n\t"
-        "movd    (%%"REG_c", %%"REG_S"), %%mm0          \n\t"
+        "naclmovq1    \"(%%"REG_d", %%"REG_a")\", %%mm3          \n\t"
+        "naclmovd1    \"(%%"REG_c", %%"REG_S")\", %%mm0          \n\t"
         "punpcklbw                %%mm7, %%mm0          \n\t"
         "pshufw                   $0xFF, %%mm0, %%mm1   \n\t"
         "1:                                             \n\t"
         "pshufw                   $0xFF, %%mm0, %%mm0   \n\t"
         "2:                                             \n\t"
         "psubw                    %%mm1, %%mm0          \n\t"
-        "movl   8(%%"REG_b", %%"REG_a"), %%esi          \n\t"
+        "naclmovl1   \"8(%%"REG_b", %%"REG_a")\", %%esi          \n\t"
         "pmullw                   %%mm3, %%mm0          \n\t"
         "psllw                       $7, %%mm1          \n\t"
         "paddw                    %%mm1, %%mm0          \n\t"
 
-        "movq                     %%mm0, (%%"REG_D", %%"REG_a") \n\t"
+        "naclmovq2                     %%mm0, \"(%%"REG_D", %%"REG_a")\" \n\t"
 
         "add                         $8, %%"REG_a"      \n\t"
         // End
         "9:                                             \n\t"
         // "int                       $3                   \n\t"
-        "lea       " LOCAL_MANGLE(0b) ", %0             \n\t"
-        "lea       " LOCAL_MANGLE(1b) ", %1             \n\t"
-        "lea       " LOCAL_MANGLE(2b) ", %2             \n\t"
-        "dec                         %1                 \n\t"
-        "dec                         %2                 \n\t"
-        "sub                         %0, %1             \n\t"
-        "sub                         %0, %2             \n\t"
-        "lea       " LOCAL_MANGLE(9b) ", %3             \n\t"
-        "sub                         %0, %3             \n\t"
+        "lea       " LOCAL_MANGLE(0b) ", %q0             \n\t"
+        "lea       " LOCAL_MANGLE(1b) ", %q1             \n\t"
+        "lea       " LOCAL_MANGLE(2b) ", %q2             \n\t"
+        "dec                         %q1                 \n\t"
+        "dec                         %q2                 \n\t"
+        "sub                         %q0, %q1             \n\t"
+        "sub                         %q0, %q2             \n\t"
+        "lea       " LOCAL_MANGLE(9b) ", %q3             \n\t"
+        "sub                         %q0, %q3             \n\t"
 
 
         : "=r" (fragmentB), "=r" (imm8OfPShufW1B), "=r" (imm8OfPShufW2B),
           "=r" (fragmentLengthB)
+            :: "%r14"
         );
 
     xpos        = 0; // lumXInc/2 - 0x8000; // difference between pixel centers
diff --git a/libswscale/x86/rgb2rgb_template.c b/libswscale/x86/rgb2rgb_template.c
index d684b70..2aec77b 100644
--- a/libswscale/x86/rgb2rgb_template.c
+++ b/libswscale/x86/rgb2rgb_template.c
@@ -33,13 +33,17 @@
 #undef EMMS
 #undef SFENCE
 #undef PAVGB
+#undef NACLMOVNTQ2
+#undef NACL_PAVGB1
 
 #if COMPILE_TEMPLATE_AMD3DNOW
 #define PREFETCH  "prefetch"
 #define PAVGB     "pavgusb"
+#define NACL_PAVGB1  "naclpavgusb1"
 #elif COMPILE_TEMPLATE_MMXEXT
 #define PREFETCH "prefetchnta"
 #define PAVGB     "pavgb"
+#define NACL_PAVGB1  "naclpavgb1"
 #else
 #define PREFETCH  " # nop"
 #endif
@@ -54,8 +58,10 @@
 #if COMPILE_TEMPLATE_MMXEXT
 #define MOVNTQ "movntq"
 #define SFENCE "sfence"
+#define NACLMOVNTQ2 "naclmovntq2 "
 #else
 #define MOVNTQ "movq"
+#define NACLMOVNTQ2 "naclmovq2 "
 #define SFENCE " # nop"
 #endif
 
@@ -70,28 +76,28 @@ static inline void RENAME(rgb24tobgr32)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *end;
     const uint8_t *mm_end;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     mm_end = end - 23;
-    __asm__ volatile("movq        %0, %%mm7"::"m"(mask32a):"memory");
+    __asm__ volatile("movq        %q0, %%mm7"::"m"(mask32a):"memory");
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "punpckldq  3(%1), %%mm0    \n\t"
-            "movd       6(%1), %%mm1    \n\t"
-            "punpckldq  9(%1), %%mm1    \n\t"
-            "movd      12(%1), %%mm2    \n\t"
-            "punpckldq 15(%1), %%mm2    \n\t"
-            "movd      18(%1), %%mm3    \n\t"
-            "punpckldq 21(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq  %%nacl:3(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:6(%%r15, %q1), %%mm1    \n\t"
+            "punpckldq  %%nacl:9(%%r15, %q1), %%mm1    \n\t"
+            "movd      %%nacl:12(%%r15, %q1), %%mm2    \n\t"
+            "punpckldq %%nacl:15(%%r15, %q1), %%mm2    \n\t"
+            "movd      %%nacl:18(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq %%nacl:21(%%r15, %q1), %%mm3    \n\t"
             "por        %%mm7, %%mm0    \n\t"
             "por        %%mm7, %%mm1    \n\t"
             "por        %%mm7, %%mm2    \n\t"
             "por        %%mm7, %%mm3    \n\t"
-            MOVNTQ"     %%mm0,   (%0)   \n\t"
-            MOVNTQ"     %%mm1,  8(%0)   \n\t"
-            MOVNTQ"     %%mm2, 16(%0)   \n\t"
-            MOVNTQ"     %%mm3, 24(%0)"
+            MOVNTQ"     %%mm0,   %%nacl:(%%r15, %q0)   \n\t"
+            MOVNTQ"     %%mm1,  %%nacl:8(%%r15, %q0)   \n\t"
+            MOVNTQ"     %%mm2, %%nacl:16(%%r15, %q0)   \n\t"
+            MOVNTQ"     %%mm3, %%nacl:24(%%r15, %q0)"
             :: "r"(dest), "r"(s)
             :"memory");
         dest += 32;
@@ -136,9 +142,9 @@ static inline void RENAME(rgb24tobgr32)(const uint8_t *src, uint8_t *dst, int sr
             "por        %%mm3, %%mm1    \n\t" \
             "por        %%mm5, %%mm4    \n\t" \
  \
-            MOVNTQ"     %%mm0,   (%0)    \n\t" \
-            MOVNTQ"     %%mm1,  8(%0)    \n\t" \
-            MOVNTQ"     %%mm4, 16(%0)"
+            MOVNTQ"     %%mm0,   %%nacl:(%%r15, %q0)    \n\t" \
+            MOVNTQ"     %%mm1,  %%nacl:8(%%r15, %q0)    \n\t" \
+            MOVNTQ"     %%mm4, %%nacl:16(%%r15, %q0)"
 
 
 static inline void RENAME(rgb32tobgr24)(const uint8_t *src, uint8_t *dst, int src_size)
@@ -148,15 +154,15 @@ static inline void RENAME(rgb32tobgr24)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *end;
     const uint8_t *mm_end;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     mm_end = end - 31;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movq        (%1), %%mm0    \n\t"
-            "movq       8(%1), %%mm1    \n\t"
-            "movq      16(%1), %%mm4    \n\t"
-            "movq      24(%1), %%mm5    \n\t"
+            PREFETCH"  32(%q1)           \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm1    \n\t"
+            "movq      %%nacl:16(%%r15, %q1), %%mm4    \n\t"
+            "movq      %%nacl:24(%%r15, %q1), %%mm5    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm1, %%mm3    \n\t"
             "movq       %%mm4, %%mm6    \n\t"
@@ -190,22 +196,22 @@ static inline void RENAME(rgb15to16)(const uint8_t *src, uint8_t *dst, int src_s
     register const uint8_t *end;
     const uint8_t *mm_end;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s));
-    __asm__ volatile("movq        %0, %%mm4"::"m"(mask15s));
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s));
+    __asm__ volatile("movq        %q0, %%mm4"::"m"(mask15s));
     mm_end = end - 15;
     while (s<mm_end) {
         __asm__ volatile(
-            PREFETCH" 32(%1)        \n\t"
-            "movq      (%1), %%mm0  \n\t"
-            "movq     8(%1), %%mm2  \n\t"
+            PREFETCH" 32(%%r15, %q1)        \n\t"
+            "movq      %%nacl:(%%r15, %q1), %%mm0  \n\t"
+            "movq     %%nacl:8(%%r15, %q1), %%mm2  \n\t"
             "movq     %%mm0, %%mm1  \n\t"
             "movq     %%mm2, %%mm3  \n\t"
             "pand     %%mm4, %%mm0  \n\t"
             "pand     %%mm4, %%mm2  \n\t"
             "paddw    %%mm1, %%mm0  \n\t"
             "paddw    %%mm3, %%mm2  \n\t"
-            MOVNTQ"   %%mm0,  (%0)  \n\t"
-            MOVNTQ"   %%mm2, 8(%0)"
+            MOVNTQ"   %%mm0,  %%nacl:(%%r15, %q0)  \n\t"
+            MOVNTQ"   %%mm2, %%nacl:8(%%r15, %q0)"
             :: "r"(d), "r"(s)
         );
         d+=16;
@@ -233,15 +239,15 @@ static inline void RENAME(rgb16to15)(const uint8_t *src, uint8_t *dst, int src_s
     register const uint8_t *end;
     const uint8_t *mm_end;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s));
-    __asm__ volatile("movq        %0, %%mm7"::"m"(mask15rg));
-    __asm__ volatile("movq        %0, %%mm6"::"m"(mask15b));
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s));
+    __asm__ volatile("movq        %q0, %%mm7"::"m"(mask15rg));
+    __asm__ volatile("movq        %q0, %%mm6"::"m"(mask15b));
     mm_end = end - 15;
     while (s<mm_end) {
         __asm__ volatile(
-            PREFETCH" 32(%1)        \n\t"
-            "movq      (%1), %%mm0  \n\t"
-            "movq     8(%1), %%mm2  \n\t"
+            PREFETCH" 32(%%r15, %q1)        \n\t"
+            "movq      %%nacl:(%%r15, %q1), %%mm0  \n\t"
+            "movq     %%nacl:8(%%r15, %q1), %%mm2  \n\t"
             "movq     %%mm0, %%mm1  \n\t"
             "movq     %%mm2, %%mm3  \n\t"
             "psrlq       $1, %%mm0  \n\t"
@@ -252,8 +258,8 @@ static inline void RENAME(rgb16to15)(const uint8_t *src, uint8_t *dst, int src_s
             "pand     %%mm6, %%mm3  \n\t"
             "por      %%mm1, %%mm0  \n\t"
             "por      %%mm3, %%mm2  \n\t"
-            MOVNTQ"   %%mm0,  (%0)  \n\t"
-            MOVNTQ"   %%mm2, 8(%0)"
+            MOVNTQ"   %%mm0,  %%nacl:(%%r15, %q0)  \n\t"
+            MOVNTQ"   %%mm2, %%nacl:8(%%r15, %q0)"
             :: "r"(d), "r"(s)
         );
         d+=16;
@@ -283,17 +289,17 @@ static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, int src_s
     end = s + src_size;
     mm_end = end - 15;
     __asm__ volatile(
-        "movq           %3, %%mm5   \n\t"
-        "movq           %4, %%mm6   \n\t"
-        "movq           %5, %%mm7   \n\t"
+        "movq           %q3, %%mm5   \n\t"
+        "movq           %q4, %%mm6   \n\t"
+        "movq           %q5, %%mm7   \n\t"
         "jmp 2f                     \n\t"
         ".p2align        4          \n\t"
         "1:                         \n\t"
-        PREFETCH"   32(%1)          \n\t"
-        "movd         (%1), %%mm0   \n\t"
-        "movd        4(%1), %%mm3   \n\t"
-        "punpckldq   8(%1), %%mm0   \n\t"
-        "punpckldq  12(%1), %%mm3   \n\t"
+        PREFETCH"   32(%%r15, %q1)          \n\t"
+        "movd         %%nacl:(%%r15, %q1), %%mm0   \n\t"
+        "movd        %%nacl:4(%%r15, %q1), %%mm3   \n\t"
+        "punpckldq   %%nacl:8(%%r15, %q1), %%mm0   \n\t"
+        "punpckldq  %%nacl:12(%%r15, %q1), %%mm3   \n\t"
         "movq        %%mm0, %%mm1   \n\t"
         "movq        %%mm3, %%mm4   \n\t"
         "pand        %%mm6, %%mm0   \n\t"
@@ -307,11 +313,11 @@ static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, int src_s
         "psrld          $5, %%mm0   \n\t"
         "pslld         $11, %%mm3   \n\t"
         "por         %%mm3, %%mm0   \n\t"
-        MOVNTQ"      %%mm0, (%0)    \n\t"
-        "add           $16,  %1     \n\t"
-        "add            $8,  %0     \n\t"
+        MOVNTQ"      %%mm0, %%nacl:(%%r15, %q0)    \n\t"
+        "add           $16,  %q1     \n\t"
+        "add            $8,  %q0     \n\t"
         "2:                         \n\t"
-        "cmp            %2,  %1     \n\t"
+        "cmp            %q2,  %q1     \n\t"
         " jb            1b          \n\t"
         : "+r" (d), "+r"(s)
         : "r" (mm_end), "m" (mask3216g), "m" (mask3216br), "m" (mul3216)
@@ -331,19 +337,19 @@ static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq          %0, %%mm7    \n\t"
-        "movq          %1, %%mm6    \n\t"
+        "movq          %q0, %%mm7    \n\t"
+        "movq          %q1, %%mm6    \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 15;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "movd       4(%1), %%mm3    \n\t"
-            "punpckldq  8(%1), %%mm0    \n\t"
-            "punpckldq 12(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:4(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq  %%nacl:8(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq %%nacl:12(%%r15, %q1), %%mm3    \n\t"
             "movq       %%mm0, %%mm1    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm3, %%mm4    \n\t"
@@ -358,15 +364,15 @@ static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, int sr
             "pand       %%mm6, %%mm4    \n\t"
             "psrlq        $19, %%mm2    \n\t"
             "psrlq        $19, %%mm5    \n\t"
-            "pand          %2, %%mm2    \n\t"
-            "pand          %2, %%mm5    \n\t"
+            "pand          %q2, %%mm2    \n\t"
+            "pand          %q2, %%mm5    \n\t"
             "por        %%mm1, %%mm0    \n\t"
             "por        %%mm4, %%mm3    \n\t"
             "por        %%mm2, %%mm0    \n\t"
             "por        %%mm5, %%mm3    \n\t"
             "psllq        $16, %%mm3    \n\t"
             "por        %%mm3, %%mm0    \n\t"
-            MOVNTQ"     %%mm0, (%0)     \n\t"
+            MOVNTQ"     %%mm0, %%nacl:(%%r15, %q0)     \n\t"
             :: "r"(d),"r"(s),"m"(blue_16mask):"memory");
         d += 4;
         s += 16;
@@ -388,17 +394,17 @@ static inline void RENAME(rgb32to15)(const uint8_t *src, uint8_t *dst, int src_s
     end = s + src_size;
     mm_end = end - 15;
     __asm__ volatile(
-        "movq           %3, %%mm5   \n\t"
-        "movq           %4, %%mm6   \n\t"
-        "movq           %5, %%mm7   \n\t"
+        "movq           %q3, %%mm5   \n\t"
+        "movq           %q4, %%mm6   \n\t"
+        "movq           %q5, %%mm7   \n\t"
         "jmp            2f          \n\t"
         ".p2align        4          \n\t"
         "1:                         \n\t"
-        PREFETCH"   32(%1)          \n\t"
-        "movd         (%1), %%mm0   \n\t"
-        "movd        4(%1), %%mm3   \n\t"
-        "punpckldq   8(%1), %%mm0   \n\t"
-        "punpckldq  12(%1), %%mm3   \n\t"
+        PREFETCH"   32(%%r15, %q1)          \n\t"
+        "movd         %%nacl:(%%r15, %q1), %%mm0   \n\t"
+        "movd        %%nacl:4(%%r15, %q1), %%mm3   \n\t"
+        "punpckldq   %%nacl:8(%%r15, %q1), %%mm0   \n\t"
+        "punpckldq  %%nacl:12(%%r15, %q1), %%mm3   \n\t"
         "movq        %%mm0, %%mm1   \n\t"
         "movq        %%mm3, %%mm4   \n\t"
         "pand        %%mm6, %%mm0   \n\t"
@@ -412,11 +418,11 @@ static inline void RENAME(rgb32to15)(const uint8_t *src, uint8_t *dst, int src_s
         "psrld          $6, %%mm0   \n\t"
         "pslld         $10, %%mm3   \n\t"
         "por         %%mm3, %%mm0   \n\t"
-        MOVNTQ"      %%mm0, (%0)    \n\t"
-        "add           $16,  %1     \n\t"
-        "add            $8,  %0     \n\t"
+        MOVNTQ"      %%mm0, %%nacl:(%%r15, %q0)    \n\t"
+        "add           $16,  %q1     \n\t"
+        "add            $8,  %q0     \n\t"
         "2:                         \n\t"
-        "cmp            %2,  %1     \n\t"
+        "cmp            %q2,  %q1     \n\t"
         " jb            1b          \n\t"
         : "+r" (d), "+r"(s)
         : "r" (mm_end), "m" (mask3215g), "m" (mask3216br), "m" (mul3215)
@@ -436,19 +442,19 @@ static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq          %0, %%mm7    \n\t"
-        "movq          %1, %%mm6    \n\t"
+        "movq          %q0, %%mm7    \n\t"
+        "movq          %q1, %%mm6    \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 15;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "movd       4(%1), %%mm3    \n\t"
-            "punpckldq  8(%1), %%mm0    \n\t"
-            "punpckldq 12(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:4(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq  %%nacl:8(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq %%nacl:12(%%r15, %q1), %%mm3    \n\t"
             "movq       %%mm0, %%mm1    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm3, %%mm4    \n\t"
@@ -463,15 +469,15 @@ static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, int sr
             "pand       %%mm6, %%mm4    \n\t"
             "psrlq        $19, %%mm2    \n\t"
             "psrlq        $19, %%mm5    \n\t"
-            "pand          %2, %%mm2    \n\t"
-            "pand          %2, %%mm5    \n\t"
+            "pand          %q2, %%mm2    \n\t"
+            "pand          %q2, %%mm5    \n\t"
             "por        %%mm1, %%mm0    \n\t"
             "por        %%mm4, %%mm3    \n\t"
             "por        %%mm2, %%mm0    \n\t"
             "por        %%mm5, %%mm3    \n\t"
             "psllq        $16, %%mm3    \n\t"
             "por        %%mm3, %%mm0    \n\t"
-            MOVNTQ"     %%mm0, (%0)     \n\t"
+            MOVNTQ"     %%mm0, %%nacl:(%%r15, %q0)     \n\t"
             ::"r"(d),"r"(s),"m"(blue_15mask):"memory");
         d += 4;
         s += 16;
@@ -491,27 +497,27 @@ static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq         %0, %%mm7     \n\t"
-        "movq         %1, %%mm6     \n\t"
+        "movq         %q0, %%mm7     \n\t"
+        "movq         %q1, %%mm6     \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 11;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "movd       3(%1), %%mm3    \n\t"
-            "punpckldq  6(%1), %%mm0    \n\t"
-            "punpckldq  9(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:3(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq  %%nacl:6(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq  %%nacl:9(%%r15, %q1), %%mm3    \n\t"
             "movq       %%mm0, %%mm1    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm3, %%mm4    \n\t"
             "movq       %%mm3, %%mm5    \n\t"
             "psrlq         $3, %%mm0    \n\t"
             "psrlq         $3, %%mm3    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %2, %%mm3    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q2, %%mm3    \n\t"
             "psrlq         $5, %%mm1    \n\t"
             "psrlq         $5, %%mm4    \n\t"
             "pand       %%mm6, %%mm1    \n\t"
@@ -526,7 +532,7 @@ static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, int sr
             "por        %%mm5, %%mm3    \n\t"
             "psllq        $16, %%mm3    \n\t"
             "por        %%mm3, %%mm0    \n\t"
-            MOVNTQ"     %%mm0, (%0)     \n\t"
+            MOVNTQ"     %%mm0, %%nacl:(%%r15, %q0)     \n\t"
             ::"r"(d),"r"(s),"m"(blue_16mask):"memory");
         d += 4;
         s += 12;
@@ -548,19 +554,19 @@ static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, int src_s
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq         %0, %%mm7     \n\t"
-        "movq         %1, %%mm6     \n\t"
+        "movq         %q0, %%mm7     \n\t"
+        "movq         %q1, %%mm6     \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 15;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "movd       3(%1), %%mm3    \n\t"
-            "punpckldq  6(%1), %%mm0    \n\t"
-            "punpckldq  9(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:3(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq  %%nacl:6(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq  %%nacl:9(%%r15, %q1), %%mm3    \n\t"
             "movq       %%mm0, %%mm1    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm3, %%mm4    \n\t"
@@ -575,15 +581,15 @@ static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, int src_s
             "pand       %%mm6, %%mm4    \n\t"
             "psrlq        $19, %%mm2    \n\t"
             "psrlq        $19, %%mm5    \n\t"
-            "pand          %2, %%mm2    \n\t"
-            "pand          %2, %%mm5    \n\t"
+            "pand          %q2, %%mm2    \n\t"
+            "pand          %q2, %%mm5    \n\t"
             "por        %%mm1, %%mm0    \n\t"
             "por        %%mm4, %%mm3    \n\t"
             "por        %%mm2, %%mm0    \n\t"
             "por        %%mm5, %%mm3    \n\t"
             "psllq        $16, %%mm3    \n\t"
             "por        %%mm3, %%mm0    \n\t"
-            MOVNTQ"     %%mm0, (%0)     \n\t"
+            MOVNTQ"     %%mm0, %%nacl:(%%r15, %q0)     \n\t"
             ::"r"(d),"r"(s),"m"(blue_16mask):"memory");
         d += 4;
         s += 12;
@@ -605,27 +611,27 @@ static inline void RENAME(rgb24tobgr15)(const uint8_t *src, uint8_t *dst, int sr
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq          %0, %%mm7    \n\t"
-        "movq          %1, %%mm6    \n\t"
+        "movq          %q0, %%mm7    \n\t"
+        "movq          %q1, %%mm6    \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 11;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movd        (%1), %%mm0    \n\t"
-            "movd       3(%1), %%mm3    \n\t"
-            "punpckldq  6(%1), %%mm0    \n\t"
-            "punpckldq  9(%1), %%mm3    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movd        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movd       %%nacl:3(%%r15, %q1), %%mm3    \n\t"
+            "punpckldq  %%nacl:6(%%r15, %q1), %%mm0    \n\t"
+            "punpckldq  %%nacl:9(%%r15, %q1), %%mm3    \n\t"
             "movq       %%mm0, %%mm1    \n\t"
             "movq       %%mm0, %%mm2    \n\t"
             "movq       %%mm3, %%mm4    \n\t"
             "movq       %%mm3, %%mm5    \n\t"
             "psrlq         $3, %%mm0    \n\t"
             "psrlq         $3, %%mm3    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %2, %%mm3    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q2, %%mm3    \n\t"
             "psrlq         $6, %%mm1    \n\t"
             "psrlq         $6, %%mm4    \n\t"
             "pand       %%mm6, %%mm1    \n\t"
@@ -640,7 +646,7 @@ static inline void RENAME(rgb24tobgr15)(const uint8_t *src, uint8_t *dst, int sr
             "por        %%mm5, %%mm3    \n\t"
             "psllq        $16, %%mm3    \n\t"
             "por        %%mm3, %%mm0    \n\t"
-            MOVNTQ"     %%mm0, (%0)     \n\t"
+            MOVNTQ"     %%mm0, %%nacl:(%%r15, %q0)     \n\t"
             ::"r"(d),"r"(s),"m"(blue_15mask):"memory");
         d += 4;
         s += 12;
@@ -662,19 +668,19 @@ static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, int src_s
     const uint8_t *mm_end;
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*src):"memory");
     __asm__ volatile(
-        "movq         %0, %%mm7     \n\t"
-        "movq         %1, %%mm6     \n\t"
+        "movq         %q0, %%mm7     \n\t"
+        "movq         %q1, %%mm6     \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 15;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH" 32(%1)            \n\t"
-            "movd       (%1), %%mm0     \n\t"
-            "movd      3(%1), %%mm3     \n\t"
-            "punpckldq 6(%1), %%mm0     \n\t"
-            "punpckldq 9(%1), %%mm3     \n\t"
+            PREFETCH" 32(%%r15, %q1)            \n\t"
+            "movd       %%nacl:(%%r15, %q1), %%mm0     \n\t"
+            "movd      %%nacl:3(%%r15, %q1), %%mm3     \n\t"
+            "punpckldq %%nacl:6(%%r15, %q1), %%mm0     \n\t"
+            "punpckldq %%nacl:9(%%r15, %q1), %%mm3     \n\t"
             "movq      %%mm0, %%mm1     \n\t"
             "movq      %%mm0, %%mm2     \n\t"
             "movq      %%mm3, %%mm4     \n\t"
@@ -689,15 +695,15 @@ static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, int src_s
             "pand      %%mm6, %%mm4     \n\t"
             "psrlq       $19, %%mm2     \n\t"
             "psrlq       $19, %%mm5     \n\t"
-            "pand         %2, %%mm2     \n\t"
-            "pand         %2, %%mm5     \n\t"
+            "pand         %q2, %%mm2     \n\t"
+            "pand         %q2, %%mm5     \n\t"
             "por       %%mm1, %%mm0     \n\t"
             "por       %%mm4, %%mm3     \n\t"
             "por       %%mm2, %%mm0     \n\t"
             "por       %%mm5, %%mm3     \n\t"
             "psllq       $16, %%mm3     \n\t"
             "por       %%mm3, %%mm0     \n\t"
-            MOVNTQ"    %%mm0, (%0)      \n\t"
+            MOVNTQ"    %%mm0, %%nacl:(%%r15, %q0)      \n\t"
             ::"r"(d),"r"(s),"m"(blue_15mask):"memory");
         d += 4;
         s += 12;
@@ -719,17 +725,17 @@ static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, int sr
     uint8_t *d = dst;
     const uint16_t *s = (const uint16_t*)src;
     end = s + src_size/2;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     mm_end = end - 7;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movq        (%1), %%mm0    \n\t"
-            "movq        (%1), %%mm1    \n\t"
-            "movq        (%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm1    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm0    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm1    \n\t"
@@ -737,12 +743,12 @@ static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm3    \n\t"
             "movq       %%mm1, %%mm4    \n\t"
             "movq       %%mm2, %%mm5    \n\t"
-            "punpcklwd     %5, %%mm0    \n\t"
-            "punpcklwd     %5, %%mm1    \n\t"
-            "punpcklwd     %5, %%mm2    \n\t"
-            "punpckhwd     %5, %%mm3    \n\t"
-            "punpckhwd     %5, %%mm4    \n\t"
-            "punpckhwd     %5, %%mm5    \n\t"
+            "punpcklwd     %q5, %%mm0    \n\t"
+            "punpcklwd     %q5, %%mm1    \n\t"
+            "punpcklwd     %q5, %%mm2    \n\t"
+            "punpckhwd     %q5, %%mm3    \n\t"
+            "punpckhwd     %q5, %%mm4    \n\t"
+            "punpckhwd     %q5, %%mm5    \n\t"
             "psllq         $8, %%mm1    \n\t"
             "psllq        $16, %%mm2    \n\t"
             "por        %%mm1, %%mm0    \n\t"
@@ -755,12 +761,12 @@ static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm6    \n\t"
             "movq       %%mm3, %%mm7    \n\t"
 
-            "movq       8(%1), %%mm0    \n\t"
-            "movq       8(%1), %%mm1    \n\t"
-            "movq       8(%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm0    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm1    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm0    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm1    \n\t"
@@ -768,12 +774,12 @@ static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm3    \n\t"
             "movq       %%mm1, %%mm4    \n\t"
             "movq       %%mm2, %%mm5    \n\t"
-            "punpcklwd     %5, %%mm0    \n\t"
-            "punpcklwd     %5, %%mm1    \n\t"
-            "punpcklwd     %5, %%mm2    \n\t"
-            "punpckhwd     %5, %%mm3    \n\t"
-            "punpckhwd     %5, %%mm4    \n\t"
-            "punpckhwd     %5, %%mm5    \n\t"
+            "punpcklwd     %q5, %%mm0    \n\t"
+            "punpcklwd     %q5, %%mm1    \n\t"
+            "punpcklwd     %q5, %%mm2    \n\t"
+            "punpckhwd     %q5, %%mm3    \n\t"
+            "punpckhwd     %q5, %%mm4    \n\t"
+            "punpckhwd     %q5, %%mm5    \n\t"
             "psllq         $8, %%mm1    \n\t"
             "psllq        $16, %%mm2    \n\t"
             "por        %%mm1, %%mm0    \n\t"
@@ -823,17 +829,17 @@ static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int sr
     uint8_t *d = (uint8_t *)dst;
     const uint16_t *s = (const uint16_t *)src;
     end = s + src_size/2;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     mm_end = end - 7;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movq        (%1), %%mm0    \n\t"
-            "movq        (%1), %%mm1    \n\t"
-            "movq        (%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm1    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
             "psrlq         $1, %%mm2    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm0    \n\t"
@@ -842,12 +848,12 @@ static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm3    \n\t"
             "movq       %%mm1, %%mm4    \n\t"
             "movq       %%mm2, %%mm5    \n\t"
-            "punpcklwd     %5, %%mm0    \n\t"
-            "punpcklwd     %5, %%mm1    \n\t"
-            "punpcklwd     %5, %%mm2    \n\t"
-            "punpckhwd     %5, %%mm3    \n\t"
-            "punpckhwd     %5, %%mm4    \n\t"
-            "punpckhwd     %5, %%mm5    \n\t"
+            "punpcklwd     %q5, %%mm0    \n\t"
+            "punpcklwd     %q5, %%mm1    \n\t"
+            "punpcklwd     %q5, %%mm2    \n\t"
+            "punpckhwd     %q5, %%mm3    \n\t"
+            "punpckhwd     %q5, %%mm4    \n\t"
+            "punpckhwd     %q5, %%mm5    \n\t"
             "psllq         $8, %%mm1    \n\t"
             "psllq        $16, %%mm2    \n\t"
             "por        %%mm1, %%mm0    \n\t"
@@ -860,12 +866,12 @@ static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm6    \n\t"
             "movq       %%mm3, %%mm7    \n\t"
 
-            "movq       8(%1), %%mm0    \n\t"
-            "movq       8(%1), %%mm1    \n\t"
-            "movq       8(%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm0    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm1    \n\t"
+            "movq       %%nacl:8(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
             "psrlq         $1, %%mm2    \n\t"
             "pmulhw        "MANGLE(mul15_mid)", %%mm0    \n\t"
@@ -874,12 +880,12 @@ static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int sr
             "movq       %%mm0, %%mm3    \n\t"
             "movq       %%mm1, %%mm4    \n\t"
             "movq       %%mm2, %%mm5    \n\t"
-            "punpcklwd     %5, %%mm0    \n\t"
-            "punpcklwd     %5, %%mm1    \n\t"
-            "punpcklwd     %5, %%mm2    \n\t"
-            "punpckhwd     %5, %%mm3    \n\t"
-            "punpckhwd     %5, %%mm4    \n\t"
-            "punpckhwd     %5, %%mm5    \n\t"
+            "punpcklwd     %q5, %%mm0    \n\t"
+            "punpcklwd     %q5, %%mm1    \n\t"
+            "punpcklwd     %q5, %%mm2    \n\t"
+            "punpckhwd     %q5, %%mm3    \n\t"
+            "punpckhwd     %q5, %%mm4    \n\t"
+            "punpckhwd     %q5, %%mm5    \n\t"
             "psllq         $8, %%mm1    \n\t"
             "psllq        $16, %%mm2    \n\t"
             "por        %%mm1, %%mm0    \n\t"
@@ -937,8 +943,8 @@ static inline void RENAME(rgb16tobgr24)(const uint8_t *src, uint8_t *dst, int sr
     "movq       %%mm0, %%mm3    \n\t"                               \
     "punpcklwd  %%mm2, %%mm0    \n\t" /* FF R1 G1 B1 FF R0 G0 B0 */ \
     "punpckhwd  %%mm2, %%mm3    \n\t" /* FF R3 G3 B3 FF R2 G2 B2 */ \
-    MOVNTQ"     %%mm0,  (%0)    \n\t"                               \
-    MOVNTQ"     %%mm3, 8(%0)    \n\t"                               \
+    MOVNTQ"     %%mm0,  %%nacl:(%%r15, %q0)    \n\t"                               \
+    MOVNTQ"     %%mm3, %%nacl:8(%%r15, %q0)    \n\t"                               \
 
 static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, int src_size)
 {
@@ -947,22 +953,22 @@ static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, int src_s
     uint8_t *d = dst;
     const uint16_t *s = (const uint16_t *)src;
     end = s + src_size/2;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     __asm__ volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
     __asm__ volatile("pcmpeqd %%mm6,%%mm6    \n\t":::"memory");
     mm_end = end - 3;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movq        (%1), %%mm0    \n\t"
-            "movq        (%1), %%mm1    \n\t"
-            "movq        (%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm1    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
-            "pmulhw        %5, %%mm0    \n\t"
-            "pmulhw        %5, %%mm1    \n\t"
+            "pmulhw        %q5, %%mm0    \n\t"
+            "pmulhw        %q5, %%mm1    \n\t"
             "pmulhw        "MANGLE(mul15_hi)", %%mm2    \n\t"
             PACK_RGB32
             ::"r"(d),"r"(s),"m"(mask15b),"m"(mask15g),"m"(mask15r) ,"m"(mul15_mid)
@@ -989,22 +995,22 @@ static inline void RENAME(rgb16to32)(const uint8_t *src, uint8_t *dst, int src_s
     uint8_t *d = dst;
     const uint16_t *s = (const uint16_t*)src;
     end = s + src_size/2;
-    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %q0"::"m"(*s):"memory");
     __asm__ volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
     __asm__ volatile("pcmpeqd %%mm6,%%mm6    \n\t":::"memory");
     mm_end = end - 3;
     while (s < mm_end) {
         __asm__ volatile(
-            PREFETCH"  32(%1)           \n\t"
-            "movq        (%1), %%mm0    \n\t"
-            "movq        (%1), %%mm1    \n\t"
-            "movq        (%1), %%mm2    \n\t"
-            "pand          %2, %%mm0    \n\t"
-            "pand          %3, %%mm1    \n\t"
-            "pand          %4, %%mm2    \n\t"
+            PREFETCH"  32(%%r15, %q1)           \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm0    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm1    \n\t"
+            "movq        %%nacl:(%%r15, %q1), %%mm2    \n\t"
+            "pand          %q2, %%mm0    \n\t"
+            "pand          %q3, %%mm1    \n\t"
+            "pand          %q4, %%mm2    \n\t"
             "psllq         $5, %%mm0    \n\t"
             "psrlq         $1, %%mm2    \n\t"
-            "pmulhw        %5, %%mm0    \n\t"
+            "pmulhw        %q5, %%mm0    \n\t"
             "pmulhw        "MANGLE(mul16_mid)", %%mm1    \n\t"
             "pmulhw        "MANGLE(mul15_hi)", %%mm2    \n\t"
             PACK_RGB32
@@ -1031,18 +1037,18 @@ static inline void RENAME(shuffle_bytes_2103)(const uint8_t *src, uint8_t *dst,
     const uint8_t *s = src-idx;
     uint8_t *d = dst-idx;
     __asm__ volatile(
-        "test          %0, %0           \n\t"
+        "test          %q0, %q0           \n\t"
         "jns           2f               \n\t"
-        PREFETCH"       (%1, %0)        \n\t"
-        "movq          %3, %%mm7        \n\t"
-        "pxor          %4, %%mm7        \n\t"
+        PREFETCH"       (%q1, %q0)        \n\t"
+        "movq          %q3, %%mm7        \n\t"
+        "pxor          %q4, %%mm7        \n\t"
         "movq       %%mm7, %%mm6        \n\t"
-        "pxor          %5, %%mm7        \n\t"
+        "pxor          %q5, %%mm7        \n\t"
         ".p2align       4               \n\t"
         "1:                             \n\t"
-        PREFETCH"     32(%1, %0)        \n\t"
-        "movq           (%1, %0), %%mm0 \n\t"
-        "movq          8(%1, %0), %%mm1 \n\t"
+        PREFETCH"     32(%q1, %q0)        \n\t"
+        "naclmovq1           \"(%q1, %q0)\", %%mm0 \n\t"
+        "naclmovq1          \"8(%q1, %q0)\", %%mm1 \n\t"
 # if COMPILE_TEMPLATE_MMXEXT
         "pshufw      $177, %%mm0, %%mm3 \n\t"
         "pshufw      $177, %%mm1, %%mm5 \n\t"
@@ -1070,16 +1076,16 @@ static inline void RENAME(shuffle_bytes_2103)(const uint8_t *src, uint8_t *dst,
         "por        %%mm3, %%mm0        \n\t"
         "por        %%mm5, %%mm1        \n\t"
 # endif
-        MOVNTQ"     %%mm0,  (%2, %0)    \n\t"
-        MOVNTQ"     %%mm1, 8(%2, %0)    \n\t"
-        "add          $16, %0           \n\t"
+        NACLMOVNTQ2"     %%mm0,  \"(%q2, %q0)\"    \n\t"
+        NACLMOVNTQ2"     %%mm1, \"8(%q2, %q0)\"    \n\t"
+        "add          $16, %q0           \n\t"
         "js            1b               \n\t"
         SFENCE"                         \n\t"
         EMMS"                           \n\t"
         "2:                             \n\t"
         : "+&r"(idx)
         : "r" (s), "r" (d), "m" (mask32b), "m" (mask32r), "m" (mmx_one)
-        : "memory");
+        : "memory", "%r14");
     for (; idx<15; idx+=4) {
         register int v = *(const uint32_t *)&s[idx], g = v & 0xff00ff00;
         v &= 0xff00ff;
@@ -1099,40 +1105,41 @@ static inline void RENAME(rgb24tobgr24)(const uint8_t *src, uint8_t *dst, int sr
         "movq     "MANGLE(mask24b)", %%mm7              \n\t"
         ".p2align                 4                     \n\t"
         "1:                                             \n\t"
-        PREFETCH" 32(%1, %%"REG_a")                     \n\t"
-        "movq       (%1, %%"REG_a"), %%mm0              \n\t" // BGR BGR BG
-        "movq       (%1, %%"REG_a"), %%mm1              \n\t" // BGR BGR BG
-        "movq      2(%1, %%"REG_a"), %%mm2              \n\t" // R BGR BGR B
+        PREFETCH" 32(%q1, %%"REG_a")                     \n\t"
+        "naclmovq1       \"(%q1, %%"REG_a")\", %%mm0              \n\t" // BGR BGR BG
+        "naclmovq1       \"(%q1, %%"REG_a")\", %%mm1              \n\t" // BGR BGR BG
+        "naclmovq1      \"2(%q1, %%"REG_a")\", %%mm2              \n\t" // R BGR BGR B
         "psllq                  $16, %%mm0              \n\t" // 00 BGR BGR
         "pand                 %%mm5, %%mm0              \n\t"
         "pand                 %%mm6, %%mm1              \n\t"
         "pand                 %%mm7, %%mm2              \n\t"
         "por                  %%mm0, %%mm1              \n\t"
         "por                  %%mm2, %%mm1              \n\t"
-        "movq      6(%1, %%"REG_a"), %%mm0              \n\t" // BGR BGR BG
-        MOVNTQ"               %%mm1,   (%2, %%"REG_a")  \n\t" // RGB RGB RG
-        "movq      8(%1, %%"REG_a"), %%mm1              \n\t" // R BGR BGR B
-        "movq     10(%1, %%"REG_a"), %%mm2              \n\t" // GR BGR BGR
+        "naclmovq1      \"6(%q1, %%"REG_a")\", %%mm0              \n\t" // BGR BGR BG
+        NACLMOVNTQ2"               %%mm1,   \"(%q2, %%"REG_a")\"  \n\t" // RGB RGB RG
+        "naclmovq1      \"8(%q1, %%"REG_a")\", %%mm1              \n\t" // R BGR BGR B
+        "naclmovq1     \"10(%q1, %%"REG_a")\", %%mm2              \n\t" // GR BGR BGR
         "pand                 %%mm7, %%mm0              \n\t"
         "pand                 %%mm5, %%mm1              \n\t"
         "pand                 %%mm6, %%mm2              \n\t"
         "por                  %%mm0, %%mm1              \n\t"
         "por                  %%mm2, %%mm1              \n\t"
-        "movq     14(%1, %%"REG_a"), %%mm0              \n\t" // R BGR BGR B
-        MOVNTQ"               %%mm1,  8(%2, %%"REG_a")  \n\t" // B RGB RGB R
-        "movq     16(%1, %%"REG_a"), %%mm1              \n\t" // GR BGR BGR
-        "movq     18(%1, %%"REG_a"), %%mm2              \n\t" // BGR BGR BG
+        "naclmovq1     \"14(%q1, %%"REG_a")\", %%mm0              \n\t" // R BGR BGR B
+        NACLMOVNTQ2"               %%mm1,  \"8(%q2, %%"REG_a")\"  \n\t" // B RGB RGB R
+        "naclmovq1     \"16(%q1, %%"REG_a")\", %%mm1              \n\t" // GR BGR BGR
+        "naclmovq1     \"18(%q1, %%"REG_a")\", %%mm2              \n\t" // BGR BGR BG
         "pand                 %%mm6, %%mm0              \n\t"
         "pand                 %%mm7, %%mm1              \n\t"
         "pand                 %%mm5, %%mm2              \n\t"
         "por                  %%mm0, %%mm1              \n\t"
         "por                  %%mm2, %%mm1              \n\t"
-        MOVNTQ"               %%mm1, 16(%2, %%"REG_a")  \n\t"
+        NACLMOVNTQ2"               %%mm1, \"16(%q2, %%"REG_a")\"  \n\t"
         "add                    $24, %%"REG_a"          \n\t"
         " js                     1b                     \n\t"
         "2:                                             \n\t"
         : "+a" (mmx_size)
         : "r" (src-mmx_size), "r"(dst-mmx_size)
+               : "%r14"
     );
 
     __asm__ volatile(SFENCE:::"memory");
@@ -1166,17 +1173,17 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
             "xor                 %%"REG_a", %%"REG_a"   \n\t"
             ".p2align                    4              \n\t"
             "1:                                         \n\t"
-            PREFETCH"    32(%1, %%"REG_a", 2)           \n\t"
-            PREFETCH"    32(%2, %%"REG_a")              \n\t"
-            PREFETCH"    32(%3, %%"REG_a")              \n\t"
-            "movq          (%2, %%"REG_a"), %%mm0       \n\t" // U(0)
+            PREFETCH"    32(%q1, %%"REG_a", 2)           \n\t"
+            PREFETCH"    32(%q2, %%"REG_a")              \n\t"
+            PREFETCH"    32(%q3, %%"REG_a")              \n\t"
+            "naclmovq1          \"(%q2, %%"REG_a")\", %%mm0       \n\t" // U(0)
             "movq                    %%mm0, %%mm2       \n\t" // U(0)
-            "movq          (%3, %%"REG_a"), %%mm1       \n\t" // V(0)
+            "naclmovq1          \"(%q3, %%"REG_a")\", %%mm1       \n\t" // V(0)
             "punpcklbw               %%mm1, %%mm0       \n\t" // UVUV UVUV(0)
             "punpckhbw               %%mm1, %%mm2       \n\t" // UVUV UVUV(8)
 
-            "movq        (%1, %%"REG_a",2), %%mm3       \n\t" // Y(0)
-            "movq       8(%1, %%"REG_a",2), %%mm5       \n\t" // Y(8)
+            "naclmovq1        \"(%q1, %%"REG_a",2)\", %%mm3       \n\t" // Y(0)
+            "naclmovq1       \"8(%q1, %%"REG_a",2)\", %%mm5       \n\t" // Y(8)
             "movq                    %%mm3, %%mm4       \n\t" // Y(0)
             "movq                    %%mm5, %%mm6       \n\t" // Y(8)
             "punpcklbw               %%mm0, %%mm3       \n\t" // YUYV YUYV(0)
@@ -1184,13 +1191,13 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
             "punpcklbw               %%mm2, %%mm5       \n\t" // YUYV YUYV(8)
             "punpckhbw               %%mm2, %%mm6       \n\t" // YUYV YUYV(12)
 
-            MOVNTQ"                  %%mm3,   (%0, %%"REG_a", 4)    \n\t"
-            MOVNTQ"                  %%mm4,  8(%0, %%"REG_a", 4)    \n\t"
-            MOVNTQ"                  %%mm5, 16(%0, %%"REG_a", 4)    \n\t"
-            MOVNTQ"                  %%mm6, 24(%0, %%"REG_a", 4)    \n\t"
+            NACLMOVNTQ2"                  %%mm3, \"  (%q0, %%"REG_a", 4)\"    \n\t"
+            NACLMOVNTQ2"                  %%mm4, \" 8(%q0, %%"REG_a", 4)\"    \n\t"
+            NACLMOVNTQ2"                  %%mm5, \"16(%q0, %%"REG_a", 4)\"    \n\t"
+            NACLMOVNTQ2"                  %%mm6, \"24(%q0, %%"REG_a", 4)\"    \n\t"
 
             "add                        $8, %%"REG_a"   \n\t"
-            "cmp                        %4, %%"REG_a"   \n\t"
+            "cmp                        %q4, %%"REG_a"   \n\t"
             " jb                        1b              \n\t"
             ::"r"(dst), "r"(ysrc), "r"(usrc), "r"(vsrc), "g" (chromWidth)
             : "%"REG_a
@@ -1204,7 +1211,7 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
     }
     __asm__(EMMS"       \n\t"
             SFENCE"     \n\t"
-            :::"memory");
+            :::"memory", "%r14");
 }
 
 /**
@@ -1231,17 +1238,17 @@ static inline void RENAME(yuvPlanartouyvy)(const uint8_t *ysrc, const uint8_t *u
             "xor                %%"REG_a", %%"REG_a"    \n\t"
             ".p2align                   4               \n\t"
             "1:                                         \n\t"
-            PREFETCH"   32(%1, %%"REG_a", 2)            \n\t"
-            PREFETCH"   32(%2, %%"REG_a")               \n\t"
-            PREFETCH"   32(%3, %%"REG_a")               \n\t"
-            "movq         (%2, %%"REG_a"), %%mm0        \n\t" // U(0)
+            PREFETCH"   32(%q1, %%"REG_a", 2)            \n\t"
+            PREFETCH"   32(%q2, %%"REG_a")               \n\t"
+            PREFETCH"   32(%q3, %%"REG_a")               \n\t"
+            "naclmovq1         \"(%q2, %%"REG_a")\", %%mm0        \n\t" // U(0)
             "movq                   %%mm0, %%mm2        \n\t" // U(0)
-            "movq         (%3, %%"REG_a"), %%mm1        \n\t" // V(0)
+            "naclmovq1         \"(%q3, %%"REG_a")\", %%mm1        \n\t" // V(0)
             "punpcklbw              %%mm1, %%mm0        \n\t" // UVUV UVUV(0)
             "punpckhbw              %%mm1, %%mm2        \n\t" // UVUV UVUV(8)
 
-            "movq       (%1, %%"REG_a",2), %%mm3        \n\t" // Y(0)
-            "movq      8(%1, %%"REG_a",2), %%mm5        \n\t" // Y(8)
+            "naclmovq1       \"(%q1, %%"REG_a",2)\", %%mm3        \n\t" // Y(0)
+            "naclmovq1      \"8(%q1, %%"REG_a",2)\", %%mm5        \n\t" // Y(8)
             "movq                   %%mm0, %%mm4        \n\t" // Y(0)
             "movq                   %%mm2, %%mm6        \n\t" // Y(8)
             "punpcklbw              %%mm3, %%mm0        \n\t" // YUYV YUYV(0)
@@ -1249,13 +1256,13 @@ static inline void RENAME(yuvPlanartouyvy)(const uint8_t *ysrc, const uint8_t *u
             "punpcklbw              %%mm5, %%mm2        \n\t" // YUYV YUYV(8)
             "punpckhbw              %%mm5, %%mm6        \n\t" // YUYV YUYV(12)
 
-            MOVNTQ"                 %%mm0,   (%0, %%"REG_a", 4)     \n\t"
-            MOVNTQ"                 %%mm4,  8(%0, %%"REG_a", 4)     \n\t"
-            MOVNTQ"                 %%mm2, 16(%0, %%"REG_a", 4)     \n\t"
-            MOVNTQ"                 %%mm6, 24(%0, %%"REG_a", 4)     \n\t"
+            NACLMOVNTQ2"                 %%mm0,   \"(%q0, %%"REG_a", 4)\"     \n\t"
+            NACLMOVNTQ2"                 %%mm4,  \"8(%q0, %%"REG_a", 4)\"     \n\t"
+            NACLMOVNTQ2"                 %%mm2, \"16(%q0, %%"REG_a", 4)\"     \n\t"
+            NACLMOVNTQ2"                 %%mm6, \"24(%q0, %%"REG_a", 4)\"     \n\t"
 
             "add                       $8, %%"REG_a"    \n\t"
-            "cmp                       %4, %%"REG_a"    \n\t"
+            "cmp                       %q4, %%"REG_a"    \n\t"
             " jb                       1b               \n\t"
             ::"r"(dst), "r"(ysrc), "r"(usrc), "r"(vsrc), "g" (chromWidth)
             : "%"REG_a
@@ -1269,7 +1276,7 @@ static inline void RENAME(yuvPlanartouyvy)(const uint8_t *ysrc, const uint8_t *u
     }
     __asm__(EMMS"       \n\t"
             SFENCE"     \n\t"
-            :::"memory");
+            :::"memory", "%r14");
 }
 
 /**
@@ -1321,9 +1328,9 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "psrlw                      $8, %%mm7       \n\t" // FF,00,FF,00...
             ".p2align                    4              \n\t"
             "1:                \n\t"
-            PREFETCH" 64(%0, %%"REG_a", 4)              \n\t"
-            "movq       (%0, %%"REG_a", 4), %%mm0       \n\t" // YUYV YUYV(0)
-            "movq      8(%0, %%"REG_a", 4), %%mm1       \n\t" // YUYV YUYV(4)
+            PREFETCH" 64(%q0, %%"REG_a", 4)              \n\t"
+            "naclmovq1       \"(%q0, %%"REG_a", 4)\", %%mm0       \n\t" // YUYV YUYV(0)
+            "naclmovq1      \"8(%q0, %%"REG_a", 4)\", %%mm1       \n\t" // YUYV YUYV(4)
             "movq                    %%mm0, %%mm2       \n\t" // YUYV YUYV(0)
             "movq                    %%mm1, %%mm3       \n\t" // YUYV YUYV(4)
             "psrlw                      $8, %%mm0       \n\t" // U0V0 U0V0(0)
@@ -1333,10 +1340,10 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb                %%mm1, %%mm0       \n\t" // UVUV UVUV(0)
             "packuswb                %%mm3, %%mm2       \n\t" // YYYY YYYY(0)
 
-            MOVNTQ"                  %%mm2, (%1, %%"REG_a", 2)  \n\t"
+            NACLMOVNTQ2"                  %%mm2, \"(%q1, %%"REG_a", 2)\"  \n\t"
 
-            "movq     16(%0, %%"REG_a", 4), %%mm1       \n\t" // YUYV YUYV(8)
-            "movq     24(%0, %%"REG_a", 4), %%mm2       \n\t" // YUYV YUYV(12)
+            "naclmovq1     \"16(%q0, %%"REG_a", 4)\", %%mm1       \n\t" // YUYV YUYV(8)
+            "naclmovq1     \"24(%q0, %%"REG_a", 4)\", %%mm2       \n\t" // YUYV YUYV(12)
             "movq                    %%mm1, %%mm3       \n\t" // YUYV YUYV(8)
             "movq                    %%mm2, %%mm4       \n\t" // YUYV YUYV(12)
             "psrlw                      $8, %%mm1       \n\t" // U0V0 U0V0(8)
@@ -1346,7 +1353,7 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb                %%mm2, %%mm1       \n\t" // UVUV UVUV(8)
             "packuswb                %%mm4, %%mm3       \n\t" // YYYY YYYY(8)
 
-            MOVNTQ"                  %%mm3, 8(%1, %%"REG_a", 2) \n\t"
+            NACLMOVNTQ2"                  %%mm3, \"8(%q1, %%"REG_a", 2)\" \n\t"
 
             "movq                    %%mm0, %%mm2       \n\t" // UVUV UVUV(0)
             "movq                    %%mm1, %%mm3       \n\t" // UVUV UVUV(8)
@@ -1357,14 +1364,14 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb                %%mm1, %%mm0       \n\t" // VVVV VVVV(0)
             "packuswb                %%mm3, %%mm2       \n\t" // UUUU UUUU(0)
 
-            MOVNTQ"                  %%mm0, (%3, %%"REG_a")     \n\t"
-            MOVNTQ"                  %%mm2, (%2, %%"REG_a")     \n\t"
+            NACLMOVNTQ2"                  %%mm0, \"(%q3, %%"REG_a")\"     \n\t"
+            NACLMOVNTQ2"                  %%mm2, \"(%q2, %%"REG_a")\"     \n\t"
 
             "add                        $8, %%"REG_a"   \n\t"
-            "cmp                        %4, %%"REG_a"   \n\t"
+            "cmp                        %q4, %%"REG_a"   \n\t"
             " jb                        1b              \n\t"
             ::"r"(src), "r"(ydst), "r"(udst), "r"(vdst), "g" (chromWidth)
-            : "memory", "%"REG_a
+            : "memory", "%"REG_a, "%r14"
         );
 
         ydst += lumStride;
@@ -1374,11 +1381,11 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "xor                 %%"REG_a", %%"REG_a"   \n\t"
             ".p2align                    4              \n\t"
             "1:                                         \n\t"
-            PREFETCH" 64(%0, %%"REG_a", 4)              \n\t"
-            "movq       (%0, %%"REG_a", 4), %%mm0       \n\t" // YUYV YUYV(0)
-            "movq      8(%0, %%"REG_a", 4), %%mm1       \n\t" // YUYV YUYV(4)
-            "movq     16(%0, %%"REG_a", 4), %%mm2       \n\t" // YUYV YUYV(8)
-            "movq     24(%0, %%"REG_a", 4), %%mm3       \n\t" // YUYV YUYV(12)
+            PREFETCH" 64(%q0, %%"REG_a", 4)              \n\t"
+            "naclmovq1       \"(%q0, %%"REG_a", 4)\", %%mm0       \n\t" // YUYV YUYV(0)
+            "naclmovq1      \"8(%q0, %%"REG_a", 4)\", %%mm1       \n\t" // YUYV YUYV(4)
+            "naclmovq1     \"16(%q0, %%"REG_a", 4)\", %%mm2       \n\t" // YUYV YUYV(8)
+            "naclmovq1     \"24(%q0, %%"REG_a", 4)\", %%mm3       \n\t" // YUYV YUYV(12)
             "pand                    %%mm7, %%mm0       \n\t" // Y0Y0 Y0Y0(0)
             "pand                    %%mm7, %%mm1       \n\t" // Y0Y0 Y0Y0(4)
             "pand                    %%mm7, %%mm2       \n\t" // Y0Y0 Y0Y0(8)
@@ -1386,15 +1393,15 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb                %%mm1, %%mm0       \n\t" // YYYY YYYY(0)
             "packuswb                %%mm3, %%mm2       \n\t" // YYYY YYYY(8)
 
-            MOVNTQ"                  %%mm0,  (%1, %%"REG_a", 2) \n\t"
-            MOVNTQ"                  %%mm2, 8(%1, %%"REG_a", 2) \n\t"
+            NACLMOVNTQ2"                  %%mm0,  \"(%q1, %%"REG_a", 2)\" \n\t"
+            NACLMOVNTQ2"                  %%mm2, \"8(%q1, %%"REG_a", 2)\" \n\t"
 
             "add                        $8, %%"REG_a"   \n\t"
-            "cmp                        %4, %%"REG_a"   \n\t"
+            "cmp                        %q4, %%"REG_a"   \n\t"
             " jb                        1b              \n\t"
 
             ::"r"(src), "r"(ydst), "r"(udst), "r"(vdst), "g" (chromWidth)
-            : "memory", "%"REG_a
+            : "memory", "%"REG_a, "%r14"
         );
         udst += chromStride;
         vdst += chromStride;
@@ -1426,23 +1433,23 @@ static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, int srcWid
     for (y=1; y<srcHeight; y++) {
         const x86_reg mmxSize= srcWidth&~15;
         __asm__ volatile(
-            "mov           %4, %%"REG_a"            \n\t"
+            "mov           %q4, %%"REG_a"            \n\t"
             "movq        "MANGLE(mmx_ff)", %%mm0    \n\t"
-            "movq         (%0, %%"REG_a"), %%mm4    \n\t"
+            "naclmovq1         \"(%q0, %%"REG_a")\", %%mm4    \n\t"
             "movq                   %%mm4, %%mm2    \n\t"
             "psllq                     $8, %%mm4    \n\t"
             "pand                   %%mm0, %%mm2    \n\t"
             "por                    %%mm2, %%mm4    \n\t"
-            "movq         (%1, %%"REG_a"), %%mm5    \n\t"
+            "naclmovq1         \"(%q1, %%"REG_a")\", %%mm5    \n\t"
             "movq                   %%mm5, %%mm3    \n\t"
             "psllq                     $8, %%mm5    \n\t"
             "pand                   %%mm0, %%mm3    \n\t"
             "por                    %%mm3, %%mm5    \n\t"
             "1:                                     \n\t"
-            "movq         (%0, %%"REG_a"), %%mm0    \n\t"
-            "movq         (%1, %%"REG_a"), %%mm1    \n\t"
-            "movq        1(%0, %%"REG_a"), %%mm2    \n\t"
-            "movq        1(%1, %%"REG_a"), %%mm3    \n\t"
+            "naclmovq1         \"(%q0, %%"REG_a")\", %%mm0    \n\t"
+            "naclmovq1         \"(%q1, %%"REG_a")\", %%mm1    \n\t"
+            "naclmovq1        \"1(%q0, %%"REG_a")\", %%mm2    \n\t"
+            "naclmovq1        \"1(%q1, %%"REG_a")\", %%mm3    \n\t"
             PAVGB"                  %%mm0, %%mm5    \n\t"
             PAVGB"                  %%mm0, %%mm3    \n\t"
             PAVGB"                  %%mm0, %%mm5    \n\t"
@@ -1457,13 +1464,13 @@ static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, int srcWid
             "punpckhbw              %%mm3, %%mm7    \n\t"
             "punpcklbw              %%mm2, %%mm4    \n\t"
             "punpckhbw              %%mm2, %%mm6    \n\t"
-            MOVNTQ"                 %%mm5,  (%2, %%"REG_a", 2)  \n\t"
-            MOVNTQ"                 %%mm7, 8(%2, %%"REG_a", 2)  \n\t"
-            MOVNTQ"                 %%mm4,  (%3, %%"REG_a", 2)  \n\t"
-            MOVNTQ"                 %%mm6, 8(%3, %%"REG_a", 2)  \n\t"
+            NACLMOVNTQ2"                 %%mm5,  \"(%q2, %%"REG_a", 2)\"  \n\t"
+            NACLMOVNTQ2"                 %%mm7, \"8(%q2, %%"REG_a", 2)\"  \n\t"
+            NACLMOVNTQ2"                 %%mm4,  \"(%q3, %%"REG_a", 2)\"  \n\t"
+            NACLMOVNTQ2"                 %%mm6, \"8(%q3, %%"REG_a", 2)\"  \n\t"
             "add                       $8, %%"REG_a"            \n\t"
-            "movq       -1(%0, %%"REG_a"), %%mm4    \n\t"
-            "movq       -1(%1, %%"REG_a"), %%mm5    \n\t"
+            "naclmovq1       \"-1(%q0, %%"REG_a")\", %%mm4    \n\t"
+            "naclmovq1       \"-1(%q1, %%"REG_a")\", %%mm5    \n\t"
             " js                       1b                       \n\t"
             :: "r" (src + mmxSize  ), "r" (src + srcStride + mmxSize  ),
                "r" (dst + mmxSize*2), "r" (dst + dstStride + mmxSize*2),
@@ -1519,9 +1526,9 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "psrlw                  $8, %%mm7   \n\t" // FF,00,FF,00...
             ".p2align                4          \n\t"
             "1:                                 \n\t"
-            PREFETCH" 64(%0, %%"REG_a", 4)          \n\t"
-            "movq       (%0, %%"REG_a", 4), %%mm0   \n\t" // UYVY UYVY(0)
-            "movq      8(%0, %%"REG_a", 4), %%mm1   \n\t" // UYVY UYVY(4)
+            PREFETCH" 64(%q0, %%"REG_a", 4)          \n\t"
+            "naclmovq1       \"(%q0, %%"REG_a", 4)\", %%mm0   \n\t" // UYVY UYVY(0)
+            "naclmovq1      \"8(%q0, %%"REG_a", 4)\", %%mm1   \n\t" // UYVY UYVY(4)
             "movq                %%mm0, %%mm2   \n\t" // UYVY UYVY(0)
             "movq                %%mm1, %%mm3   \n\t" // UYVY UYVY(4)
             "pand                %%mm7, %%mm0   \n\t" // U0V0 U0V0(0)
@@ -1531,10 +1538,10 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb            %%mm1, %%mm0   \n\t" // UVUV UVUV(0)
             "packuswb            %%mm3, %%mm2   \n\t" // YYYY YYYY(0)
 
-            MOVNTQ"              %%mm2,  (%1, %%"REG_a", 2) \n\t"
+            NACLMOVNTQ2"              %%mm2,  \"(%q1, %%"REG_a", 2)\" \n\t"
 
-            "movq     16(%0, %%"REG_a", 4), %%mm1   \n\t" // UYVY UYVY(8)
-            "movq     24(%0, %%"REG_a", 4), %%mm2   \n\t" // UYVY UYVY(12)
+            "naclmovq1     \"16(%q0, %%"REG_a", 4)\", %%mm1   \n\t" // UYVY UYVY(8)
+            "naclmovq1     \"24(%q0, %%"REG_a", 4)\", %%mm2   \n\t" // UYVY UYVY(12)
             "movq                %%mm1, %%mm3   \n\t" // UYVY UYVY(8)
             "movq                %%mm2, %%mm4   \n\t" // UYVY UYVY(12)
             "pand                %%mm7, %%mm1   \n\t" // U0V0 U0V0(8)
@@ -1544,7 +1551,7 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb            %%mm2, %%mm1   \n\t" // UVUV UVUV(8)
             "packuswb            %%mm4, %%mm3   \n\t" // YYYY YYYY(8)
 
-            MOVNTQ"              %%mm3, 8(%1, %%"REG_a", 2) \n\t"
+            NACLMOVNTQ2"              %%mm3, \"8(%q1, %%"REG_a", 2)\" \n\t"
 
             "movq                %%mm0, %%mm2   \n\t" // UVUV UVUV(0)
             "movq                %%mm1, %%mm3   \n\t" // UVUV UVUV(8)
@@ -1555,14 +1562,14 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "packuswb            %%mm1, %%mm0   \n\t" // VVVV VVVV(0)
             "packuswb            %%mm3, %%mm2   \n\t" // UUUU UUUU(0)
 
-            MOVNTQ"              %%mm0, (%3, %%"REG_a") \n\t"
-            MOVNTQ"              %%mm2, (%2, %%"REG_a") \n\t"
+            NACLMOVNTQ2"              %%mm0, \"(%q3, %%"REG_a")\" \n\t"
+            NACLMOVNTQ2"              %%mm2, \"(%q2, %%"REG_a")\" \n\t"
 
             "add                    $8, %%"REG_a"   \n\t"
-            "cmp                    %4, %%"REG_a"   \n\t"
+            "cmp                    %q4, %%"REG_a"   \n\t"
             " jb                    1b          \n\t"
             ::"r"(src), "r"(ydst), "r"(udst), "r"(vdst), "g" (chromWidth)
-            : "memory", "%"REG_a
+            : "memory", "%"REG_a, "%r14"
         );
 
         ydst += lumStride;
@@ -1572,27 +1579,27 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
             "xor                 %%"REG_a", %%"REG_a"   \n\t"
             ".p2align                    4              \n\t"
             "1:                                 \n\t"
-            PREFETCH" 64(%0, %%"REG_a", 4)          \n\t"
-            "movq       (%0, %%"REG_a", 4), %%mm0   \n\t" // YUYV YUYV(0)
-            "movq      8(%0, %%"REG_a", 4), %%mm1   \n\t" // YUYV YUYV(4)
-            "movq     16(%0, %%"REG_a", 4), %%mm2   \n\t" // YUYV YUYV(8)
-            "movq     24(%0, %%"REG_a", 4), %%mm3   \n\t" // YUYV YUYV(12)
+            PREFETCH" 64(%q0, %%"REG_a", 4)          \n\t"
+            "naclmovq1       \"(%q0, %%"REG_a", 4)\", %%mm0   \n\t" // YUYV YUYV(0)
+            "naclmovq1      \"8(%q0, %%"REG_a", 4)\", %%mm1   \n\t" // YUYV YUYV(4)
+            "naclmovq1     \"16(%q0, %%"REG_a", 4)\", %%mm2   \n\t" // YUYV YUYV(8)
+            "naclmovq1     \"24(%q0, %%"REG_a", 4)\", %%mm3   \n\t" // YUYV YUYV(12)
             "psrlw                  $8, %%mm0   \n\t" // Y0Y0 Y0Y0(0)
             "psrlw                  $8, %%mm1   \n\t" // Y0Y0 Y0Y0(4)
             "psrlw                  $8, %%mm2   \n\t" // Y0Y0 Y0Y0(8)
             "psrlw                  $8, %%mm3   \n\t" // Y0Y0 Y0Y0(12)
             "packuswb            %%mm1, %%mm0   \n\t" // YYYY YYYY(0)
-            "packuswb            %%mm3, %%mm2   \n\t" // YYYY YYYY(8)
+            "packuswb            %%mm3, %%   \n\t" // YYYY YYYY(8)
 
-            MOVNTQ"              %%mm0,  (%1, %%"REG_a", 2) \n\t"
-            MOVNTQ"              %%mm2, 8(%1, %%"REG_a", 2) \n\t"
+            NACLMOVNTQ2"              %%mm0,  \"(%q1, %%"REG_a", 2)\" \n\t"
+            NACLMOVNTQ2"              %%mm2, \"8(%q1, %%"REG_a", 2)\" \n\t"
 
             "add                    $8, %%"REG_a"   \n\t"
-            "cmp                    %4, %%"REG_a"   \n\t"
+            "cmp                    %q4, %%"REG_a"   \n\t"
             " jb                    1b          \n\t"
 
             ::"r"(src), "r"(ydst), "r"(udst), "r"(vdst), "g" (chromWidth)
-            : "memory", "%"REG_a
+            : "memory", "%"REG_a, "%r14"
         );
         udst += chromStride;
         vdst += chromStride;
@@ -1627,20 +1634,20 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
         int i;
         for (i=0; i<2; i++) {
             __asm__ volatile(
-                "mov                        %2, %%"REG_a"   \n\t"
-                "movq          "BGR2Y_IDX"(%3), %%mm6       \n\t"
+                "mov                        %q2, %%"REG_a"   \n\t"
+                "movq          %%nacl:"BGR2Y_IDX"(%%r15, %q3), %%mm6       \n\t"
                 "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
                 "pxor                    %%mm7, %%mm7       \n\t"
                 "lea (%%"REG_a", %%"REG_a", 2), %%"REG_d"   \n\t"
                 ".p2align                    4              \n\t"
                 "1:                                         \n\t"
-                PREFETCH"    64(%0, %%"REG_d")              \n\t"
-                "movd          (%0, %%"REG_d"), %%mm0       \n\t"
-                "movd         3(%0, %%"REG_d"), %%mm1       \n\t"
+                PREFETCH"    64(%q0, %%"REG_d")              \n\t"
+                "naclmovd1          \"(%q0, %%"REG_d")\", %%mm0       \n\t"
+                "naclmovd1         \"3(%q0, %%"REG_d")\", %%mm1       \n\t"
                 "punpcklbw               %%mm7, %%mm0       \n\t"
                 "punpcklbw               %%mm7, %%mm1       \n\t"
-                "movd         6(%0, %%"REG_d"), %%mm2       \n\t"
-                "movd         9(%0, %%"REG_d"), %%mm3       \n\t"
+                "naclmovd1         \"6(%q0, %%"REG_d")\", %%mm2       \n\t"
+                "naclmovd1         \"9(%q0, %%"REG_d")\", %%mm3       \n\t"
                 "punpcklbw               %%mm7, %%mm2       \n\t"
                 "punpcklbw               %%mm7, %%mm3       \n\t"
                 "pmaddwd                 %%mm6, %%mm0       \n\t"
@@ -1658,12 +1665,12 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
                 "packssdw                %%mm2, %%mm0       \n\t"
                 "psraw                      $7, %%mm0       \n\t"
 
-                "movd        12(%0, %%"REG_d"), %%mm4       \n\t"
-                "movd        15(%0, %%"REG_d"), %%mm1       \n\t"
+                "naclmovd1        \"12(%q0, %%"REG_d")\", %%mm4       \n\t"
+                "naclmovd1        \"15(%q0, %%"REG_d")\", %%mm1       \n\t"
                 "punpcklbw               %%mm7, %%mm4       \n\t"
                 "punpcklbw               %%mm7, %%mm1       \n\t"
-                "movd        18(%0, %%"REG_d"), %%mm2       \n\t"
-                "movd        21(%0, %%"REG_d"), %%mm3       \n\t"
+                "naclmovd1        \"18(%q0, %%"REG_d")\", %%mm2       \n\t"
+                "naclmovd1        \"21(%q0, %%"REG_d")\", %%mm3       \n\t"
                 "punpcklbw               %%mm7, %%mm2       \n\t"
                 "punpcklbw               %%mm7, %%mm3       \n\t"
                 "pmaddwd                 %%mm6, %%mm4       \n\t"
@@ -1685,7 +1692,7 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
                 "packuswb                %%mm4, %%mm0       \n\t"
                 "paddusb "MANGLE(ff_bgr2YOffset)", %%mm0    \n\t"
 
-                MOVNTQ"                  %%mm0, (%1, %%"REG_a") \n\t"
+                NACLMOVNTQ2"                  %%mm0, \"(%q1, %%"REG_a")\" \n\t"
                 "add                        $8,      %%"REG_a"  \n\t"
                 " js                        1b                  \n\t"
                 : : "r" (src+width*3), "r" (ydst+width), "g" ((x86_reg)-width), "r"(rgb2yuv)
@@ -1696,21 +1703,21 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
         }
         src -= srcStride*2;
         __asm__ volatile(
-            "mov                        %4, %%"REG_a"   \n\t"
+            "mov                        %q4, %%"REG_a"   \n\t"
             "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
-            "movq          "BGR2U_IDX"(%5), %%mm6       \n\t"
+            "movq          %%nacl:"BGR2U_IDX"(%%r15, %q5), %%mm6       \n\t"
             "pxor                    %%mm7, %%mm7       \n\t"
             "lea (%%"REG_a", %%"REG_a", 2), %%"REG_d"   \n\t"
             "add                 %%"REG_d", %%"REG_d"   \n\t"
             ".p2align                    4              \n\t"
             "1:                                         \n\t"
-            PREFETCH"    64(%0, %%"REG_d")              \n\t"
-            PREFETCH"    64(%1, %%"REG_d")              \n\t"
+            PREFETCH"    64(%q0, %%"REG_d")              \n\t"
+            PREFETCH"    64(%q1, %%"REG_d")              \n\t"
 #if COMPILE_TEMPLATE_MMXEXT || COMPILE_TEMPLATE_AMD3DNOW
-            "movq          (%0, %%"REG_d"), %%mm0       \n\t"
-            "movq          (%1, %%"REG_d"), %%mm1       \n\t"
-            "movq         6(%0, %%"REG_d"), %%mm2       \n\t"
-            "movq         6(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovq1          \"(%q0, %%"REG_d")\", %%mm0       \n\t"
+            "naclmovq1          \"(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovq1         \"6(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovq1         \"6(%q1, %%"REG_d")\", %%mm3       \n\t"
             PAVGB"                   %%mm1, %%mm0       \n\t"
             PAVGB"                   %%mm3, %%mm2       \n\t"
             "movq                    %%mm0, %%mm1       \n\t"
@@ -1722,10 +1729,10 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "punpcklbw               %%mm7, %%mm0       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
 #else
-            "movd          (%0, %%"REG_d"), %%mm0       \n\t"
-            "movd          (%1, %%"REG_d"), %%mm1       \n\t"
-            "movd         3(%0, %%"REG_d"), %%mm2       \n\t"
-            "movd         3(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovd1          \"(%q0, %%"REG_d")\", %%mm0       \n\t"
+            "naclmovd1          \"(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovd1         \"3(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovd1         \"3(%q1, %%"REG_d")\", %%mm3       \n\t"
             "punpcklbw               %%mm7, %%mm0       \n\t"
             "punpcklbw               %%mm7, %%mm1       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
@@ -1733,10 +1740,10 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "paddw                   %%mm1, %%mm0       \n\t"
             "paddw                   %%mm3, %%mm2       \n\t"
             "paddw                   %%mm2, %%mm0       \n\t"
-            "movd         6(%0, %%"REG_d"), %%mm4       \n\t"
-            "movd         6(%1, %%"REG_d"), %%mm1       \n\t"
-            "movd         9(%0, %%"REG_d"), %%mm2       \n\t"
-            "movd         9(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovd1         \"6(%q0, %%"REG_d")\", %%mm4       \n\t"
+            "naclmovd1         \"6(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovd1         \"9(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovd1         \"9(%q1, %%"REG_d")\", %%mm3       \n\t"
             "punpcklbw               %%mm7, %%mm4       \n\t"
             "punpcklbw               %%mm7, %%mm1       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
@@ -1747,8 +1754,8 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "psrlw                      $2, %%mm0       \n\t"
             "psrlw                      $2, %%mm2       \n\t"
 #endif
-            "movq          "BGR2V_IDX"(%5), %%mm1       \n\t"
-            "movq          "BGR2V_IDX"(%5), %%mm3       \n\t"
+            "movq          %%nacl:"BGR2V_IDX"(%%r15, %q5), %%mm1       \n\t"
+            "movq          %%nacl:"BGR2V_IDX"(%%r15, %q5), %%mm3       \n\t"
 
             "pmaddwd                 %%mm0, %%mm1       \n\t"
             "pmaddwd                 %%mm2, %%mm3       \n\t"
@@ -1766,10 +1773,10 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "psraw                      $7, %%mm0       \n\t"
 
 #if COMPILE_TEMPLATE_MMXEXT || COMPILE_TEMPLATE_AMD3DNOW
-            "movq        12(%0, %%"REG_d"), %%mm4       \n\t"
-            "movq        12(%1, %%"REG_d"), %%mm1       \n\t"
-            "movq        18(%0, %%"REG_d"), %%mm2       \n\t"
-            "movq        18(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovq1        \"12(%q0, %%"REG_d")\", %%mm4       \n\t"
+            "naclmovq1        \"12(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovq1        \"18(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovq1        \"18(%q1, %%"REG_d")\", %%mm3       \n\t"
             PAVGB"                   %%mm1, %%mm4       \n\t"
             PAVGB"                   %%mm3, %%mm2       \n\t"
             "movq                    %%mm4, %%mm1       \n\t"
@@ -1781,10 +1788,10 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "punpcklbw               %%mm7, %%mm4       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
 #else
-            "movd        12(%0, %%"REG_d"), %%mm4       \n\t"
-            "movd        12(%1, %%"REG_d"), %%mm1       \n\t"
-            "movd        15(%0, %%"REG_d"), %%mm2       \n\t"
-            "movd        15(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovd1        \"12(%q0, %%"REG_d")\", %%mm4       \n\t"
+            "naclmovd1        \"12(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovd1        \"15(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovd1        \"15(%q1, %%"REG_d")\", %%mm3       \n\t"
             "punpcklbw               %%mm7, %%mm4       \n\t"
             "punpcklbw               %%mm7, %%mm1       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
@@ -1792,10 +1799,10 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "paddw                   %%mm1, %%mm4       \n\t"
             "paddw                   %%mm3, %%mm2       \n\t"
             "paddw                   %%mm2, %%mm4       \n\t"
-            "movd        18(%0, %%"REG_d"), %%mm5       \n\t"
-            "movd        18(%1, %%"REG_d"), %%mm1       \n\t"
-            "movd        21(%0, %%"REG_d"), %%mm2       \n\t"
-            "movd        21(%1, %%"REG_d"), %%mm3       \n\t"
+            "naclmovd1        \"18(%q0, %%"REG_d")\", %%mm5       \n\t"
+            "naclmovd1        \"18(%q1, %%"REG_d")\", %%mm1       \n\t"
+            "naclmovd1        \"21(%q0, %%"REG_d")\", %%mm2       \n\t"
+            "naclmovd1        \"21(%q1, %%"REG_d")\", %%mm3       \n\t"
             "punpcklbw               %%mm7, %%mm5       \n\t"
             "punpcklbw               %%mm7, %%mm1       \n\t"
             "punpcklbw               %%mm7, %%mm2       \n\t"
@@ -1807,8 +1814,8 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "psrlw                      $2, %%mm4       \n\t"
             "psrlw                      $2, %%mm2       \n\t"
 #endif
-            "movq          "BGR2V_IDX"(%5), %%mm1       \n\t"
-            "movq          "BGR2V_IDX"(%5), %%mm3       \n\t"
+            "movq          %%nacl:"BGR2V_IDX"(%%r15, %q5), %%mm1       \n\t"
+            "movq          %%nacl:"BGR2V_IDX"(%%r15, %q5), %%mm3       \n\t"
 
             "pmaddwd                 %%mm4, %%mm1       \n\t"
             "pmaddwd                 %%mm2, %%mm3       \n\t"
@@ -1831,13 +1838,13 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             "punpckhdq               %%mm4, %%mm1           \n\t"
             "packsswb                %%mm1, %%mm0           \n\t"
             "paddb "MANGLE(ff_bgr2UVOffset)", %%mm0         \n\t"
-            "movd                    %%mm0, (%2, %%"REG_a") \n\t"
+            "naclmovd2                    %%mm0, \"(%q2, %%"REG_a")\" \n\t"
             "punpckhdq               %%mm0, %%mm0           \n\t"
-            "movd                    %%mm0, (%3, %%"REG_a") \n\t"
+            "naclmovd2                    %%mm0, \"(%q3, %%"REG_a")\" \n\t"
             "add                        $4, %%"REG_a"       \n\t"
             " js                        1b                  \n\t"
             : : "r" (src+chromWidth*6), "r" (src+srcStride+chromWidth*6), "r" (udst+chromWidth), "r" (vdst+chromWidth), "g" (-chromWidth), "r"(rgb2yuv)
-            : "%"REG_a, "%"REG_d
+            : "%"REG_a, "%"REG_d, "%r14"
         );
 
         udst += chromStride;
@@ -1868,46 +1875,46 @@ static void RENAME(interleaveBytes)(const uint8_t *src1, const uint8_t *src2, ui
         __asm__(
             "xor              %%"REG_a", %%"REG_a"  \n\t"
             "1:                                     \n\t"
-            PREFETCH" 64(%1, %%"REG_a")             \n\t"
-            PREFETCH" 64(%2, %%"REG_a")             \n\t"
-            "movdqa     (%1, %%"REG_a"), %%xmm0     \n\t"
-            "movdqa     (%1, %%"REG_a"), %%xmm1     \n\t"
-            "movdqa     (%2, %%"REG_a"), %%xmm2     \n\t"
+            PREFETCH" 64(%q1, %%"REG_a")             \n\t"
+            PREFETCH" 64(%q2, %%"REG_a")             \n\t"
+            "naclmovdqa1     \"(%q1, %%"REG_a")\", %%xmm0     \n\t"
+            "naclmovdqa1     \"(%q1, %%"REG_a")\", %%xmm1     \n\t"
+            "naclmovdqa1     \"(%q2, %%"REG_a")\", %%xmm2     \n\t"
             "punpcklbw           %%xmm2, %%xmm0     \n\t"
             "punpckhbw           %%xmm2, %%xmm1     \n\t"
-            "movntdq             %%xmm0,   (%0, %%"REG_a", 2)   \n\t"
-            "movntdq             %%xmm1, 16(%0, %%"REG_a", 2)   \n\t"
+            "naclmovntdq2             %%xmm0,   \"(%q0, %%"REG_a", 2)\"   \n\t"
+            "naclmovntdq2             %%xmm1, \"16(%q0, %%"REG_a", 2)\"   \n\t"
             "add                    $16, %%"REG_a"  \n\t"
-            "cmp                     %3, %%"REG_a"  \n\t"
+            "cmp                     %q3, %%"REG_a"  \n\t"
             " jb                     1b             \n\t"
             ::"r"(dest), "r"(src1), "r"(src2), "r" ((x86_reg)width-15)
-            : "memory", "%"REG_a""
+            : "memory", "%"REG_a"", "%r14"
         );
 #else
         __asm__(
             "xor %%"REG_a", %%"REG_a"               \n\t"
             "1:                                     \n\t"
-            PREFETCH" 64(%1, %%"REG_a")             \n\t"
-            PREFETCH" 64(%2, %%"REG_a")             \n\t"
-            "movq       (%1, %%"REG_a"), %%mm0      \n\t"
-            "movq      8(%1, %%"REG_a"), %%mm2      \n\t"
+            PREFETCH" 64(%q1, %%"REG_a")             \n\t"
+            PREFETCH" 64(%q2, %%"REG_a")             \n\t"
+            "naclmovq1       \"(%q1, %%"REG_a")\", %%mm0      \n\t"
+            "naclmovq1      \"8(%q1, %%"REG_a")\", %%mm2      \n\t"
             "movq                 %%mm0, %%mm1      \n\t"
             "movq                 %%mm2, %%mm3      \n\t"
-            "movq       (%2, %%"REG_a"), %%mm4      \n\t"
-            "movq      8(%2, %%"REG_a"), %%mm5      \n\t"
+            "naclmovq1       \"(%q2, %%"REG_a")\", %%mm4      \n\t"
+            "naclmovq1      \"8(%q2, %%"REG_a")\", %%mm5      \n\t"
             "punpcklbw            %%mm4, %%mm0      \n\t"
             "punpckhbw            %%mm4, %%mm1      \n\t"
             "punpcklbw            %%mm5, %%mm2      \n\t"
             "punpckhbw            %%mm5, %%mm3      \n\t"
-            MOVNTQ"               %%mm0,   (%0, %%"REG_a", 2)   \n\t"
-            MOVNTQ"               %%mm1,  8(%0, %%"REG_a", 2)   \n\t"
-            MOVNTQ"               %%mm2, 16(%0, %%"REG_a", 2)   \n\t"
-            MOVNTQ"               %%mm3, 24(%0, %%"REG_a", 2)   \n\t"
+            NACLMOVNTQ2"               %%mm0,   \"(%q0, %%"REG_a", 2)\"   \n\t"
+            NACLMOVNTQ2"               %%mm1,  \"8(%q0, %%"REG_a", 2)\"   \n\t"
+            NACLMOVNTQ2"               %%mm2, \"16(%q0, %%"REG_a", 2)\"   \n\t"
+            NACLMOVNTQ2"               %%mm3, \"24(%q0, %%"REG_a", 2)\"   \n\t"
             "add                    $16, %%"REG_a"  \n\t"
-            "cmp                     %3, %%"REG_a"  \n\t"
+            "cmp                     %q3, %%"REG_a"  \n\t"
             " jb                     1b             \n\t"
             ::"r"(dest), "r"(src1), "r"(src2), "r" ((x86_reg)width-15)
-            : "memory", "%"REG_a
+            : "memory", "%"REG_a, "%r14"
         );
 #endif
         for (w= (width&(~15)); w < width; w++) {
@@ -1938,8 +1945,8 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
     int w,h;
     w=width/2; h=height/2;
     __asm__ volatile(
-        PREFETCH" %0    \n\t"
-        PREFETCH" %1    \n\t"
+        PREFETCH" %q0    \n\t"
+        PREFETCH" %q1    \n\t"
         ::"m"(*(src1+srcStride1)),"m"(*(src2+srcStride2)):"memory");
     for (y=0;y<h;y++) {
         const uint8_t* s1=src1+srcStride1*(y>>1);
@@ -1947,11 +1954,11 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
         x=0;
         for (;x<w-31;x+=32) {
             __asm__ volatile(
-                PREFETCH"   32(%1,%2)        \n\t"
-                "movq         (%1,%2), %%mm0 \n\t"
-                "movq        8(%1,%2), %%mm2 \n\t"
-                "movq       16(%1,%2), %%mm4 \n\t"
-                "movq       24(%1,%2), %%mm6 \n\t"
+                PREFETCH"   32(%q1,%q2)        \n\t"
+                "naclmovq1         \"(%q1,%q2)\", %%mm0 \n\t"
+                "naclmovq1        \"8(%q1,%q2)\", %%mm2 \n\t"
+                "naclmovq1       \"16(%q1,%q2)\", %%mm4 \n\t"
+                "naclmovq1       \"24(%q1,%q2)\", %%mm6 \n\t"
                 "movq      %%mm0, %%mm1 \n\t"
                 "movq      %%mm2, %%mm3 \n\t"
                 "movq      %%mm4, %%mm5 \n\t"
@@ -1964,16 +1971,16 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
                 "punpckhbw %%mm5, %%mm5 \n\t"
                 "punpcklbw %%mm6, %%mm6 \n\t"
                 "punpckhbw %%mm7, %%mm7 \n\t"
-                MOVNTQ"    %%mm0,   (%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm1,  8(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm2, 16(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm3, 24(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm4, 32(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm5, 40(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm6, 48(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm7, 56(%0,%2,2)"
+                NACLMOVNTQ2"    %%mm0,   \"(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm1,  \"8(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm2, \"16(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm3, \"24(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm4, \"32(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm5, \"40(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm6, \"48(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm7, \"56(%q0,%q2,2)\""
                 :: "r"(d), "r"(s1), "r"(x)
-                :"memory");
+                :"memory", "%r14");
         }
         for (;x<w;x++) d[2*x]=d[2*x+1]=s1[x];
     }
@@ -1983,11 +1990,11 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
         x=0;
         for (;x<w-31;x+=32) {
             __asm__ volatile(
-                PREFETCH"   32(%1,%2)        \n\t"
-                "movq         (%1,%2), %%mm0 \n\t"
-                "movq        8(%1,%2), %%mm2 \n\t"
-                "movq       16(%1,%2), %%mm4 \n\t"
-                "movq       24(%1,%2), %%mm6 \n\t"
+                PREFETCH"   32(%q1,%q2)        \n\t"
+                "naclmovq1         \"(%q1,%q2)\", %%mm0 \n\t"
+                "naclmovq1        \"8(%q1,%q2)\", %%mm2 \n\t"
+                "naclmovq1       \"16(%q1,%q2)\", %%mm4 \n\t"
+                "naclmovq1       \"24(%q1,%q2)\", %%mm6 \n\t"
                 "movq      %%mm0, %%mm1 \n\t"
                 "movq      %%mm2, %%mm3 \n\t"
                 "movq      %%mm4, %%mm5 \n\t"
@@ -2000,16 +2007,16 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
                 "punpckhbw %%mm5, %%mm5 \n\t"
                 "punpcklbw %%mm6, %%mm6 \n\t"
                 "punpckhbw %%mm7, %%mm7 \n\t"
-                MOVNTQ"    %%mm0,   (%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm1,  8(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm2, 16(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm3, 24(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm4, 32(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm5, 40(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm6, 48(%0,%2,2)  \n\t"
-                MOVNTQ"    %%mm7, 56(%0,%2,2)"
+                NACLMOVNTQ2"    %%mm0,   \"(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm1,  \"8(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm2, \"16(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm3, \"24(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm4, \"32(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm5, \"40(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm6, \"48(%q0,%q2,2)\"  \n\t"
+                NACLMOVNTQ2"    %%mm7, \"56(%q0,%q2,2)\""
                 :: "r"(d), "r"(s2), "r"(x)
-                :"memory");
+                :"memory", "%r14");
         }
         for (;x<w;x++) d[2*x]=d[2*x+1]=s2[x];
     }
@@ -2037,12 +2044,12 @@ static inline void RENAME(yvu9_to_yuy2)(const uint8_t *src1, const uint8_t *src2
         x=0;
         for (;x<w-7;x+=8) {
             __asm__ volatile(
-                PREFETCH"   32(%1, %0)          \n\t"
-                PREFETCH"   32(%2, %0)          \n\t"
-                PREFETCH"   32(%3, %0)          \n\t"
-                "movq      (%1, %0, 4), %%mm0   \n\t" /* Y0Y1Y2Y3Y4Y5Y6Y7 */
-                "movq         (%2, %0), %%mm1   \n\t" /* U0U1U2U3U4U5U6U7 */
-                "movq         (%3, %0), %%mm2   \n\t" /* V0V1V2V3V4V5V6V7 */
+                PREFETCH"   32(%q1, %q0)          \n\t"
+                PREFETCH"   32(%q2, %q0)          \n\t"
+                PREFETCH"   32(%q3, %q0)          \n\t"
+                "naclmovq1      \"(%q1, %q0, 4)\", %%mm0   \n\t" /* Y0Y1Y2Y3Y4Y5Y6Y7 */
+                "naclmovq1         \"(%q2, %q0)\", %%mm1   \n\t" /* U0U1U2U3U4U5U6U7 */
+                "naclmovq1         \"(%q3, %q0)\", %%mm2   \n\t" /* V0V1V2V3V4V5V6V7 */
                 "movq            %%mm0, %%mm3   \n\t" /* Y0Y1Y2Y3Y4Y5Y6Y7 */
                 "movq            %%mm1, %%mm4   \n\t" /* U0U1U2U3U4U5U6U7 */
                 "movq            %%mm2, %%mm5   \n\t" /* V0V1V2V3V4V5V6V7 */
@@ -2055,37 +2062,37 @@ static inline void RENAME(yvu9_to_yuy2)(const uint8_t *src1, const uint8_t *src2
                 "punpcklbw       %%mm2, %%mm1   \n\t" /* U0V0 U0V0 U1V1 U1V1*/
                 "punpcklbw       %%mm1, %%mm0   \n\t" /* Y0U0 Y1V0 Y2U0 Y3V0*/
                 "punpckhbw       %%mm1, %%mm3   \n\t" /* Y4U1 Y5V1 Y6U1 Y7V1*/
-                MOVNTQ"          %%mm0,  (%4, %0, 8)    \n\t"
-                MOVNTQ"          %%mm3, 8(%4, %0, 8)    \n\t"
+                NACLMOVNTQ2"          %%mm0,  \"(%q4, %q0, 8)\"    \n\t"
+                NACLMOVNTQ2"          %%mm3, \"8(%q4, %q0, 8)\"    \n\t"
 
                 "punpckhbw       %%mm2, %%mm6   \n\t" /* U2V2 U2V2 U3V3 U3V3*/
-                "movq     8(%1, %0, 4), %%mm0   \n\t"
+                "naclmovq1     \"8(%q1, %q0, 4)\", %%mm0   \n\t"
                 "movq            %%mm0, %%mm3   \n\t"
                 "punpcklbw       %%mm6, %%mm0   \n\t" /* Y U2 Y V2 Y U2 Y V2*/
                 "punpckhbw       %%mm6, %%mm3   \n\t" /* Y U3 Y V3 Y U3 Y V3*/
-                MOVNTQ"          %%mm0, 16(%4, %0, 8)   \n\t"
-                MOVNTQ"          %%mm3, 24(%4, %0, 8)   \n\t"
+                NACLMOVNTQ2"          %%mm0, \"16(%q4, %q0, 8)\"   \n\t"
+                NACLMOVNTQ2"          %%mm3, \"24(%q4, %q0, 8)\"   \n\t"
 
                 "movq            %%mm4, %%mm6   \n\t"
-                "movq    16(%1, %0, 4), %%mm0   \n\t"
+                "naclmovq1    \"16(%q1, %q0, 4)\", %%mm0   \n\t"
                 "movq            %%mm0, %%mm3   \n\t"
                 "punpcklbw       %%mm5, %%mm4   \n\t"
                 "punpcklbw       %%mm4, %%mm0   \n\t" /* Y U4 Y V4 Y U4 Y V4*/
                 "punpckhbw       %%mm4, %%mm3   \n\t" /* Y U5 Y V5 Y U5 Y V5*/
-                MOVNTQ"          %%mm0, 32(%4, %0, 8)   \n\t"
-                MOVNTQ"          %%mm3, 40(%4, %0, 8)   \n\t"
+                NACLMOVNTQ2"          %%mm0, \"32(%q4, %q0, 8)\"   \n\t"
+                NACLMOVNTQ2"          %%mm3, \"40(%q4, %q0, 8)\"   \n\t"
 
                 "punpckhbw       %%mm5, %%mm6   \n\t"
-                "movq    24(%1, %0, 4), %%mm0   \n\t"
+                "naclmovq1    \"24(%q1, %q0, 4)\", %%mm0   \n\t"
                 "movq            %%mm0, %%mm3   \n\t"
                 "punpcklbw       %%mm6, %%mm0   \n\t" /* Y U6 Y V6 Y U6 Y V6*/
                 "punpckhbw       %%mm6, %%mm3   \n\t" /* Y U7 Y V7 Y U7 Y V7*/
-                MOVNTQ"          %%mm0, 48(%4, %0, 8)   \n\t"
-                MOVNTQ"          %%mm3, 56(%4, %0, 8)   \n\t"
+                NACLMOVNTQ2"          %%mm0, \"48(%q4, %q0, 8)\"   \n\t"
+                NACLMOVNTQ2"          %%mm3, \"56(%q4, %q0, 8)\"   \n\t"
 
                 : "+r" (x)
                 : "r"(yp), "r" (up), "r"(vp), "r"(d)
-                :"memory");
+                :"memory", "%r14");
         }
         for (; x<w; x++) {
             const int x2 = x<<2;
@@ -2119,22 +2126,23 @@ static void RENAME(extract_even)(const uint8_t *src, uint8_t *dst, x86_reg count
             "pcmpeqw       %%mm7, %%mm7        \n\t"
             "psrlw            $8, %%mm7        \n\t"
             "1:                                \n\t"
-            "movq -30(%1, %0, 2), %%mm0        \n\t"
-            "movq -22(%1, %0, 2), %%mm1        \n\t"
-            "movq -14(%1, %0, 2), %%mm2        \n\t"
-            "movq  -6(%1, %0, 2), %%mm3        \n\t"
+            "naclmovq1 \"-30(%q1, %q0, 2)\", %%mm0        \n\t"
+            "naclmovq1 \"-22(%q1, %q0, 2)\", %%mm1        \n\t"
+            "naclmovq1 \"-14(%q1, %q0, 2)\", %%mm2        \n\t"
+            "naclmovq1  \"-6(%q1, %q0, 2)\", %%mm3        \n\t"
             "pand          %%mm7, %%mm0        \n\t"
             "pand          %%mm7, %%mm1        \n\t"
             "pand          %%mm7, %%mm2        \n\t"
             "pand          %%mm7, %%mm3        \n\t"
             "packuswb      %%mm1, %%mm0        \n\t"
             "packuswb      %%mm3, %%mm2        \n\t"
-            MOVNTQ"        %%mm0,-15(%2, %0)   \n\t"
-            MOVNTQ"        %%mm2,- 7(%2, %0)   \n\t"
-            "add             $16, %0           \n\t"
+            NACLMOVNTQ2"        %%mm0,\"-15(%q2, %q0)\"   \n\t"
+            NACLMOVNTQ2"        %%mm2, \"-7(%q2, %q0)\"   \n\t"
+            "add             $16, %q0           \n\t"
             " js 1b                            \n\t"
             : "+r"(count)
             : "r"(src), "r"(dst)
+            : "%r14"
         );
         count -= 15;
     }
@@ -2157,10 +2165,10 @@ static void RENAME(extract_even2)(const uint8_t *src, uint8_t *dst0, uint8_t *ds
             "pcmpeqw       %%mm7, %%mm7        \n\t"
             "psrlw            $8, %%mm7        \n\t"
             "1:                                \n\t"
-            "movq -28(%1, %0, 4), %%mm0        \n\t"
-            "movq -20(%1, %0, 4), %%mm1        \n\t"
-            "movq -12(%1, %0, 4), %%mm2        \n\t"
-            "movq  -4(%1, %0, 4), %%mm3        \n\t"
+            "naclmovq1 \"-28(%q1, %q0, 4)\", %%mm0        \n\t"
+            "naclmovq1 \"-20(%q1, %q0, 4)\", %%mm1        \n\t"
+            "naclmovq1 \"-12(%q1, %q0, 4)\", %%mm2        \n\t"
+            "naclmovq1  \"-4(%q1, %q0, 4)\", %%mm3        \n\t"
             "pand          %%mm7, %%mm0        \n\t"
             "pand          %%mm7, %%mm1        \n\t"
             "pand          %%mm7, %%mm2        \n\t"
@@ -2175,12 +2183,13 @@ static void RENAME(extract_even2)(const uint8_t *src, uint8_t *dst0, uint8_t *ds
             "pand          %%mm7, %%mm3        \n\t"
             "packuswb      %%mm2, %%mm0        \n\t"
             "packuswb      %%mm3, %%mm1        \n\t"
-            MOVNTQ"        %%mm0,- 7(%3, %0)   \n\t"
-            MOVNTQ"        %%mm1,- 7(%2, %0)   \n\t"
-            "add              $8, %0           \n\t"
+            NACLMOVNTQ2"        %%mm0, \"-7(%q3, %q0)\"   \n\t"
+            NACLMOVNTQ2"        %%mm1, \"-7(%q2, %q0)\"   \n\t"
+            "add              $8, %q0           \n\t"
             " js 1b                            \n\t"
             : "+r"(count)
             : "r"(src), "r"(dst0), "r"(dst1)
+                  : "%r14"
         );
         count -= 7;
     }
@@ -2206,14 +2215,14 @@ static void RENAME(extract_even2avg)(const uint8_t *src0, const uint8_t *src1, u
             "pcmpeqw        %%mm7, %%mm7        \n\t"
             "psrlw             $8, %%mm7        \n\t"
             "1:                                \n\t"
-            "movq  -28(%1, %0, 4), %%mm0        \n\t"
-            "movq  -20(%1, %0, 4), %%mm1        \n\t"
-            "movq  -12(%1, %0, 4), %%mm2        \n\t"
-            "movq   -4(%1, %0, 4), %%mm3        \n\t"
-            PAVGB" -28(%2, %0, 4), %%mm0        \n\t"
-            PAVGB" -20(%2, %0, 4), %%mm1        \n\t"
-            PAVGB" -12(%2, %0, 4), %%mm2        \n\t"
-            PAVGB" - 4(%2, %0, 4), %%mm3        \n\t"
+            "naclmovq1  \"-28(%q1, %q0, 4)\", %%mm0        \n\t"
+            "naclmovq1  \"-20(%q1, %q0, 4)\", %%mm1        \n\t"
+            "naclmovq1  \"-12(%q1, %q0, 4)\", %%mm2        \n\t"
+            "naclmovq1   \"-4(%q1, %q0, 4)\", %%mm3        \n\t"
+            NACL_PAVGB1" \"-28(%q2, %q0, 4)\", %%mm0        \n\t"
+            NACL_PAVGB1" \"-20(%q2, %q0, 4)\", %%mm1        \n\t"
+            NACL_PAVGB1" \"-12(%q2, %q0, 4)\", %%mm2        \n\t"
+            NACL_PAVGB1" \"- 4(%q2, %q0, 4)\", %%mm3        \n\t"
             "pand           %%mm7, %%mm0        \n\t"
             "pand           %%mm7, %%mm1        \n\t"
             "pand           %%mm7, %%mm2        \n\t"
@@ -2228,12 +2237,13 @@ static void RENAME(extract_even2avg)(const uint8_t *src0, const uint8_t *src1, u
             "pand           %%mm7, %%mm3        \n\t"
             "packuswb       %%mm2, %%mm0        \n\t"
             "packuswb       %%mm3, %%mm1        \n\t"
-            MOVNTQ"         %%mm0,- 7(%4, %0)   \n\t"
-            MOVNTQ"         %%mm1,- 7(%3, %0)   \n\t"
-            "add               $8, %0           \n\t"
+            NACLMOVNTQ2"         %%mm0, \"-7(%q4, %q0)\"   \n\t"
+            NACLMOVNTQ2"         %%mm1, \"-7(%q3, %q0)\"   \n\t"
+            "add               $8, %q0           \n\t"
             " js 1b                            \n\t"
             : "+r"(count)
             : "r"(src0), "r"(src1), "r"(dst0), "r"(dst1)
+                  : "%r14"
         );
         count -= 7;
     }
@@ -2258,10 +2268,10 @@ static void RENAME(extract_odd2)(const uint8_t *src, uint8_t *dst0, uint8_t *dst
             "pcmpeqw       %%mm7, %%mm7        \n\t"
             "psrlw            $8, %%mm7        \n\t"
             "1:                                \n\t"
-            "movq -28(%1, %0, 4), %%mm0        \n\t"
-            "movq -20(%1, %0, 4), %%mm1        \n\t"
-            "movq -12(%1, %0, 4), %%mm2        \n\t"
-            "movq  -4(%1, %0, 4), %%mm3        \n\t"
+            "naclmovq1 \"-28(%q1, %q0, 4)\", %%mm0        \n\t"
+            "naclmovq1 \"-20(%q1, %q0, 4)\", %%mm1        \n\t"
+            "naclmovq1 \"-12(%q1, %q0, 4)\", %%mm2        \n\t"
+            "naclmovq1  \"-4(%q1, %q0, 4)\", %%mm3        \n\t"
             "psrlw            $8, %%mm0        \n\t"
             "psrlw            $8, %%mm1        \n\t"
             "psrlw            $8, %%mm2        \n\t"
@@ -2276,12 +2286,13 @@ static void RENAME(extract_odd2)(const uint8_t *src, uint8_t *dst0, uint8_t *dst
             "pand          %%mm7, %%mm3        \n\t"
             "packuswb      %%mm2, %%mm0        \n\t"
             "packuswb      %%mm3, %%mm1        \n\t"
-            MOVNTQ"        %%mm0,- 7(%3, %0)   \n\t"
-            MOVNTQ"        %%mm1,- 7(%2, %0)   \n\t"
-            "add              $8, %0           \n\t"
+            NACLMOVNTQ2"        %%mm0, \"-7(%q3, %q0)\"   \n\t"
+            NACLMOVNTQ2"        %%mm1, \"-7(%q2, %q0)\"   \n\t"
+            "add              $8, %q0           \n\t"
             " js 1b                            \n\t"
             : "+r"(count)
             : "r"(src), "r"(dst0), "r"(dst1)
+                  : "%r14"
         );
         count -= 7;
     }
@@ -2308,14 +2319,14 @@ static void RENAME(extract_odd2avg)(const uint8_t *src0, const uint8_t *src1, ui
             "pcmpeqw        %%mm7, %%mm7        \n\t"
             "psrlw             $8, %%mm7        \n\t"
             "1:                                \n\t"
-            "movq  -28(%1, %0, 4), %%mm0        \n\t"
-            "movq  -20(%1, %0, 4), %%mm1        \n\t"
-            "movq  -12(%1, %0, 4), %%mm2        \n\t"
-            "movq   -4(%1, %0, 4), %%mm3        \n\t"
-            PAVGB" -28(%2, %0, 4), %%mm0        \n\t"
-            PAVGB" -20(%2, %0, 4), %%mm1        \n\t"
-            PAVGB" -12(%2, %0, 4), %%mm2        \n\t"
-            PAVGB" - 4(%2, %0, 4), %%mm3        \n\t"
+            "naclmovq1  \"-28(%q1, %q0, 4)\", %%mm0        \n\t"
+            "naclmovq1  \"-20(%q1, %q0, 4)\", %%mm1        \n\t"
+            "naclmovq1  \"-12(%q1, %q0, 4)\", %%mm2        \n\t"
+            "naclmovq1   \"-4(%q1, %q0, 4)\", %%mm3        \n\t"
+            NACL_PAVGB1" \"-28(%q2, %q0, 4)\", %%mm0        \n\t"
+            NACL_PAVGB1" \"-20(%q2, %q0, 4)\", %%mm1        \n\t"
+            NACL_PAVGB1" \"-12(%q2, %q0, 4)\", %%mm2        \n\t"
+            NACL_PAVGB1" \"- 4(%q2, %q0, 4)\", %%mm3        \n\t"
             "psrlw             $8, %%mm0        \n\t"
             "psrlw             $8, %%mm1        \n\t"
             "psrlw             $8, %%mm2        \n\t"
@@ -2330,12 +2341,13 @@ static void RENAME(extract_odd2avg)(const uint8_t *src0, const uint8_t *src1, ui
             "pand           %%mm7, %%mm3        \n\t"
             "packuswb       %%mm2, %%mm0        \n\t"
             "packuswb       %%mm3, %%mm1        \n\t"
-            MOVNTQ"         %%mm0,- 7(%4, %0)   \n\t"
-            MOVNTQ"         %%mm1,- 7(%3, %0)   \n\t"
-            "add               $8, %0           \n\t"
+            NACLMOVNTQ2"         %%mm0, \"-7(%q4, %q0)\"   \n\t"
+            NACLMOVNTQ2"         %%mm1, \"-7(%q3, %q0)\"   \n\t"
+            "add               $8, %q0           \n\t"
             " js 1b                            \n\t"
             : "+r"(count)
             : "r"(src0), "r"(src1), "r"(dst0), "r"(dst1)
+                  : "%r14"
         );
         count -= 7;
     }
diff --git a/libswscale/x86/swscale.c b/libswscale/x86/swscale.c
index a86f9f8..35a6fb0 100644
--- a/libswscale/x86/swscale.c
+++ b/libswscale/x86/swscale.c
@@ -209,7 +209,7 @@ static void yuv2yuvX_sse3(const int16_t *filter, int filterSize,
         return yuv2yuvX_MMXEXT(filter, filterSize, src, dest, dstW, dither, offset);
     }
     if (offset) {
-        __asm__ volatile("movq       (%0), %%xmm3\n\t"
+        __asm__ volatile("movq       %%nacl:(%%r15, %q0), %%xmm3\n\t"
                          "movdqa    %%xmm3, %%xmm4\n\t"
                          "psrlq       $24, %%xmm3\n\t"
                          "psllq       $40, %%xmm4\n\t"
@@ -217,7 +217,7 @@ static void yuv2yuvX_sse3(const int16_t *filter, int filterSize,
                          :: "r"(dither)
                          );
     } else {
-        __asm__ volatile("movq       (%0), %%xmm3\n\t"
+        __asm__ volatile("movq       %%nacl:(%%r15, %q0), %%xmm3\n\t"
                          :: "r"(dither)
                          );
     }
@@ -225,7 +225,7 @@ static void yuv2yuvX_sse3(const int16_t *filter, int filterSize,
     __asm__ volatile(
         "pxor      %%xmm0, %%xmm0\n\t"
         "punpcklbw %%xmm0, %%xmm3\n\t"
-        "movd          %0, %%xmm1\n\t"
+        "movd          %q0, %%xmm1\n\t"
         "punpcklwd %%xmm1, %%xmm1\n\t"
         "punpckldq %%xmm1, %%xmm1\n\t"
         "punpcklqdq %%xmm1, %%xmm1\n\t"
@@ -237,16 +237,16 @@ static void yuv2yuvX_sse3(const int16_t *filter, int filterSize,
     __asm__ volatile(
         "movdqa    %%xmm3, %%xmm4\n\t"
         "movdqa    %%xmm3, %%xmm7\n\t"
-        "movl %3, %%ecx\n\t"
-        "mov                                 %0, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "movl %q3, %%ecx\n\t"
+        "mov                                 %q0, %%"REG_d"  \n\t"\
+        "mov                        %%nacl:(%%r15, %%"REG_d"), %%"REG_S"  \n\t"\
         ".p2align                             4             \n\t" /* FIXME Unroll? */\
         "1:                                                 \n\t"\
-        "movddup                  8(%%"REG_d"), %%xmm0      \n\t" /* filterCoeff */\
-        "movdqa              (%%"REG_S", %%"REG_c", 2), %%xmm2      \n\t" /* srcData */\
-        "movdqa            16(%%"REG_S", %%"REG_c", 2), %%xmm5      \n\t" /* srcData */\
+        "movddup                  %%nacl:8(%%r15, %%"REG_d"), %%xmm0      \n\t" /* filterCoeff */\
+        "naclmovdqa1              \"(%%"REG_S", %%"REG_c", 2)\", %%xmm2      \n\t" /* srcData */\
+        "naclmovdqa1             \"16(%%"REG_S", %%"REG_c", 2)\", %%xmm5      \n\t" /* srcData */\
         "add                                $16, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "mov                        %%nacl:(%%r15, %%"REG_d"), %%"REG_S"  \n\t"\
         "test                         %%"REG_S", %%"REG_S"  \n\t"\
         "pmulhw                           %%xmm0, %%xmm2      \n\t"\
         "pmulhw                           %%xmm0, %%xmm5      \n\t"\
@@ -256,17 +256,17 @@ static void yuv2yuvX_sse3(const int16_t *filter, int filterSize,
         "psraw                               $3, %%xmm3      \n\t"\
         "psraw                               $3, %%xmm4      \n\t"\
         "packuswb                         %%xmm4, %%xmm3      \n\t"
-        "movntdq                          %%xmm3, (%1, %%"REG_c")\n\t"
+        "naclmovntdq2                          %%xmm3, \"(%q1, %%"REG_c")\"\n\t"
         "add                         $16, %%"REG_c"         \n\t"\
-        "cmp                          %2, %%"REG_c"         \n\t"\
+        "cmp                          %q2, %%"REG_c"         \n\t"\
         "movdqa    %%xmm7, %%xmm3\n\t"
         "movdqa    %%xmm7, %%xmm4\n\t"
-        "mov                                 %0, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "mov                                 %q0, %%"REG_d"  \n\t"\
+        "mov                        %%nacl:(%%r15, %%"REG_d"), %%"REG_S"  \n\t"\
         "jb                                  1b             \n\t"\
         :: "g" (filter),
            "r" (dest-offset), "g" ((x86_reg)(dstW+offset)), "m" (offset)
-        : "%"REG_d, "%"REG_S, "%"REG_c
+        : "%"REG_d, "%"REG_S, "%"REG_c, "%r14"
     );
 }
 #endif
diff --git a/libswscale/x86/swscale_template.c b/libswscale/x86/swscale_template.c
index c7a1bb4..30b0374 100644
--- a/libswscale/x86/swscale_template.c
+++ b/libswscale/x86/swscale_template.c
@@ -22,6 +22,8 @@
 #undef MOVNTQ
 #undef MOVNTQ2
 #undef PREFETCH
+#undef NACL_MOVNTQ2
+#undef NACLMOVNTQ2
 
 #if COMPILE_TEMPLATE_MMXEXT
 #define PREFETCH "prefetchnta"
@@ -32,19 +34,24 @@
 #if COMPILE_TEMPLATE_MMXEXT
 #define REAL_MOVNTQ(a,b) "movntq " #a ", " #b " \n\t"
 #define MOVNTQ2 "movntq "
+#define NACLMOVNTQ2 "naclmovntq2 "
+#define NACL_MOVNTQ2(a,b) "naclmovntq2 " #a ", \"" #b "\" \n\t"
 #else
 #define REAL_MOVNTQ(a,b) "movq " #a ", " #b " \n\t"
+#define NACL_MOVNTQ2(a,b) "naclmovq2 " #a ", \"" #b "\" \n\t"
 #define MOVNTQ2 "movq "
+#define NACLMOVNTQ2 "naclmovq2 "
 #endif
 #define MOVNTQ(a,b)  REAL_MOVNTQ(a,b)
 
+
 #if !COMPILE_TEMPLATE_MMXEXT
 static av_always_inline void
 dither_8to16(const uint8_t *srcDither, int rot)
 {
     if (rot) {
         __asm__ volatile("pxor      %%mm0, %%mm0\n\t"
-                         "movq       (%0), %%mm3\n\t"
+                         "movq       %%nacl:(%%r15, %q0), %%mm3\n\t"
                          "movq      %%mm3, %%mm4\n\t"
                          "psrlq       $24, %%mm3\n\t"
                          "psllq       $40, %%mm4\n\t"
@@ -56,7 +63,7 @@ dither_8to16(const uint8_t *srcDither, int rot)
                          );
     } else {
         __asm__ volatile("pxor      %%mm0, %%mm0\n\t"
-                         "movq       (%0), %%mm3\n\t"
+                         "movq       %%nacl:(%%r15, %q0), %%mm3\n\t"
                          "movq      %%mm3, %%mm4\n\t"
                          "punpcklbw %%mm0, %%mm3\n\t"
                          "punpckhbw %%mm0, %%mm4\n\t"
@@ -73,7 +80,7 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
     dither_8to16(dither, offset);
     filterSize--;
     __asm__ volatile(
-        "movd %0, %%mm1\n\t"
+        "movd %q0, %%mm1\n\t"
         "punpcklwd %%mm1, %%mm1\n\t"
         "punpckldq %%mm1, %%mm1\n\t"
         "psllw        $3, %%mm1\n\t"
@@ -87,16 +94,16 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
     __asm__ volatile(\
         "movq    %%mm3, %%mm6\n\t"
         "movq    %%mm4, %%mm7\n\t"
-        "movl %3, %%ecx\n\t"
-        "mov                                 %0, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "movl %q3, %%ecx\n\t"
+        "mov                                 %q0, %%"REG_d"  \n\t"\
+        "mov                        %%nacl:(%%r15,%%"REG_d"), %%"REG_S"  \n\t"\
         ".p2align                             4             \n\t" /* FIXME Unroll? */\
         "1:                                                 \n\t"\
-        "movq                      8(%%"REG_d"), %%mm0      \n\t" /* filterCoeff */\
-        "movq                (%%"REG_S", %%"REG_c", 2), %%mm2      \n\t" /* srcData */\
-        "movq               8(%%"REG_S", %%"REG_c", 2), %%mm5      \n\t" /* srcData */\
+        "movq                      %%nacl:8(%%r15,%%"REG_d"), %%mm0      \n\t" /* filterCoeff */\
+        "naclmovq1                \"(%%"REG_S", %%"REG_c", 2)\", %%mm2      \n\t" /* srcData */\
+        "naclmovq1               \"8(%%"REG_S", %%"REG_c", 2)\", %%mm5      \n\t" /* srcData */\
         "add                                $16, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "mov                        %%nacl:(%%r15,%%"REG_d"), %%"REG_S"  \n\t"\
         "test                         %%"REG_S", %%"REG_S"  \n\t"\
         "pmulhw                           %%mm0, %%mm2      \n\t"\
         "pmulhw                           %%mm0, %%mm5      \n\t"\
@@ -106,17 +113,17 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         "psraw                               $3, %%mm3      \n\t"\
         "psraw                               $3, %%mm4      \n\t"\
         "packuswb                         %%mm4, %%mm3      \n\t"
-        MOVNTQ2 "                         %%mm3, (%1, %%"REG_c")\n\t"
+        NACLMOVNTQ2   "%%mm3,   \"(%q1, %%"REG_c")\"           \n\t"\
         "add                          $8, %%"REG_c"         \n\t"\
-        "cmp                          %2, %%"REG_c"         \n\t"\
+        "cmp                          %q2, %%"REG_c"         \n\t"\
         "movq    %%mm6, %%mm3\n\t"
         "movq    %%mm7, %%mm4\n\t"
-        "mov                                 %0, %%"REG_d"  \n\t"\
-        "mov                        (%%"REG_d"), %%"REG_S"  \n\t"\
+        "mov                                 %q0, %%"REG_d"  \n\t"\
+        "mov                        %%nacl:(%%r15, %%"REG_d"), %%"REG_S"  \n\t"\
         "jb                                  1b             \n\t"\
         :: "g" (filter),
            "r" (dest-offset), "g" ((x86_reg)(dstW+offset)), "m" (offset)
-        : "%"REG_d, "%"REG_S, "%"REG_c
+        : "%"REG_d, "%"REG_S, "%"REG_c, "%r14"
     );
 }
 
@@ -126,18 +133,18 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         ".p2align                      4                \n\t"\
         "nop                                            \n\t"\
         "1:                                             \n\t"\
-        "lea "CHR_MMX_FILTER_OFFSET"(%0), %%"REG_d"     \n\t"\
-        "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
-        "movq      "VROUNDER_OFFSET"(%0), %%mm3         \n\t"\
+        "lea "CHR_MMX_FILTER_OFFSET"(%q0), %%"REG_d"     \n\t"\
+        "mov                 %%nacl:(%%r15,%%"REG_d"), %%"REG_S"     \n\t"\
+        "movq      %%nacl:"VROUNDER_OFFSET"(%%r15,%q0), %%mm3         \n\t"\
         "movq                      %%mm3, %%mm4         \n\t"\
         ".p2align                      4                \n\t"\
         "2:                                             \n\t"\
-        "movq               8(%%"REG_d"), %%mm0         \n\t" /* filterCoeff */\
-        "movq     (%%"REG_S", %%"REG_a"), %%mm2         \n\t" /* UsrcData */\
-        "add                          %6, %%"REG_S"     \n\t" \
-        "movq     (%%"REG_S", %%"REG_a"), %%mm5         \n\t" /* VsrcData */\
+        "movq               %%nacl:8(%%r15,%%"REG_d"), %%mm0         \n\t" /* filterCoeff */\
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm2         \n\t" /* UsrcData */\
+        "add                          %q6, %%"REG_S"     \n\t" \
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm5         \n\t" /* VsrcData */\
         "add                         $16, %%"REG_d"     \n\t"\
-        "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
+        "mov                 %%nacl:(%%r15,%%"REG_d"), %%"REG_S"     \n\t"\
         "pmulhw                    %%mm0, %%mm2         \n\t"\
         "pmulhw                    %%mm0, %%mm5         \n\t"\
         "paddw                     %%mm2, %%mm3         \n\t"\
@@ -146,17 +153,17 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         " jnz                         2b                \n\t"\
 
 #define YSCALEYUV2PACKEDX_YA(offset,coeff,src1,src2,dst1,dst2) \
-    "lea                "offset"(%0), %%"REG_d"     \n\t"\
-    "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
-    "movq      "VROUNDER_OFFSET"(%0), "#dst1"       \n\t"\
+    "lea                "offset"(%q0), %%"REG_d"     \n\t"\
+    "mov                 %%nacl:(%%r15,%%"REG_d"), %%"REG_S"     \n\t"\
+    "movq      %%nacl:"VROUNDER_OFFSET"(%%r15, %q0), "#dst1"       \n\t"\
     "movq                    "#dst1", "#dst2"       \n\t"\
     ".p2align                      4                \n\t"\
     "2:                                             \n\t"\
-    "movq               8(%%"REG_d"), "#coeff"      \n\t" /* filterCoeff */\
-    "movq  (%%"REG_S", %%"REG_a", 2), "#src1"       \n\t" /* Y1srcData */\
-    "movq 8(%%"REG_S", %%"REG_a", 2), "#src2"       \n\t" /* Y2srcData */\
+    "movq               %%nacl:8(%%r15, %%"REG_d"), "#coeff"      \n\t" /* filterCoeff */\
+    "naclmovq1  \"(%%"REG_S", %%"REG_a", 2)\", "#src1"       \n\t" /* Y1srcData */\
+    "naclmovq1 \"8(%%"REG_S", %%"REG_a", 2)\", "#src2"       \n\t" /* Y2srcData */\
     "add                         $16, %%"REG_d"            \n\t"\
-    "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
+    "mov                 %%nacl:(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
     "pmulhw                 "#coeff", "#src1"       \n\t"\
     "pmulhw                 "#coeff", "#src2"       \n\t"\
     "paddw                   "#src1", "#dst1"       \n\t"\
@@ -172,7 +179,7 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         :: "r" (&c->redDither),                   \
             "m" (dummy), "m" (dummy), "m" (dummy),\
             "r" (dest), "m" (dstW_reg), "m"(uv_off) \
-        : "%"REG_a, "%"REG_d, "%"REG_S            \
+        : "%"REG_a, "%"REG_d, "%"REG_S, "%r14"           \
     );
 
 #define YSCALEYUV2PACKEDX_ACCURATE_UV \
@@ -181,30 +188,30 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         ".p2align                      4                \n\t"\
         "nop                                            \n\t"\
         "1:                                             \n\t"\
-        "lea "CHR_MMX_FILTER_OFFSET"(%0), %%"REG_d"     \n\t"\
-        "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
+        "lea "CHR_MMX_FILTER_OFFSET"(%q0), %%"REG_d"     \n\t"\
+        "mov                 %%nacl:(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
         "pxor                      %%mm4, %%mm4         \n\t"\
         "pxor                      %%mm5, %%mm5         \n\t"\
         "pxor                      %%mm6, %%mm6         \n\t"\
         "pxor                      %%mm7, %%mm7         \n\t"\
         ".p2align                      4                \n\t"\
         "2:                                             \n\t"\
-        "movq     (%%"REG_S", %%"REG_a"), %%mm0         \n\t" /* UsrcData */\
-        "add                          %6, %%"REG_S"      \n\t" \
-        "movq     (%%"REG_S", %%"REG_a"), %%mm2         \n\t" /* VsrcData */\
-        "mov "STR(APCK_PTR2)"(%%"REG_d"), %%"REG_S"     \n\t"\
-        "movq     (%%"REG_S", %%"REG_a"), %%mm1         \n\t" /* UsrcData */\
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm0         \n\t" /* UsrcData */\
+        "add                          %q6, %%"REG_S"      \n\t" \
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm2         \n\t" /* VsrcData */\
+        "mov %%nacl:"STR(APCK_PTR2)"(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm1         \n\t" /* UsrcData */\
         "movq                      %%mm0, %%mm3         \n\t"\
         "punpcklwd                 %%mm1, %%mm0         \n\t"\
         "punpckhwd                 %%mm1, %%mm3         \n\t"\
-        "movq "STR(APCK_COEF)"(%%"REG_d"),%%mm1         \n\t" /* filterCoeff */\
+        "naclmovq1 \""STR(APCK_COEF)"(%%"REG_d")\",%%mm1         \n\t" /* filterCoeff */\
         "pmaddwd                   %%mm1, %%mm0         \n\t"\
         "pmaddwd                   %%mm1, %%mm3         \n\t"\
         "paddd                     %%mm0, %%mm4         \n\t"\
         "paddd                     %%mm3, %%mm5         \n\t"\
-        "add                          %6, %%"REG_S"      \n\t" \
-        "movq     (%%"REG_S", %%"REG_a"), %%mm3         \n\t" /* VsrcData */\
-        "mov "STR(APCK_SIZE)"(%%"REG_d"), %%"REG_S"     \n\t"\
+        "add                          %q6, %%"REG_S"      \n\t" \
+        "naclmovq1     \"(%%"REG_S", %%"REG_a")\", %%mm3         \n\t" /* VsrcData */\
+        "mov %%nacl:"STR(APCK_SIZE)"(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
         "add           $"STR(APCK_SIZE)", %%"REG_d"     \n\t"\
         "test                  %%"REG_S", %%"REG_S"     \n\t"\
         "movq                      %%mm2, %%mm0         \n\t"\
@@ -219,37 +226,37 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
         "psrad                       $16, %%mm5         \n\t"\
         "psrad                       $16, %%mm6         \n\t"\
         "psrad                       $16, %%mm7         \n\t"\
-        "movq      "VROUNDER_OFFSET"(%0), %%mm0         \n\t"\
+        "movq      %%nacl:"VROUNDER_OFFSET"(%%r15, %q0), %%mm0         \n\t"\
         "packssdw                  %%mm5, %%mm4         \n\t"\
         "packssdw                  %%mm7, %%mm6         \n\t"\
         "paddw                     %%mm0, %%mm4         \n\t"\
         "paddw                     %%mm0, %%mm6         \n\t"\
-        "movq                      %%mm4, "U_TEMP"(%0)  \n\t"\
-        "movq                      %%mm6, "V_TEMP"(%0)  \n\t"\
+        "movq                      %%mm4, %%nacl:"U_TEMP"(%%r15, %q0)  \n\t"\
+        "movq                      %%mm6, %%nacl:"V_TEMP"(%%r15, %q0)  \n\t"\
 
 #define YSCALEYUV2PACKEDX_ACCURATE_YA(offset) \
-    "lea                "offset"(%0), %%"REG_d"     \n\t"\
-    "mov                 (%%"REG_d"), %%"REG_S"     \n\t"\
+    "lea                "offset"(%q0), %%"REG_d"     \n\t"\
+    "mov                 %%nacl:(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
     "pxor                      %%mm1, %%mm1         \n\t"\
     "pxor                      %%mm5, %%mm5         \n\t"\
     "pxor                      %%mm7, %%mm7         \n\t"\
     "pxor                      %%mm6, %%mm6         \n\t"\
     ".p2align                      4                \n\t"\
     "2:                                             \n\t"\
-    "movq  (%%"REG_S", %%"REG_a", 2), %%mm0         \n\t" /* Y1srcData */\
-    "movq 8(%%"REG_S", %%"REG_a", 2), %%mm2         \n\t" /* Y2srcData */\
-    "mov "STR(APCK_PTR2)"(%%"REG_d"), %%"REG_S"     \n\t"\
-    "movq  (%%"REG_S", %%"REG_a", 2), %%mm4         \n\t" /* Y1srcData */\
+    "naclmovq1  \"(%%"REG_S", %%"REG_a", 2)\", %%mm0         \n\t" /* Y1srcData */\
+    "naclmovq1 \"8(%%"REG_S", %%"REG_a", 2)\", %%mm2         \n\t" /* Y2srcData */\
+    "mov %%nacl:"STR(APCK_PTR2)"(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
+    "naclmovq1  \"(%%"REG_S", %%"REG_a", 2)\", %%mm4         \n\t" /* Y1srcData */\
     "movq                      %%mm0, %%mm3         \n\t"\
     "punpcklwd                 %%mm4, %%mm0         \n\t"\
     "punpckhwd                 %%mm4, %%mm3         \n\t"\
-    "movq "STR(APCK_COEF)"(%%"REG_d"), %%mm4         \n\t" /* filterCoeff */\
+    "naclmovq1 \""STR(APCK_COEF)"(%%"REG_d")\", %%mm4         \n\t" /* filterCoeff */\
     "pmaddwd                   %%mm4, %%mm0         \n\t"\
     "pmaddwd                   %%mm4, %%mm3         \n\t"\
     "paddd                     %%mm0, %%mm1         \n\t"\
     "paddd                     %%mm3, %%mm5         \n\t"\
-    "movq 8(%%"REG_S", %%"REG_a", 2), %%mm3         \n\t" /* Y2srcData */\
-    "mov "STR(APCK_SIZE)"(%%"REG_d"), %%"REG_S"     \n\t"\
+    "naclmovq1 \"8(%%"REG_S", %%"REG_a", 2)\", %%mm3         \n\t" /* Y2srcData */\
+    "mov %%nacl:"STR(APCK_SIZE)"(%%r15, %%"REG_d"), %%"REG_S"     \n\t"\
     "add           $"STR(APCK_SIZE)", %%"REG_d"     \n\t"\
     "test                  %%"REG_S", %%"REG_S"     \n\t"\
     "movq                      %%mm2, %%mm0         \n\t"\
@@ -264,32 +271,32 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
     "psrad                       $16, %%mm5         \n\t"\
     "psrad                       $16, %%mm7         \n\t"\
     "psrad                       $16, %%mm6         \n\t"\
-    "movq      "VROUNDER_OFFSET"(%0), %%mm0         \n\t"\
+    "movq      %%nacl:"VROUNDER_OFFSET"(%%r15, %q0), %%mm0         \n\t"\
     "packssdw                  %%mm5, %%mm1         \n\t"\
     "packssdw                  %%mm6, %%mm7         \n\t"\
     "paddw                     %%mm0, %%mm1         \n\t"\
     "paddw                     %%mm0, %%mm7         \n\t"\
-    "movq               "U_TEMP"(%0), %%mm3         \n\t"\
-    "movq               "V_TEMP"(%0), %%mm4         \n\t"\
+    "movq               %%nacl:"U_TEMP"(%%r15, %q0), %%mm3         \n\t"\
+    "movq               %%nacl:"V_TEMP"(%%r15, %q0), %%mm4         \n\t"\
 
 #define YSCALEYUV2PACKEDX_ACCURATE \
     YSCALEYUV2PACKEDX_ACCURATE_UV \
     YSCALEYUV2PACKEDX_ACCURATE_YA(LUM_MMX_FILTER_OFFSET)
 
 #define YSCALEYUV2RGBX \
-    "psubw  "U_OFFSET"(%0), %%mm3       \n\t" /* (U-128)8*/\
-    "psubw  "V_OFFSET"(%0), %%mm4       \n\t" /* (V-128)8*/\
+    "psubw  %%nacl:"U_OFFSET"(%%r15, %q0), %%mm3       \n\t" /* (%%r15, U-128)8*/\
+    "psubw  %%nacl:"V_OFFSET"(%%r15, %q0), %%mm4       \n\t" /* (%%r15, V-128)8*/\
     "movq            %%mm3, %%mm2       \n\t" /* (U-128)8*/\
     "movq            %%mm4, %%mm5       \n\t" /* (V-128)8*/\
-    "pmulhw "UG_COEFF"(%0), %%mm3       \n\t"\
-    "pmulhw "VG_COEFF"(%0), %%mm4       \n\t"\
+    "pmulhw %%nacl:"UG_COEFF"(%%r15, %q0), %%mm3       \n\t"\
+    "pmulhw %%nacl:"VG_COEFF"(%%r15, %q0), %%mm4       \n\t"\
     /* mm2=(U-128)8, mm3=ug, mm4=vg mm5=(V-128)8 */\
-    "pmulhw "UB_COEFF"(%0), %%mm2       \n\t"\
-    "pmulhw "VR_COEFF"(%0), %%mm5       \n\t"\
-    "psubw  "Y_OFFSET"(%0), %%mm1       \n\t" /* 8(Y-16)*/\
-    "psubw  "Y_OFFSET"(%0), %%mm7       \n\t" /* 8(Y-16)*/\
-    "pmulhw  "Y_COEFF"(%0), %%mm1       \n\t"\
-    "pmulhw  "Y_COEFF"(%0), %%mm7       \n\t"\
+    "pmulhw %%nacl:"UB_COEFF"(%%r15, %q0), %%mm2       \n\t"\
+    "pmulhw %%nacl:"VR_COEFF"(%%r15, %q0), %%mm5       \n\t"\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, %q0), %%mm1       \n\t" /* 8(%%r15, Y-16)*/\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, %q0), %%mm7       \n\t" /* 8(%%r15, Y-16)*/\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, %q0), %%mm1       \n\t"\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, %q0), %%mm7       \n\t"\
     /* mm1= Y1, mm2=ub, mm3=ug, mm4=vg mm5=vr, mm7=Y2 */\
     "paddw           %%mm3, %%mm4       \n\t"\
     "movq            %%mm2, %%mm0       \n\t"\
@@ -326,10 +333,10 @@ static void RENAME(yuv2yuvX)(const int16_t *filter, int filterSize,
     "punpcklwd  "#t", "#q2"     \n\t" /* ARGBARGB 2 */\
     "punpckhwd  "#t", "#q3"     \n\t" /* ARGBARGB 3 */\
 \
-    MOVNTQ(   q0,   (dst, index, 4))\
-    MOVNTQ(    b,  8(dst, index, 4))\
-    MOVNTQ(   q2, 16(dst, index, 4))\
-    MOVNTQ(   q3, 24(dst, index, 4))\
+    NACL_MOVNTQ2(   q0,   (dst, index, 4))\
+    NACL_MOVNTQ2(    b,  8(dst, index, 4))\
+    NACL_MOVNTQ2(   q2, 16(dst, index, 4))\
+    NACL_MOVNTQ2(   q3, 24(dst, index, 4))\
 \
     "add      $8, "#index"      \n\t"\
     "cmp "#dstw", "#index"      \n\t"\
@@ -350,21 +357,21 @@ static void RENAME(yuv2rgb32_X_ar)(SwsContext *c, const int16_t *lumFilter,
     if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {
         YSCALEYUV2PACKEDX_ACCURATE
         YSCALEYUV2RGBX
-        "movq                      %%mm2, "U_TEMP"(%0)  \n\t"
-        "movq                      %%mm4, "V_TEMP"(%0)  \n\t"
-        "movq                      %%mm5, "Y_TEMP"(%0)  \n\t"
+        "movq                      %%mm2, %%nacl:"U_TEMP"(%%r15, %q0)  \n\t"
+        "movq                      %%mm4, %%nacl:"V_TEMP"(%%r15, %q0)  \n\t"
+        "movq                      %%mm5, %%nacl:"Y_TEMP"(%%r15, %q0)  \n\t"
         YSCALEYUV2PACKEDX_ACCURATE_YA(ALP_MMX_FILTER_OFFSET)
-        "movq               "Y_TEMP"(%0), %%mm5         \n\t"
+        "movq               %%nacl:"Y_TEMP"(%%r15, %q0), %%mm5         \n\t"
         "psraw                        $3, %%mm1         \n\t"
         "psraw                        $3, %%mm7         \n\t"
         "packuswb                  %%mm7, %%mm1         \n\t"
-        WRITEBGR32(%4, %5, %%REGa, %%mm3, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm2, %%mm6)
+        WRITEBGR32(%q4, %q5, %%REGa, %%mm3, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm2, %%mm6)
         YSCALEYUV2PACKEDX_END
     } else {
         YSCALEYUV2PACKEDX_ACCURATE
         YSCALEYUV2RGBX
         "pcmpeqd %%mm7, %%mm7 \n\t"
-        WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+        WRITEBGR32(%q4, %q5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
         YSCALEYUV2PACKEDX_END
     }
 }
@@ -387,13 +394,13 @@ static void RENAME(yuv2rgb32_X)(SwsContext *c, const int16_t *lumFilter,
         "psraw                        $3, %%mm1         \n\t"
         "psraw                        $3, %%mm7         \n\t"
         "packuswb                  %%mm7, %%mm1         \n\t"
-        WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
+        WRITEBGR32(%q4, %q5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
         YSCALEYUV2PACKEDX_END
     } else {
         YSCALEYUV2PACKEDX
         YSCALEYUV2RGBX
         "pcmpeqd %%mm7, %%mm7 \n\t"
-        WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+        WRITEBGR32(%q4, %q5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
         YSCALEYUV2PACKEDX_END
     }
 }
@@ -418,8 +425,8 @@ static void RENAME(yuv2rgb32_X)(SwsContext *c, const int16_t *lumFilter,
     "por          %%mm3, %%mm2  \n\t"\
     "por          %%mm4, %%mm1  \n\t"\
 \
-    MOVNTQ(%%mm2,  (dst, index, 2))\
-    MOVNTQ(%%mm1, 8(dst, index, 2))\
+    NACL_MOVNTQ2(%%mm2,  (dst, index, 2))\
+    NACL_MOVNTQ2(%%mm1, 8(dst, index, 2))\
 \
     "add             $8, "#index"   \n\t"\
     "cmp        "#dstw", "#index"   \n\t"\
@@ -442,11 +449,11 @@ static void RENAME(yuv2rgb565_X_ar)(SwsContext *c, const int16_t *lumFilter,
     "pxor %%mm7, %%mm7 \n\t"
     /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-    "paddusb "BLUE_DITHER"(%0), %%mm2\n\t"
-    "paddusb "GREEN_DITHER"(%0), %%mm4\n\t"
-    "paddusb "RED_DITHER"(%0), %%mm5\n\t"
+    "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q0), %%mm2\n\t"
+    "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q0), %%mm4\n\t"
+    "paddusb %%nacl:"RED_DITHER"(%%r15, %q0), %%mm5\n\t"
 #endif
-    WRITERGB16(%4, %5, %%REGa)
+    WRITERGB16(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -466,11 +473,11 @@ static void RENAME(yuv2rgb565_X)(SwsContext *c, const int16_t *lumFilter,
     "pxor %%mm7, %%mm7 \n\t"
     /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-    "paddusb "BLUE_DITHER"(%0), %%mm2  \n\t"
-    "paddusb "GREEN_DITHER"(%0), %%mm4  \n\t"
-    "paddusb "RED_DITHER"(%0), %%mm5  \n\t"
+    "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q0), %%mm2  \n\t"
+    "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q0), %%mm4  \n\t"
+    "paddusb %%nacl:"RED_DITHER"(%%r15, %q0), %%mm5  \n\t"
 #endif
-    WRITERGB16(%4, %5, %%REGa)
+    WRITERGB16(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -495,8 +502,8 @@ static void RENAME(yuv2rgb565_X)(SwsContext *c, const int16_t *lumFilter,
     "por          %%mm3, %%mm2  \n\t"\
     "por          %%mm4, %%mm1  \n\t"\
 \
-    MOVNTQ(%%mm2,  (dst, index, 2))\
-    MOVNTQ(%%mm1, 8(dst, index, 2))\
+    NACL_MOVNTQ2(%%mm2, (dst, index, 2))\
+    NACL_MOVNTQ2(%%mm1, 8(dst, index, 2))\
 \
     "add             $8, "#index"   \n\t"\
     "cmp        "#dstw", "#index"   \n\t"\
@@ -519,11 +526,11 @@ static void RENAME(yuv2rgb555_X_ar)(SwsContext *c, const int16_t *lumFilter,
     "pxor %%mm7, %%mm7 \n\t"
     /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-    "paddusb "BLUE_DITHER"(%0), %%mm2\n\t"
-    "paddusb "GREEN_DITHER"(%0), %%mm4\n\t"
-    "paddusb "RED_DITHER"(%0), %%mm5\n\t"
+    "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q0), %%mm2\n\t"
+    "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q0), %%mm4\n\t"
+    "paddusb %%nacl:"RED_DITHER"(%%r15, %q0), %%mm5\n\t"
 #endif
-    WRITERGB15(%4, %5, %%REGa)
+    WRITERGB15(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -543,11 +550,11 @@ static void RENAME(yuv2rgb555_X)(SwsContext *c, const int16_t *lumFilter,
     "pxor %%mm7, %%mm7 \n\t"
     /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-    "paddusb "BLUE_DITHER"(%0), %%mm2  \n\t"
-    "paddusb "GREEN_DITHER"(%0), %%mm4  \n\t"
-    "paddusb "RED_DITHER"(%0), %%mm5  \n\t"
+    "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q0), %%mm2  \n\t"
+    "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q0), %%mm4  \n\t"
+    "paddusb %%nacl:"RED_DITHER"(%%r15, %q0), %%mm5  \n\t"
 #endif
-    WRITERGB15(%4, %5, %%REGa)
+    WRITERGB15(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -585,18 +592,18 @@ static void RENAME(yuv2rgb555_X)(SwsContext *c, const int16_t *lumFilter,
     "movq      %%mm2, %%mm6     \n\t" /* 0RGBRGB0 1 */\
     "psllq       $40, %%mm2     \n\t" /* GB000000 1 */\
     "por       %%mm2, %%mm0     \n\t" /* GBRGBRGB 0 */\
-    MOVNTQ(%%mm0, (dst))\
+    MOVNTQ(%%mm0, %%nacl:(%%r15, dst))\
 \
     "psrlq       $24, %%mm6     \n\t" /* 0000RGBR 1 */\
     "movq      %%mm1, %%mm5     \n\t" /* 0RGBRGB0 2 */\
     "psllq       $24, %%mm1     \n\t" /* BRGB0000 2 */\
     "por       %%mm1, %%mm6     \n\t" /* BRGBRGBR 1 */\
-    MOVNTQ(%%mm6, 8(dst))\
+    MOVNTQ(%%mm6, %%nacl:8(%%r15, dst))\
 \
     "psrlq       $40, %%mm5     \n\t" /* 000000RG 2 */\
     "psllq        $8, %%mm3     \n\t" /* RGBRGB00 3 */\
     "por       %%mm3, %%mm5     \n\t" /* RGBRGBRG 2 */\
-    MOVNTQ(%%mm5, 16(dst))\
+    MOVNTQ(%%mm5, %%nacl:16(%%r15, dst))\
 \
     "add         $24, "#dst"    \n\t"\
 \
@@ -619,7 +626,7 @@ static void RENAME(yuv2rgb555_X)(SwsContext *c, const int16_t *lumFilter,
     "psllq     $8, %%mm3        \n\t" /* G2        G1       G0    */\
     "por    %%mm1, %%mm6        \n\t"\
     "por    %%mm3, %%mm6        \n\t"\
-    MOVNTQ(%%mm6, (dst))\
+    MOVNTQ(%%mm6, %%nacl:(%%r15, dst))\
 \
     "psrlq     $8, %%mm4        \n\t" /* 00 G7 G6 G5  G4 G3 G2 G1 */\
     "pshufw $0xA5, %%mm2, %%mm1 \n\t" /* B5 B4 B5 B4  B3 B2 B3 B2 */\
@@ -632,7 +639,7 @@ static void RENAME(yuv2rgb555_X)(SwsContext *c, const int16_t *lumFilter,
 \
     "por    %%mm1, %%mm3        \n\t" /* B5    G4 B4     G3 B3    */\
     "por    %%mm3, %%mm6        \n\t"\
-    MOVNTQ(%%mm6, 8(dst))\
+    MOVNTQ(%%mm6, %%nacl:8(%%r15, dst))\
 \
     "pshufw $0xFF, %%mm2, %%mm1 \n\t" /* B7 B6 B7 B6  B7 B6 B6 B7 */\
     "pshufw $0xFA, %%mm4, %%mm3 \n\t" /* 00 G7 00 G7  G6 G5 G6 G5 */\
@@ -644,7 +651,7 @@ static void RENAME(yuv2rgb555_X)(SwsContext *c, const int16_t *lumFilter,
 \
     "por    %%mm1, %%mm3        \n\t"\
     "por    %%mm3, %%mm6        \n\t"\
-    MOVNTQ(%%mm6, 16(dst))\
+    MOVNTQ(%%mm6, %%nacl:16(%%r15, dst))\
 \
     "add      $24, "#dst"       \n\t"\
 \
@@ -675,8 +682,8 @@ static void RENAME(yuv2bgr24_X_ar)(SwsContext *c, const int16_t *lumFilter,
     YSCALEYUV2RGBX
     "pxor %%mm7, %%mm7 \n\t"
     "lea (%%"REG_a", %%"REG_a", 2), %%"REG_c"\n\t" //FIXME optimize
-    "add %4, %%"REG_c"                        \n\t"
-    WRITEBGR24(%%REGc, %5, %%REGa)
+    "add %q4, %%"REG_c"                        \n\t"
+    WRITEBGR24(%%REGc, %q5, %%REGa)
     :: "r" (&c->redDither),
        "m" (dummy), "m" (dummy), "m" (dummy),
        "r" (dest), "m" (dstW_reg), "m"(uv_off)
@@ -699,8 +706,8 @@ static void RENAME(yuv2bgr24_X)(SwsContext *c, const int16_t *lumFilter,
     YSCALEYUV2RGBX
     "pxor                    %%mm7, %%mm7       \n\t"
     "lea (%%"REG_a", %%"REG_a", 2), %%"REG_c"   \n\t" //FIXME optimize
-    "add                        %4, %%"REG_c"   \n\t"
-    WRITEBGR24(%%REGc, %5, %%REGa)
+    "add                        %q4, %%"REG_c"   \n\t"
+    WRITEBGR24(%%REGc, %q5, %%REGa)
     :: "r" (&c->redDither),
        "m" (dummy), "m" (dummy), "m" (dummy),
        "r" (dest),  "m" (dstW_reg), "m"(uv_off)
@@ -717,8 +724,8 @@ static void RENAME(yuv2bgr24_X)(SwsContext *c, const int16_t *lumFilter,
     "punpcklbw %%mm3, %%mm1     \n\t"\
     "punpckhbw %%mm3, %%mm7     \n\t"\
 \
-    MOVNTQ(%%mm1, (dst, index, 2))\
-    MOVNTQ(%%mm7, 8(dst, index, 2))\
+    NACL_MOVNTQ2(%%mm1, (dst, index, 2))\
+    NACL_MOVNTQ2(%%mm7, 8(dst, index, 2))\
 \
     "add          $8, "#index"  \n\t"\
     "cmp     "#dstw", "#index"  \n\t"\
@@ -742,7 +749,7 @@ static void RENAME(yuv2yuyv422_X_ar)(SwsContext *c, const int16_t *lumFilter,
     "psraw $3, %%mm4    \n\t"
     "psraw $3, %%mm1    \n\t"
     "psraw $3, %%mm7    \n\t"
-    WRITEYUY2(%4, %5, %%REGa)
+    WRITEYUY2(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -763,7 +770,7 @@ static void RENAME(yuv2yuyv422_X)(SwsContext *c, const int16_t *lumFilter,
     "psraw $3, %%mm4    \n\t"
     "psraw $3, %%mm1    \n\t"
     "psraw $3, %%mm7    \n\t"
-    WRITEYUY2(%4, %5, %%REGa)
+    WRITEYUY2(%q4, %q5, %%REGa)
     YSCALEYUV2PACKEDX_END
 }
 
@@ -771,50 +778,50 @@ static void RENAME(yuv2yuyv422_X)(SwsContext *c, const int16_t *lumFilter,
     "xor            "#index", "#index"  \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm2     \n\t" /* uvbuf0[eax]*/\
-    "movq     (%3, "#index"), %%mm3     \n\t" /* uvbuf1[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
-    "movq     (%3, "#index"), %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm2     \n\t" /* uvbuf0[eax]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm3     \n\t" /* uvbuf1[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "psubw             %%mm3, %%mm2     \n\t" /* uvbuf0[eax] - uvbuf1[eax]*/\
     "psubw             %%mm4, %%mm5     \n\t" /* uvbuf0[eax+2048] - uvbuf1[eax+2048]*/\
-    "movq "CHR_MMX_FILTER_OFFSET"+8("#c"), %%mm0    \n\t"\
+    "movq %%nacl:"CHR_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm0    \n\t"\
     "pmulhw            %%mm0, %%mm2     \n\t" /* (uvbuf0[eax] - uvbuf1[eax])uvalpha1>>16*/\
     "pmulhw            %%mm0, %%mm5     \n\t" /* (uvbuf0[eax+2048] - uvbuf1[eax+2048])uvalpha1>>16*/\
     "psraw                $4, %%mm3     \n\t" /* uvbuf0[eax] - uvbuf1[eax] >>4*/\
     "psraw                $4, %%mm4     \n\t" /* uvbuf0[eax+2048] - uvbuf1[eax+2048] >>4*/\
     "paddw             %%mm2, %%mm3     \n\t" /* uvbuf0[eax]uvalpha1 - uvbuf1[eax](1-uvalpha1)*/\
     "paddw             %%mm5, %%mm4     \n\t" /* uvbuf0[eax+2048]uvalpha1 - uvbuf1[eax+2048](1-uvalpha1)*/\
-    "psubw  "U_OFFSET"("#c"), %%mm3     \n\t" /* (U-128)8*/\
-    "psubw  "V_OFFSET"("#c"), %%mm4     \n\t" /* (V-128)8*/\
+    "psubw  %%nacl:"U_OFFSET"(%%r15, "#c"), %%mm3     \n\t" /* (%%r15, U-128)8*/\
+    "psubw  %%nacl:"V_OFFSET"(%%r15, "#c"), %%mm4     \n\t" /* (%%r15, V-128)8*/\
     "movq              %%mm3, %%mm2     \n\t" /* (U-128)8*/\
     "movq              %%mm4, %%mm5     \n\t" /* (V-128)8*/\
-    "pmulhw "UG_COEFF"("#c"), %%mm3     \n\t"\
-    "pmulhw "VG_COEFF"("#c"), %%mm4     \n\t"\
+    "pmulhw %%nacl:"UG_COEFF"(%%r15, "#c"), %%mm3     \n\t"\
+    "pmulhw %%nacl:"VG_COEFF"(%%r15, "#c"), %%mm4     \n\t"\
     /* mm2=(U-128)8, mm3=ug, mm4=vg mm5=(V-128)8 */\
 
 #define REAL_YSCALEYUV2RGB_YA(index, c, b1, b2) \
-    "movq  ("#b1", "#index", 2), %%mm0     \n\t" /*buf0[eax]*/\
-    "movq  ("#b2", "#index", 2), %%mm1     \n\t" /*buf1[eax]*/\
-    "movq 8("#b1", "#index", 2), %%mm6     \n\t" /*buf0[eax]*/\
-    "movq 8("#b2", "#index", 2), %%mm7     \n\t" /*buf1[eax]*/\
+    "naclmovq1  \"("#b1", "#index", 2)\", %%mm0     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"("#b2", "#index", 2)\", %%mm1     \n\t" /*buf1[eax]*/\
+    "naclmovq1 \"8("#b1", "#index", 2)\", %%mm6     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8("#b2", "#index", 2)\", %%mm7     \n\t" /*buf1[eax]*/\
     "psubw             %%mm1, %%mm0     \n\t" /* buf0[eax] - buf1[eax]*/\
     "psubw             %%mm7, %%mm6     \n\t" /* buf0[eax] - buf1[eax]*/\
-    "pmulhw "LUM_MMX_FILTER_OFFSET"+8("#c"), %%mm0  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
-    "pmulhw "LUM_MMX_FILTER_OFFSET"+8("#c"), %%mm6  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
+    "pmulhw %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm0  \n\t" /* (%%r15, buf0[eax] - buf1[eax])yalpha1>>16*/\
+    "pmulhw %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm6  \n\t" /* (%%r15, buf0[eax] - buf1[eax])yalpha1>>16*/\
     "psraw                $4, %%mm1     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "psraw                $4, %%mm7     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "paddw             %%mm0, %%mm1     \n\t" /* buf0[eax]yalpha1 + buf1[eax](1-yalpha1) >>16*/\
     "paddw             %%mm6, %%mm7     \n\t" /* buf0[eax]yalpha1 + buf1[eax](1-yalpha1) >>16*/\
 
 #define REAL_YSCALEYUV2RGB_COEFF(c) \
-    "pmulhw "UB_COEFF"("#c"), %%mm2     \n\t"\
-    "pmulhw "VR_COEFF"("#c"), %%mm5     \n\t"\
-    "psubw  "Y_OFFSET"("#c"), %%mm1     \n\t" /* 8(Y-16)*/\
-    "psubw  "Y_OFFSET"("#c"), %%mm7     \n\t" /* 8(Y-16)*/\
-    "pmulhw  "Y_COEFF"("#c"), %%mm1     \n\t"\
-    "pmulhw  "Y_COEFF"("#c"), %%mm7     \n\t"\
+    "pmulhw %%nacl:"UB_COEFF"(%%r15, "#c"), %%mm2     \n\t"\
+    "pmulhw %%nacl:"VR_COEFF"(%%r15, "#c"), %%mm5     \n\t"\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm1     \n\t" /* 8(%%r15, Y-16)*/\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm7     \n\t" /* 8(%%r15, Y-16)*/\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm1     \n\t"\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm7     \n\t"\
     /* mm1= Y1, mm2=ub, mm3=ug, mm4=vg mm5=vr, mm7=Y2 */\
     "paddw             %%mm3, %%mm4     \n\t"\
     "movq              %%mm2, %%mm0     \n\t"\
@@ -841,7 +848,7 @@ static void RENAME(yuv2yuyv422_X)(SwsContext *c, const int16_t *lumFilter,
 
 #define YSCALEYUV2RGB(index, c) \
     REAL_YSCALEYUV2RGB_UV(index, c) \
-    REAL_YSCALEYUV2RGB_YA(index, c, %0, %1) \
+    REAL_YSCALEYUV2RGB_YA(index, c, %q0, %q1) \
     REAL_YSCALEYUV2RGB_COEFF(c)
 
 /**
@@ -859,54 +866,56 @@ static void RENAME(yuv2rgb32_2)(SwsContext *c, const int16_t *buf[2],
         const int16_t *abuf0 = abuf[0], *abuf1 = abuf[1];
 #if ARCH_X86_64
         __asm__ volatile(
-            YSCALEYUV2RGB(%%r8, %5)
-            YSCALEYUV2RGB_YA(%%r8, %5, %6, %7)
+            YSCALEYUV2RGB(%%r8, %q5)
+            YSCALEYUV2RGB_YA(%%r8, %q5, %q6, %q7)
             "psraw                  $3, %%mm1       \n\t" /* abuf0[eax] - abuf1[eax] >>7*/
             "psraw                  $3, %%mm7       \n\t" /* abuf0[eax] - abuf1[eax] >>7*/
             "packuswb            %%mm7, %%mm1       \n\t"
-            WRITEBGR32(%4, 8280(%5), %%r8, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
+            WRITEBGR32(%q4, %%nacl:8280(%%r15, %q5), %%r8, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "r" (dest),
                "a" (&c->redDither),
                "r" (abuf0), "r" (abuf1)
-            : "%r8"
+            : "%r8", "%r14"
         );
 #else
         c->u_temp=(intptr_t)abuf0;
         c->v_temp=(intptr_t)abuf1;
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB(%%REGBP, %5)
-            "push                   %0              \n\t"
-            "push                   %1              \n\t"
-            "mov          "U_TEMP"(%5), %0          \n\t"
-            "mov          "V_TEMP"(%5), %1          \n\t"
-            YSCALEYUV2RGB_YA(%%REGBP, %5, %0, %1)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB(%%REGa, %q5)
+            "push                   %q0              \n\t"
+            "push                   %q1              \n\t"
+            "mov          %%nacl:"U_TEMP"(%%r15, %q5), %q0          \n\t"
+            "mov          %%nacl:"V_TEMP"(%%r15, %q5), %q1          \n\t"
+            YSCALEYUV2RGB_YA(%%REGa, %q5, %q0, %q1)
             "psraw                  $3, %%mm1       \n\t" /* abuf0[eax] - abuf1[eax] >>7*/
             "psraw                  $3, %%mm7       \n\t" /* abuf0[eax] - abuf1[eax] >>7*/
             "packuswb            %%mm7, %%mm1       \n\t"
-            "pop                    %1              \n\t"
-            "pop                    %0              \n\t"
-            WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            "pop                    %q1              \n\t"
+            "pop                    %q0              \n\t"
+            WRITEBGR32(%%REGb, %%nacl:8280(%%r15,%q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
 #endif
     } else {
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB(%%REGb, %q5)
             "pcmpeqd %%mm7, %%mm7                   \n\t"
-            WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITEBGR32(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+            "pop %%"REG_b"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+             : "%r14"
         );
     }
 }
@@ -921,16 +930,17 @@ static void RENAME(yuv2bgr24_2)(SwsContext *c, const int16_t *buf[2],
 
     //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(
     __asm__ volatile(
-        "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-        "mov        %4, %%"REG_b"               \n\t"
-        "push %%"REG_BP"                        \n\t"
-        YSCALEYUV2RGB(%%REGBP, %5)
+        "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+        "mov        %q4, %%"REG_b"               \n\t"
+        "push %%"REG_a"                        \n\t"
+        YSCALEYUV2RGB(%%REGa, %q5)
         "pxor    %%mm7, %%mm7                   \n\t"
-        WRITEBGR24(%%REGb, 8280(%5), %%REGBP)
-        "pop %%"REG_BP"                         \n\t"
-        "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+        WRITEBGR24(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+        "pop %%"REG_a"                         \n\t"
+        "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
         :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
            "a" (&c->redDither)
+           : "%r14"
     );
 }
 
@@ -944,22 +954,23 @@ static void RENAME(yuv2rgb555_2)(SwsContext *c, const int16_t *buf[2],
 
     //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(
     __asm__ volatile(
-        "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-        "mov        %4, %%"REG_b"               \n\t"
-        "push %%"REG_BP"                        \n\t"
-        YSCALEYUV2RGB(%%REGBP, %5)
+        "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+        "mov        %q4, %%"REG_b"               \n\t"
+        "push %%"REG_a"                        \n\t"
+        YSCALEYUV2RGB(%%REGa, %q5)
         "pxor    %%mm7, %%mm7                   \n\t"
         /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-        "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-        "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-        "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+        "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+        "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+        "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-        WRITERGB15(%%REGb, 8280(%5), %%REGBP)
-        "pop %%"REG_BP"                         \n\t"
-        "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+        WRITERGB15(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+        "pop %%"REG_a"                         \n\t"
+        "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
         :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
            "a" (&c->redDither)
+           : "%r14"
     );
 }
 
@@ -973,58 +984,59 @@ static void RENAME(yuv2rgb565_2)(SwsContext *c, const int16_t *buf[2],
 
     //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(
     __asm__ volatile(
-        "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-        "mov        %4, %%"REG_b"               \n\t"
-        "push %%"REG_BP"                        \n\t"
-        YSCALEYUV2RGB(%%REGBP, %5)
+        "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+        "mov        %q4, %%"REG_b"               \n\t"
+        "push %%"REG_a"                        \n\t"
+        YSCALEYUV2RGB(%%REGa, %q5)
         "pxor    %%mm7, %%mm7                   \n\t"
         /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-        "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-        "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-        "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+        "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+        "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+        "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-        WRITERGB16(%%REGb, 8280(%5), %%REGBP)
-        "pop %%"REG_BP"                         \n\t"
-        "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+        WRITERGB16(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+        "pop %%"REG_a"                         \n\t"
+        "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
         :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
            "a" (&c->redDither)
+           : "%r14"
     );
 }
 
 #define REAL_YSCALEYUV2PACKED(index, c) \
-    "movq "CHR_MMX_FILTER_OFFSET"+8("#c"), %%mm0              \n\t"\
-    "movq "LUM_MMX_FILTER_OFFSET"+8("#c"), %%mm1              \n\t"\
+    "movq %%nacl:"CHR_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm0              \n\t"\
+    "movq %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm1              \n\t"\
     "psraw                $3, %%mm0                           \n\t"\
     "psraw                $3, %%mm1                           \n\t"\
-    "movq              %%mm0, "CHR_MMX_FILTER_OFFSET"+8("#c") \n\t"\
-    "movq              %%mm1, "LUM_MMX_FILTER_OFFSET"+8("#c") \n\t"\
+    "movq              %%mm0, %%nacl:"CHR_MMX_FILTER_OFFSET"+8(%%r15, "#c") \n\t"\
+    "movq              %%mm1, %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c") \n\t"\
     "xor            "#index", "#index"                        \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm2     \n\t" /* uvbuf0[eax]*/\
-    "movq     (%3, "#index"), %%mm3     \n\t" /* uvbuf1[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
-    "movq     (%3, "#index"), %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm2     \n\t" /* uvbuf0[eax]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm3     \n\t" /* uvbuf1[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "psubw             %%mm3, %%mm2     \n\t" /* uvbuf0[eax] - uvbuf1[eax]*/\
     "psubw             %%mm4, %%mm5     \n\t" /* uvbuf0[eax+2048] - uvbuf1[eax+2048]*/\
-    "movq "CHR_MMX_FILTER_OFFSET"+8("#c"), %%mm0    \n\t"\
+    "movq %%nacl:"CHR_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm0    \n\t"\
     "pmulhw            %%mm0, %%mm2     \n\t" /* (uvbuf0[eax] - uvbuf1[eax])uvalpha1>>16*/\
     "pmulhw            %%mm0, %%mm5     \n\t" /* (uvbuf0[eax+2048] - uvbuf1[eax+2048])uvalpha1>>16*/\
     "psraw                $7, %%mm3     \n\t" /* uvbuf0[eax] - uvbuf1[eax] >>4*/\
     "psraw                $7, %%mm4     \n\t" /* uvbuf0[eax+2048] - uvbuf1[eax+2048] >>4*/\
     "paddw             %%mm2, %%mm3     \n\t" /* uvbuf0[eax]uvalpha1 - uvbuf1[eax](1-uvalpha1)*/\
     "paddw             %%mm5, %%mm4     \n\t" /* uvbuf0[eax+2048]uvalpha1 - uvbuf1[eax+2048](1-uvalpha1)*/\
-    "movq  (%0, "#index", 2), %%mm0     \n\t" /*buf0[eax]*/\
-    "movq  (%1, "#index", 2), %%mm1     \n\t" /*buf1[eax]*/\
-    "movq 8(%0, "#index", 2), %%mm6     \n\t" /*buf0[eax]*/\
-    "movq 8(%1, "#index", 2), %%mm7     \n\t" /*buf1[eax]*/\
+    "naclmovq1  \"(%q0, "#index", 2)\", %%mm0     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"(%q1, "#index", 2)\", %%mm1     \n\t" /*buf1[eax]*/\
+    "naclmovq1 \"8(%q0, "#index", 2)\", %%mm6     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8(%q1, "#index", 2)\", %%mm7     \n\t" /*buf1[eax]*/\
     "psubw             %%mm1, %%mm0     \n\t" /* buf0[eax] - buf1[eax]*/\
     "psubw             %%mm7, %%mm6     \n\t" /* buf0[eax] - buf1[eax]*/\
-    "pmulhw "LUM_MMX_FILTER_OFFSET"+8("#c"), %%mm0  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
-    "pmulhw "LUM_MMX_FILTER_OFFSET"+8("#c"), %%mm6  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
+    "pmulhw %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm0  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
+    "pmulhw %%nacl:"LUM_MMX_FILTER_OFFSET"+8(%%r15, "#c"), %%mm6  \n\t" /* (buf0[eax] - buf1[eax])yalpha1>>16*/\
     "psraw                $7, %%mm1     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "psraw                $7, %%mm7     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "paddw             %%mm0, %%mm1     \n\t" /* buf0[eax]yalpha1 + buf1[eax](1-yalpha1) >>16*/\
@@ -1042,15 +1054,16 @@ static void RENAME(yuv2yuyv422_2)(SwsContext *c, const int16_t *buf[2],
 
     //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(
     __asm__ volatile(
-        "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-        "mov %4, %%"REG_b"                        \n\t"
-        "push %%"REG_BP"                        \n\t"
-        YSCALEYUV2PACKED(%%REGBP, %5)
-        WRITEYUY2(%%REGb, 8280(%5), %%REGBP)
-        "pop %%"REG_BP"                         \n\t"
-        "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+        "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+        "mov %q4, %%"REG_b"                        \n\t"
+        "push %%"REG_a"                        \n\t"
+        YSCALEYUV2PACKED(%%REGa, %q5)
+        WRITEYUY2(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+        "pop %%"REG_a"                         \n\t"
+        "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
         :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
            "a" (&c->redDither)
+           : "%r14"
     );
 }
 
@@ -1058,29 +1071,29 @@ static void RENAME(yuv2yuyv422_2)(SwsContext *c, const int16_t *buf[2],
     "xor            "#index", "#index"  \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm3     \n\t" /* uvbuf0[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm4     \n\t" /* uvbuf0[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm3     \n\t" /* uvbuf0[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm4     \n\t" /* uvbuf0[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "psraw                $4, %%mm3     \n\t" /* uvbuf0[eax] - uvbuf1[eax] >>4*/\
     "psraw                $4, %%mm4     \n\t" /* uvbuf0[eax+2048] - uvbuf1[eax+2048] >>4*/\
-    "psubw  "U_OFFSET"("#c"), %%mm3     \n\t" /* (U-128)8*/\
-    "psubw  "V_OFFSET"("#c"), %%mm4     \n\t" /* (V-128)8*/\
+    "psubw  %%nacl:"U_OFFSET"(%%r15, "#c"), %%mm3     \n\t" /* (%%r15, U-128)8*/\
+    "psubw  %%nacl:"V_OFFSET"(%%r15, "#c"), %%mm4     \n\t" /* (%%r15, V-128)8*/\
     "movq              %%mm3, %%mm2     \n\t" /* (U-128)8*/\
     "movq              %%mm4, %%mm5     \n\t" /* (V-128)8*/\
-    "pmulhw "UG_COEFF"("#c"), %%mm3     \n\t"\
-    "pmulhw "VG_COEFF"("#c"), %%mm4     \n\t"\
+    "pmulhw %%nacl:"UG_COEFF"(%%r15, "#c"), %%mm3     \n\t"\
+    "pmulhw %%nacl:"VG_COEFF"(%%r15, "#c"), %%mm4     \n\t"\
     /* mm2=(U-128)8, mm3=ug, mm4=vg mm5=(V-128)8 */\
-    "movq  (%0, "#index", 2), %%mm1     \n\t" /*buf0[eax]*/\
-    "movq 8(%0, "#index", 2), %%mm7     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"(%q0, "#index", 2)\", %%mm1     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8(%q0, "#index", 2)\", %%mm7     \n\t" /*buf0[eax]*/\
     "psraw                $4, %%mm1     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "psraw                $4, %%mm7     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
-    "pmulhw "UB_COEFF"("#c"), %%mm2     \n\t"\
-    "pmulhw "VR_COEFF"("#c"), %%mm5     \n\t"\
-    "psubw  "Y_OFFSET"("#c"), %%mm1     \n\t" /* 8(Y-16)*/\
-    "psubw  "Y_OFFSET"("#c"), %%mm7     \n\t" /* 8(Y-16)*/\
-    "pmulhw  "Y_COEFF"("#c"), %%mm1     \n\t"\
-    "pmulhw  "Y_COEFF"("#c"), %%mm7     \n\t"\
+    "pmulhw %%nacl:"UB_COEFF"(%%r15, "#c"), %%mm2     \n\t"\
+    "pmulhw %%nacl:"VR_COEFF"(%%r15, "#c"), %%mm5     \n\t"\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm1     \n\t" /* 8(%%r15, Y-16)*/\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm7     \n\t" /* 8(%%r15, Y-16)*/\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm1     \n\t"\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm7     \n\t"\
     /* mm1= Y1, mm2=ub, mm3=ug, mm4=vg mm5=vr, mm7=Y2 */\
     "paddw             %%mm3, %%mm4     \n\t"\
     "movq              %%mm2, %%mm0     \n\t"\
@@ -1110,33 +1123,33 @@ static void RENAME(yuv2yuyv422_2)(SwsContext *c, const int16_t *buf[2],
     "xor            "#index", "#index"  \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm2     \n\t" /* uvbuf0[eax]*/\
-    "movq     (%3, "#index"), %%mm3     \n\t" /* uvbuf1[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
-    "movq     (%3, "#index"), %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm2     \n\t" /* uvbuf0[eax]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm3     \n\t" /* uvbuf1[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "paddw             %%mm2, %%mm3     \n\t" /* uvbuf0[eax] + uvbuf1[eax]*/\
     "paddw             %%mm5, %%mm4     \n\t" /* uvbuf0[eax+2048] + uvbuf1[eax+2048]*/\
     "psrlw                $5, %%mm3     \n\t" /*FIXME might overflow*/\
     "psrlw                $5, %%mm4     \n\t" /*FIXME might overflow*/\
-    "psubw  "U_OFFSET"("#c"), %%mm3     \n\t" /* (U-128)8*/\
-    "psubw  "V_OFFSET"("#c"), %%mm4     \n\t" /* (V-128)8*/\
+    "psubw  %%nacl:"U_OFFSET"(%%r15, "#c"), %%mm3     \n\t" /* (%%r15, U-128)8*/\
+    "psubw  %%nacl:"V_OFFSET"(%%r15, "#c"), %%mm4     \n\t" /* (%%r15, V-128)8*/\
     "movq              %%mm3, %%mm2     \n\t" /* (U-128)8*/\
     "movq              %%mm4, %%mm5     \n\t" /* (V-128)8*/\
-    "pmulhw "UG_COEFF"("#c"), %%mm3     \n\t"\
-    "pmulhw "VG_COEFF"("#c"), %%mm4     \n\t"\
+    "pmulhw %%nacl:"UG_COEFF"(%%r15, "#c"), %%mm3     \n\t"\
+    "pmulhw %%nacl:"VG_COEFF"(%%r15, "#c"), %%mm4     \n\t"\
     /* mm2=(U-128)8, mm3=ug, mm4=vg mm5=(V-128)8 */\
-    "movq  (%0, "#index", 2), %%mm1     \n\t" /*buf0[eax]*/\
-    "movq 8(%0, "#index", 2), %%mm7     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"(%q0, "#index", 2)\", %%mm1     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8(%q0, "#index", 2)\", %%mm7     \n\t" /*buf0[eax]*/\
     "psraw                $4, %%mm1     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
     "psraw                $4, %%mm7     \n\t" /* buf0[eax] - buf1[eax] >>4*/\
-    "pmulhw "UB_COEFF"("#c"), %%mm2     \n\t"\
-    "pmulhw "VR_COEFF"("#c"), %%mm5     \n\t"\
-    "psubw  "Y_OFFSET"("#c"), %%mm1     \n\t" /* 8(Y-16)*/\
-    "psubw  "Y_OFFSET"("#c"), %%mm7     \n\t" /* 8(Y-16)*/\
-    "pmulhw  "Y_COEFF"("#c"), %%mm1     \n\t"\
-    "pmulhw  "Y_COEFF"("#c"), %%mm7     \n\t"\
+    "pmulhw %%nacl:"UB_COEFF"(%%r15, "#c"), %%mm2     \n\t"\
+    "pmulhw %%nacl:"VR_COEFF"(%%r15, "#c"), %%mm5     \n\t"\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm1     \n\t" /* 8(%%r15, Y-16)*/\
+    "psubw  %%nacl:"Y_OFFSET"(%%r15, "#c"), %%mm7     \n\t" /* 8(%%r15, Y-16)*/\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm1     \n\t"\
+    "pmulhw  %%nacl:"Y_COEFF"(%%r15, "#c"), %%mm7     \n\t"\
     /* mm1= Y1, mm2=ub, mm3=ug, mm4=vg mm5=vr, mm7=Y2 */\
     "paddw             %%mm3, %%mm4     \n\t"\
     "movq              %%mm2, %%mm0     \n\t"\
@@ -1162,8 +1175,8 @@ static void RENAME(yuv2yuyv422_2)(SwsContext *c, const int16_t *buf[2],
 #define YSCALEYUV2RGB1b(index, c)  REAL_YSCALEYUV2RGB1b(index, c)
 
 #define REAL_YSCALEYUV2RGB1_ALPHA(index) \
-    "movq  (%1, "#index", 2), %%mm7     \n\t" /* abuf0[index  ]     */\
-    "movq 8(%1, "#index", 2), %%mm1     \n\t" /* abuf0[index+4]     */\
+    "naclmovq1  \"(%q1, "#index", 2)\", %%mm7     \n\t" /* abuf0[index  ]     */\
+    "naclmovq1 \"8(%q1, "#index", 2)\", %%mm1     \n\t" /* abuf0[index+4]     */\
     "psraw                $7, %%mm7     \n\t" /* abuf0[index  ] >>7 */\
     "psraw                $7, %%mm1     \n\t" /* abuf0[index+4] >>7 */\
     "packuswb          %%mm1, %%mm7     \n\t"
@@ -1184,58 +1197,62 @@ static void RENAME(yuv2rgb32_1)(SwsContext *c, const int16_t *buf0,
         const int16_t *ubuf1 = ubuf[0];
         if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {
             __asm__ volatile(
-                "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-                "mov        %4, %%"REG_b"               \n\t"
-                "push %%"REG_BP"                        \n\t"
-                YSCALEYUV2RGB1(%%REGBP, %5)
-                YSCALEYUV2RGB1_ALPHA(%%REGBP)
-                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
-                "pop %%"REG_BP"                         \n\t"
-                "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+                "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+                "mov        %q4, %%"REG_b"               \n\t"
+                "push %%"REG_a"                        \n\t"
+                YSCALEYUV2RGB1(%%REGa, %q5)
+                YSCALEYUV2RGB1_ALPHA(%%REGa)
+                WRITEBGR32(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+                "pop %%"REG_a"                         \n\t"
+                "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
                 :: "c" (buf0), "d" (abuf0), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                    "a" (&c->redDither)
+                   : "%r14"
             );
         } else {
             __asm__ volatile(
-                "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-                "mov        %4, %%"REG_b"               \n\t"
-                "push %%"REG_BP"                        \n\t"
-                YSCALEYUV2RGB1(%%REGBP, %5)
+                "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+                "mov        %q4, %%"REG_b"               \n\t"
+                "push %%"REG_a"                        \n\t"
+                YSCALEYUV2RGB1(%%REGa, %q5)
                 "pcmpeqd %%mm7, %%mm7                   \n\t"
-                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
-                "pop %%"REG_BP"                         \n\t"
-                "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+                WRITEBGR32(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+                "pop %%"REG_a"                         \n\t"
+                "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
                 :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                    "a" (&c->redDither)
+                   : "%r14"
             );
         }
     } else {
         const int16_t *ubuf1 = ubuf[1];
         if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {
             __asm__ volatile(
-                "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-                "mov        %4, %%"REG_b"               \n\t"
-                "push %%"REG_BP"                        \n\t"
-                YSCALEYUV2RGB1b(%%REGBP, %5)
-                YSCALEYUV2RGB1_ALPHA(%%REGBP)
-                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
-                "pop %%"REG_BP"                         \n\t"
-                "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+                "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+                "mov        %q4, %%"REG_b"               \n\t"
+                "push %%"REG_a"                        \n\t"
+                YSCALEYUV2RGB1b(%%REGa, %q5)
+                YSCALEYUV2RGB1_ALPHA(%%REGa)
+                WRITEBGR32(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+                "pop %%"REG_a"                         \n\t"
+                "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
                 :: "c" (buf0), "d" (abuf0), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                    "a" (&c->redDither)
+                   : "%r14"
             );
         } else {
             __asm__ volatile(
-                "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-                "mov        %4, %%"REG_b"               \n\t"
-                "push %%"REG_BP"                        \n\t"
-                YSCALEYUV2RGB1b(%%REGBP, %5)
+                "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+                "mov        %q4, %%"REG_b"               \n\t"
+                "push %%"REG_a"                        \n\t"
+                YSCALEYUV2RGB1b(%%REGa, %q5)
                 "pcmpeqd %%mm7, %%mm7                   \n\t"
-                WRITEBGR32(%%REGb, 8280(%5), %%REGBP, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
-                "pop %%"REG_BP"                         \n\t"
-                "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+                WRITEBGR32(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)
+                "pop %%"REG_a"                         \n\t"
+                "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
                 :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                    "a" (&c->redDither)
+                   : "%r14"
             );
         }
     }
@@ -1252,30 +1269,32 @@ static void RENAME(yuv2bgr24_1)(SwsContext *c, const int16_t *buf0,
     if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster
         const int16_t *ubuf1 = ubuf[0];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
-            WRITEBGR24(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITEBGR24(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     } else {
         const int16_t *ubuf1 = ubuf[1];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1b(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1b(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
-            WRITEBGR24(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITEBGR24(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     }
 }
@@ -1291,42 +1310,44 @@ static void RENAME(yuv2rgb555_1)(SwsContext *c, const int16_t *buf0,
     if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster
         const int16_t *ubuf1 = ubuf[0];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
             /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-            "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-            "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-            "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+            "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+            "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+            "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-            WRITERGB15(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITERGB15(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     } else {
         const int16_t *ubuf1 = ubuf[1];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1b(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1b(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
             /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-            "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-            "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-            "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+            "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+            "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+            "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-            WRITERGB15(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITERGB15(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     }
 }
@@ -1342,42 +1363,44 @@ static void RENAME(yuv2rgb565_1)(SwsContext *c, const int16_t *buf0,
     if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster
         const int16_t *ubuf1 = ubuf[0];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
             /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-            "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-            "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-            "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+            "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+            "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+            "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-            WRITERGB16(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITERGB16(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     } else {
         const int16_t *ubuf1 = ubuf[1];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2RGB1b(%%REGBP, %5)
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2RGB1b(%%REGa, %q5)
             "pxor    %%mm7, %%mm7                   \n\t"
             /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */
 #ifdef DITHER1XBPP
-            "paddusb "BLUE_DITHER"(%5), %%mm2      \n\t"
-            "paddusb "GREEN_DITHER"(%5), %%mm4      \n\t"
-            "paddusb "RED_DITHER"(%5), %%mm5      \n\t"
+            "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q5), %%mm2      \n\t"
+            "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q5), %%mm4      \n\t"
+            "paddusb %%nacl:"RED_DITHER"(%%r15, %q5), %%mm5      \n\t"
 #endif
-            WRITERGB16(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            WRITERGB16(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     }
 }
@@ -1386,14 +1409,14 @@ static void RENAME(yuv2rgb565_1)(SwsContext *c, const int16_t *buf0,
     "xor            "#index", "#index"  \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm3     \n\t" /* uvbuf0[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm4     \n\t" /* uvbuf0[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm3     \n\t" /* uvbuf0[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm4     \n\t" /* uvbuf0[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "psraw                $7, %%mm3     \n\t" \
     "psraw                $7, %%mm4     \n\t" \
-    "movq  (%0, "#index", 2), %%mm1     \n\t" /*buf0[eax]*/\
-    "movq 8(%0, "#index", 2), %%mm7     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"(%q0, "#index", 2)\", %%mm1     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8(%q0, "#index", 2)\", %%mm7     \n\t" /*buf0[eax]*/\
     "psraw                $7, %%mm1     \n\t" \
     "psraw                $7, %%mm7     \n\t" \
 
@@ -1403,18 +1426,18 @@ static void RENAME(yuv2rgb565_1)(SwsContext *c, const int16_t *buf0,
     "xor "#index", "#index"             \n\t"\
     ".p2align              4            \n\t"\
     "1:                                 \n\t"\
-    "movq     (%2, "#index"), %%mm2     \n\t" /* uvbuf0[eax]*/\
-    "movq     (%3, "#index"), %%mm3     \n\t" /* uvbuf1[eax]*/\
-    "add "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
-    "movq     (%2, "#index"), %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
-    "movq     (%3, "#index"), %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
-    "sub "UV_OFF_BYTE"("#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm2     \n\t" /* uvbuf0[eax]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm3     \n\t" /* uvbuf1[eax]*/\
+    "add %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
+    "naclmovq1     \"(%q2, "#index")\", %%mm5     \n\t" /* uvbuf0[eax+2048]*/\
+    "naclmovq1     \"(%q3, "#index")\", %%mm4     \n\t" /* uvbuf1[eax+2048]*/\
+    "sub %%nacl:"UV_OFF_BYTE"(%%r15, "#c"), "#index"  \n\t" \
     "paddw             %%mm2, %%mm3     \n\t" /* uvbuf0[eax] + uvbuf1[eax]*/\
     "paddw             %%mm5, %%mm4     \n\t" /* uvbuf0[eax+2048] + uvbuf1[eax+2048]*/\
     "psrlw                $8, %%mm3     \n\t" \
     "psrlw                $8, %%mm4     \n\t" \
-    "movq  (%0, "#index", 2), %%mm1     \n\t" /*buf0[eax]*/\
-    "movq 8(%0, "#index", 2), %%mm7     \n\t" /*buf0[eax]*/\
+    "naclmovq1  \"(%q0, "#index", 2)\", %%mm1     \n\t" /*buf0[eax]*/\
+    "naclmovq1 \"8(%q0, "#index", 2)\", %%mm7     \n\t" /*buf0[eax]*/\
     "psraw                $7, %%mm1     \n\t" \
     "psraw                $7, %%mm7     \n\t"
 #define YSCALEYUV2PACKED1b(index, c)  REAL_YSCALEYUV2PACKED1b(index, c)
@@ -1430,28 +1453,30 @@ static void RENAME(yuv2yuyv422_1)(SwsContext *c, const int16_t *buf0,
     if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster
         const int16_t *ubuf1 = ubuf[0];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2PACKED1(%%REGBP, %5)
-            WRITEYUY2(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2PACKED1(%%REGa, %q5)
+            WRITEYUY2(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     } else {
         const int16_t *ubuf1 = ubuf[1];
         __asm__ volatile(
-            "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
-            "mov        %4, %%"REG_b"               \n\t"
-            "push %%"REG_BP"                        \n\t"
-            YSCALEYUV2PACKED1b(%%REGBP, %5)
-            WRITEYUY2(%%REGb, 8280(%5), %%REGBP)
-            "pop %%"REG_BP"                         \n\t"
-            "mov "ESP_OFFSET"(%5), %%"REG_b"        \n\t"
+            "mov %%"REG_b", %%nacl:"ESP_OFFSET"(%%r15, %q5)        \n\t"
+            "mov        %q4, %%"REG_b"               \n\t"
+            "push %%"REG_a"                        \n\t"
+            YSCALEYUV2PACKED1b(%%REGa, %q5)
+            WRITEYUY2(%%REGb, %%nacl:8280(%%r15, %q5), %%REGa)
+            "pop %%"REG_a"                         \n\t"
+            "mov %%nacl:"ESP_OFFSET"(%%r15, %q5), %%"REG_b"        \n\t"
             :: "c" (buf0), "d" (buf1), "S" (ubuf0), "D" (ubuf1), "m" (dest),
                "a" (&c->redDither)
+               : "%r14"
         );
     }
 }
@@ -1474,22 +1499,22 @@ static void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,
 
     __asm__ volatile(
 #if defined(PIC)
-        "mov               %%"REG_b", %5        \n\t"
+        "mov               %%"REG_b", %q5        \n\t"
 #if ARCH_X86_64
-        "mov               -8(%%rsp), %%"REG_a" \n\t"
-        "mov               %%"REG_a", %6        \n\t"
+        "mov               %%nacl:-8(%%r15, %%rsp), %%"REG_a" \n\t"
+        "mov               %%"REG_a", %q6        \n\t"
 #endif
 #else
 #if ARCH_X86_64
         "mov               -8(%%rsp), %%"REG_a" \n\t"
-        "mov               %%"REG_a", %5        \n\t"
+        "mov               %%"REG_a", %q5        \n\t"
 #endif
 #endif
         "pxor                  %%mm7, %%mm7     \n\t"
-        "mov                      %0, %%"REG_c" \n\t"
-        "mov                      %1, %%"REG_D" \n\t"
-        "mov                      %2, %%"REG_d" \n\t"
-        "mov                      %3, %%"REG_b" \n\t"
+        "mov                      %q0, %%"REG_c" \n\t"
+        "mov                      %q1, %%"REG_D" \n\t"
+        "mov                      %q2, %%"REG_d" \n\t"
+        "mov                      %q3, %%"REG_b" \n\t"
         "xor               %%"REG_a", %%"REG_a" \n\t" // i
         PREFETCH"        (%%"REG_c")            \n\t"
         PREFETCH"      32(%%"REG_c")            \n\t"
@@ -1497,18 +1522,21 @@ static void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,
 
 #if ARCH_X86_64
 #define CALL_MMXEXT_FILTER_CODE \
-        "movl            (%%"REG_b"), %%esi     \n\t"\
-        "call                    *%4            \n\t"\
-        "movl (%%"REG_b", %%"REG_a"), %%esi     \n\t"\
+        "movl            %%nacl:(%%r15, %%"REG_b"), %%esi     \n\t"\
+        "naclcall                    %k4,%%r15            \n\t"\
+        ".bundle_lock \n\t"\
+        "lea (%%"REG_b", %%"REG_a"), %%esi \n\t"\
+        "movl (%%r15, %%rsi), %%esi     \n\t"\
+        ".bundle_unlock \n\t"\
         "add               %%"REG_S", %%"REG_c" \n\t"\
         "add               %%"REG_a", %%"REG_D" \n\t"\
         "xor               %%"REG_a", %%"REG_a" \n\t"\
 
 #else
 #define CALL_MMXEXT_FILTER_CODE \
-        "movl (%%"REG_b"), %%esi        \n\t"\
-        "call         *%4                       \n\t"\
-        "addl (%%"REG_b", %%"REG_a"), %%"REG_c" \n\t"\
+        "movl %%nacl:(%%r15, %%"REG_b"), %%esi        \n\t"\
+        "naclcall         %k4,%%r15                     \n\t"\
+        "add (%%"REG_b", %%"REG_a"), %%"REG_c" \n\t"\
         "add               %%"REG_a", %%"REG_D" \n\t"\
         "xor               %%"REG_a", %%"REG_a" \n\t"\
 
@@ -1524,26 +1552,26 @@ static void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,
         CALL_MMXEXT_FILTER_CODE
 
 #if defined(PIC)
-        "mov                      %5, %%"REG_b" \n\t"
+        "mov                      %q5, %%"REG_b" \n\t"
 #if ARCH_X86_64
-        "mov                      %6, %%"REG_a" \n\t"
+        "mov                      %q6, %%"REG_a" \n\t"
         "mov               %%"REG_a", -8(%%rsp) \n\t"
 #endif
 #else
 #if ARCH_X86_64
-        "mov                      %5, %%"REG_a" \n\t"
+        "mov                      %q5, %%"REG_a" \n\t"
         "mov               %%"REG_a", -8(%%rsp) \n\t"
 #endif
 #endif
         :: "m" (src), "m" (dst), "m" (filter), "m" (filterPos),
-           "m" (mmxextFilterCode)
+           "r" (mmxextFilterCode)
 #if defined(PIC)
           ,"m" (ebxsave)
 #endif
 #if ARCH_X86_64
           ,"m"(retsave)
 #endif
-        : "%"REG_a, "%"REG_c, "%"REG_d, "%"REG_S, "%"REG_D
+        : "%"REG_a, "%"REG_c, "%"REG_d, "%"REG_S, "%"REG_D, "%r14"
 #if !defined(PIC)
          ,"%"REG_b
 #endif
@@ -1570,22 +1598,22 @@ static void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst1, int16_t *dst2,
 
     __asm__ volatile(
 #if defined(PIC)
-        "mov          %%"REG_b", %7         \n\t"
+        "mov          %%"REG_b", %q7         \n\t"
 #if ARCH_X86_64
         "mov          -8(%%rsp), %%"REG_a"  \n\t"
-        "mov          %%"REG_a", %8         \n\t"
+        "mov          %%"REG_a", %q8         \n\t"
 #endif
 #else
 #if ARCH_X86_64
         "mov          -8(%%rsp), %%"REG_a"  \n\t"
-        "mov          %%"REG_a", %7         \n\t"
+        "mov          %%"REG_a", %q7         \n\t"
 #endif
 #endif
         "pxor             %%mm7, %%mm7      \n\t"
-        "mov                 %0, %%"REG_c"  \n\t"
-        "mov                 %1, %%"REG_D"  \n\t"
-        "mov                 %2, %%"REG_d"  \n\t"
-        "mov                 %3, %%"REG_b"  \n\t"
+        "mov                 %q0, %%"REG_c"  \n\t"
+        "mov                 %q1, %%"REG_D"  \n\t"
+        "mov                 %q2, %%"REG_d"  \n\t"
+        "mov                 %q3, %%"REG_b"  \n\t"
         "xor          %%"REG_a", %%"REG_a"  \n\t" // i
         PREFETCH"   (%%"REG_c")             \n\t"
         PREFETCH" 32(%%"REG_c")             \n\t"
@@ -1596,8 +1624,8 @@ static void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst1, int16_t *dst2,
         CALL_MMXEXT_FILTER_CODE
         CALL_MMXEXT_FILTER_CODE
         "xor          %%"REG_a", %%"REG_a"  \n\t" // i
-        "mov                 %5, %%"REG_c"  \n\t" // src
-        "mov                 %6, %%"REG_D"  \n\t" // buf2
+        "mov                 %q5, %%"REG_c"  \n\t" // src
+        "mov                 %q6, %%"REG_D"  \n\t" // buf2
         PREFETCH"   (%%"REG_c")             \n\t"
         PREFETCH" 32(%%"REG_c")             \n\t"
         PREFETCH" 64(%%"REG_c")             \n\t"
@@ -1608,26 +1636,26 @@ static void RENAME(hcscale_fast)(SwsContext *c, int16_t *dst1, int16_t *dst2,
         CALL_MMXEXT_FILTER_CODE
 
 #if defined(PIC)
-        "mov %7, %%"REG_b"    \n\t"
+        "mov %q7, %%"REG_b"    \n\t"
 #if ARCH_X86_64
-        "mov                 %8, %%"REG_a"  \n\t"
+        "mov                 %q8, %%"REG_a"  \n\t"
         "mov          %%"REG_a", -8(%%rsp)  \n\t"
 #endif
 #else
 #if ARCH_X86_64
-        "mov                 %7, %%"REG_a"  \n\t"
+        "mov                 %q7, %%"REG_a"  \n\t"
         "mov          %%"REG_a", -8(%%rsp)  \n\t"
 #endif
 #endif
         :: "m" (src1), "m" (dst1), "m" (filter), "m" (filterPos),
-           "m" (mmxextFilterCode), "m" (src2), "m"(dst2)
+           "r" (mmxextFilterCode), "m" (src2), "m"(dst2)
 #if defined(PIC)
           ,"m" (ebxsave)
 #endif
 #if ARCH_X86_64
           ,"m"(retsave)
 #endif
-        : "%"REG_a, "%"REG_c, "%"REG_d, "%"REG_S, "%"REG_D
+        : "%"REG_a, "%"REG_c, "%"REG_d, "%"REG_S, "%"REG_D, "%r14"
 #if !defined(PIC)
          ,"%"REG_b
 #endif
diff --git a/libswscale/x86/yuv2rgb_template.c b/libswscale/x86/yuv2rgb_template.c
index c879102..e6d3ae4 100644
--- a/libswscale/x86/yuv2rgb_template.c
+++ b/libswscale/x86/yuv2rgb_template.c
@@ -55,9 +55,9 @@
 
 #define YUV2RGB_INITIAL_LOAD          \
     __asm__ volatile (                \
-        "movq (%5, %0, 2), %%mm6\n\t" \
-        "movd    (%2, %0), %%mm0\n\t" \
-        "movd    (%3, %0), %%mm1\n\t" \
+        "naclmovq1 \"(%q5, %q0, 2)\", %%mm6\n\t" \
+        "naclmovd1    \"(%q2, %q0)\", %%mm0\n\t" \
+        "naclmovd1    \"(%q3, %q0)\", %%mm1\n\t" \
         "1: \n\t"                     \
 
 /* YUV2RGB core
@@ -87,20 +87,20 @@
     "psllw     $3,    %%mm1\n\t"                 \
     "psllw     $3,    %%mm6\n\t"                 \
     "psllw     $3,    %%mm7\n\t"                 \
-    "psubsw   "U_OFFSET"(%4), %%mm0\n\t"         \
-    "psubsw   "V_OFFSET"(%4), %%mm1\n\t"         \
-    "psubw    "Y_OFFSET"(%4), %%mm6\n\t"         \
-    "psubw    "Y_OFFSET"(%4), %%mm7\n\t"         \
+    "psubsw   %%nacl:"U_OFFSET"(%%r15, %q4), %%mm0\n\t"         \
+    "psubsw   %%nacl:"V_OFFSET"(%%r15, %q4), %%mm1\n\t"         \
+    "psubw    %%nacl:"Y_OFFSET"(%%r15, %q4), %%mm6\n\t"         \
+    "psubw    %%nacl:"Y_OFFSET"(%%r15, %q4), %%mm7\n\t"         \
 \
      /* multiply by coefficients */              \
     "movq      %%mm0, %%mm2\n\t"                 \
     "movq      %%mm1, %%mm3\n\t"                 \
-    "pmulhw   "UG_COEFF"(%4), %%mm2\n\t"         \
-    "pmulhw   "VG_COEFF"(%4), %%mm3\n\t"         \
-    "pmulhw   "Y_COEFF" (%4), %%mm6\n\t"         \
-    "pmulhw   "Y_COEFF" (%4), %%mm7\n\t"         \
-    "pmulhw   "UB_COEFF"(%4), %%mm0\n\t"         \
-    "pmulhw   "VR_COEFF"(%4), %%mm1\n\t"         \
+    "pmulhw   %%nacl:"UG_COEFF"(%%r15, %q4), %%mm2\n\t"         \
+    "pmulhw   %%nacl:"VG_COEFF"(%%r15, %q4), %%mm3\n\t"         \
+    "pmulhw   %%nacl:"Y_COEFF" (%%r15, %q4), %%mm6\n\t"         \
+    "pmulhw   %%nacl:"Y_COEFF" (%%r15, %q4), %%mm7\n\t"         \
+    "pmulhw   %%nacl:"UB_COEFF"(%%r15, %q4), %%mm0\n\t"         \
+    "pmulhw   %%nacl:"VR_COEFF"(%%r15, %q4), %%mm1\n\t"         \
     "paddsw    %%mm3, %%mm2\n\t"                 \
     /* now: mm0 = UB, mm1 = VR, mm2 = CG */      \
     /*      mm6 = Y1, mm7 = Y2 */                \
@@ -127,18 +127,18 @@
     "punpcklbw %%mm7, %%mm2\n\t"                 \
 
 #define YUV2RGB_ENDLOOP(depth)                   \
-    "movq 8 (%5, %0, 2), %%mm6\n\t"              \
-    "movd 4 (%3, %0),    %%mm1\n\t"              \
-    "movd 4 (%2, %0),    %%mm0\n\t"              \
-    "add $"AV_STRINGIFY(depth * 8)", %1\n\t"     \
-    "add  $4, %0\n\t"                            \
+    "naclmovq1 \"8 (%q5, %q0, 2)\", %%mm6\n\t"              \
+    "naclmovd1 \"4 (%q3, %q0)\",    %%mm1\n\t"              \
+    "naclmovd1 \"4 (%q2, %q0)\",    %%mm0\n\t"              \
+    "add $"AV_STRINGIFY(depth * 8)", %q1\n\t"     \
+    "add  $4, %q0\n\t"                            \
     "js   1b\n\t"                                \
 
 #define YUV2RGB_OPERANDS                                          \
         : "+r" (index), "+r" (image)                              \
         : "r" (pu - index), "r" (pv - index), "r"(&c->redDither), \
           "r" (py - 2*index)                                      \
-        : "memory"                                                \
+        : "memory", "%r14"                                                \
         );                                                        \
     }                                                             \
 
@@ -146,7 +146,7 @@
         : "+r" (index), "+r" (image)                              \
         : "r" (pu - index), "r" (pv - index), "r"(&c->redDither), \
           "r" (py - 2*index), "r" (pa - 2*index)                  \
-        : "memory"                                                \
+        : "memory", "%r14"                                               \
         );                                                        \
     }                                                             \
 
@@ -173,13 +173,13 @@
     "movq      %%mm0,     %%mm2\n\t"             \
     "punpcklbw %%mm1,     %%mm0\n\t"             \
     "punpckhbw %%mm1,     %%mm2\n\t"             \
-    MOVNTQ "   %%mm0,      (%1)\n\t"             \
-    MOVNTQ "   %%mm2,     8(%1)\n\t"             \
+    MOVNTQ "   %%mm0,      %%nacl:(%%r15, %q1)\n\t"             \
+    MOVNTQ "   %%mm2,     %%nacl:8(%%r15, %q1)\n\t"             \
 
 #define DITHER_RGB                               \
-    "paddusb "BLUE_DITHER"(%4),  %%mm0\n\t"      \
-    "paddusb "GREEN_DITHER"(%4), %%mm2\n\t"      \
-    "paddusb "RED_DITHER"(%4),   %%mm1\n\t"      \
+    "paddusb %%nacl:"BLUE_DITHER"(%%r15, %q4),  %%mm0\n\t"      \
+    "paddusb %%nacl:"GREEN_DITHER"(%%r15, %q4), %%mm2\n\t"      \
+    "paddusb %%nacl:"RED_DITHER"(%%r15, %q4),   %%mm1\n\t"      \
 
 #if !COMPILE_TEMPLATE_MMXEXT
 static inline int RENAME(yuv420_rgb15)(SwsContext *c, const uint8_t *src[],
@@ -278,25 +278,25 @@ DECLARE_ASM_CONST(8, int16_t, mask0100[4]) = { 0,-1, 0, 0};
     "por       %%mm6,         %%mm0 \n"\
     "por       %%mm5,         %%mm1 \n"\
     "por       %%mm7,         %%mm2 \n"\
-    MOVNTQ"    %%mm0,          (%1) \n"\
-    MOVNTQ"    %%mm1,         8(%1) \n"\
-    MOVNTQ"    %%mm2,        16(%1) \n"\
+    MOVNTQ"    %%mm0,          %%nacl:(%%r15, %q1) \n"\
+    MOVNTQ"    %%mm1,         %%nacl:8(%%r15, %q1) \n"\
+    MOVNTQ"    %%mm2,        %%nacl:16(%%r15, %q1) \n"\
 
 #else
 #undef RGB_PACK24_B
 #define RGB_PACK24_B\
-    "movd      %%mm3,       (%1) \n" /* R0 G0 B0 R1 */\
-    "movd      %%mm2,      4(%1) \n" /* G1 B1 */\
+    "movd      %%mm3,       %%nacl:(%%r15, %q1) \n" /* R0 G0 B0 R1 */\
+    "movd      %%mm2,      %%nacl:4(%%r15, %q1) \n" /* G1 B1 */\
     "psrlq     $32,        %%mm3 \n"\
     "psrlq     $16,        %%mm2 \n"\
-    "movd      %%mm3,      6(%1) \n" /* R2 G2 B2 R3 */\
-    "movd      %%mm2,     10(%1) \n" /* G3 B3 */\
+    "movd      %%mm3,      %%nacl:6(%%r15, %q1) \n" /* R2 G2 B2 R3 */\
+    "movd      %%mm2,     %%nacl:10(%%r15, %q1) \n" /* G3 B3 */\
     "psrlq     $16,        %%mm2 \n"\
-    "movd      %%mm5,     12(%1) \n" /* R4 G4 B4 R5 */\
-    "movd      %%mm2,     16(%1) \n" /* G5 B5 */\
+    "movd      %%mm5,     %%nacl:12(%%r15, %q1) \n" /* R4 G4 B4 R5 */\
+    "movd      %%mm2,     %%nacl:16(%%r15, %q1) \n" /* G5 B5 */\
     "psrlq     $32,        %%mm5 \n"\
-    "movd      %%mm2,     20(%1) \n" /* -- -- G7 B7 */\
-    "movd      %%mm5,     18(%1) \n" /* R6 G6 B6 R7 */\
+    "movd      %%mm2,     %%nacl:20(%%r15, %q1) \n" /* -- -- G7 B7 */\
+    "movd      %%mm5,     %%nacl:18(%%r15, %q1) \n" /* R6 G6 B6 R7 */\
 
 #endif
 
@@ -341,7 +341,7 @@ static inline int RENAME(yuv420_bgr24)(SwsContext *c, const uint8_t *src[],
     "pcmpeqd   %%mm"REG_ALPHA", %%mm"REG_ALPHA"\n\t" /* set alpha to 0xFF */ \
 
 #define LOAD_ALPHA                                   \
-    "movq      (%6, %0, 2),     %%mm"REG_ALPHA"\n\t" \
+    "naclmovq1      \"(%q6, %q0, 2)\",     %%mm"REG_ALPHA"\n\t" \
 
 #define RGB_PACK32(red, green, blue, alpha)  \
     "movq      %%mm"blue",  %%mm5\n\t"       \
@@ -356,10 +356,10 @@ static inline int RENAME(yuv420_bgr24)(SwsContext *c, const uint8_t *src[],
     "punpckhwd %%mm"red",   %%mm"green"\n\t" \
     "punpcklwd %%mm6,       %%mm5\n\t"       \
     "punpckhwd %%mm6,       %%mm"alpha"\n\t" \
-    MOVNTQ "   %%mm"blue",   0(%1)\n\t"      \
-    MOVNTQ "   %%mm"green",  8(%1)\n\t"      \
-    MOVNTQ "   %%mm5,       16(%1)\n\t"      \
-    MOVNTQ "   %%mm"alpha", 24(%1)\n\t"      \
+    MOVNTQ "   %%mm"blue",   %%nacl:0(%%r15, %q1)\n\t"      \
+    MOVNTQ "   %%mm"green",  %%nacl:8(%%r15, %q1)\n\t"      \
+    MOVNTQ "   %%mm5,       %%nacl:16(%%r15, %q1)\n\t"      \
+    MOVNTQ "   %%mm"alpha", %%nacl:24(%%r15, %q1)\n\t"      \
 
 #if !COMPILE_TEMPLATE_MMXEXT
 static inline int RENAME(yuv420_rgb32)(SwsContext *c, const uint8_t *src[],
